{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ab82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import regex\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2b6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/sijiawu/Work/Thesis/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee45cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/5mt219qj6l552yrf3l89xgdh0000gn/T/ipykernel_72120/2610317099.py:14: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  j_data[i]=pd.read_excel(base_path+'Combined/'+i+'_M_sco_du.xlsx')\n"
     ]
    }
   ],
   "source": [
    "# Merged=pd.read_excel(base_path+'/Combined/AER_M_sco_du.xlsx')\n",
    "# Merged.loc[Merged['journal']=='The American Economic Review','journal']='AER'\n",
    "JOURNALS= [\n",
    "    'AER', \n",
    "    'JPE', \n",
    "    'ECTA', \n",
    "    'RES', \n",
    "    'QJE'\n",
    "]\n",
    "\n",
    "#read in all processed masterlists\n",
    "j_data={}\n",
    "for i in JOURNALS:\n",
    "    j_data[i]=pd.read_excel(base_path+'Combined/'+i+'_M_sco_du.xlsx')\n",
    "#Create a batch file\n",
    "j_data=pd.concat(j_data.values(), ignore_index=True)\n",
    "j_data=j_data[j_data.duplicated()==False].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Replace the journal names with Acronyms\n",
    "j_data.loc[j_data['journal']==\"Econometrica\",'journal']='econometrica'\n",
    "j_data.loc[j_data['journal']=='The Quarterly Journal of Economics','journal']='quarterly journal of economics'\n",
    "j_data.loc[j_data['journal']=='The Review of Economic Studies','journal']='review of economic studies'\n",
    "j_data.loc[j_data['journal']=='Journal of Political Economy','journal']='journal of political economy'\n",
    "j_data.loc[j_data['journal']=='The American Economic Review','journal']='american economic review'\n",
    "\n",
    "#some corrections to the issue\n",
    "j_data.loc[j_data[\"number\"]==\"2023-03-04 00:00:00\",\"number\"]=\"3--4\"\n",
    "j_data.loc[j_data[\"number\"]==\"4-5\",\"number\"]=\"4--5\"\n",
    "j_data.loc[j_data[\"number\"]==\"1-2\",\"number\"]=\"1--2\"\n",
    "\n",
    "j_data[\"ID\"]=j_data[\"URL\"].str.split(\"/\").str[-1]\n",
    "j_data[\"title_proc\"]=j_data[\"title\"].fillna(\"none\").astype(str).str.lower()\n",
    "\n",
    "\n",
    "Merged=j_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa0c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(filepath):\n",
    "    with open(filepath) as json_data:\n",
    "        d = json.load(json_data)\n",
    "        json_data.close()\n",
    "        return d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbea08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f27b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_check=[]\n",
    "ref_names=[\"full reference in Chicago referencing style\",'reference','full reference','full_reference']\n",
    "av=0\n",
    "js=0\n",
    "js_6=0\n",
    "issue=[]\n",
    "references={}\n",
    "manu=[]\n",
    "manu2=[]\n",
    "ex1=[]\n",
    "ex2=[]\n",
    "keys=[]\n",
    "jour=[]\n",
    "alt=[]\n",
    "alt2=[]\n",
    "alt3=[]\n",
    "nj=[]\n",
    "probs=[]\n",
    "eds=[]\n",
    "count=0\n",
    "book=0\n",
    "al=[]\n",
    "issue_papers=[]\n",
    "for i in Merged.index:\n",
    "    # if count>100:\n",
    "    #     break\n",
    "    paper_id=Merged.loc[i,\"ID\"]\n",
    "    # if paper_id!='1881793':\n",
    "    #     continue\n",
    "    p_ref={\"refs\":[], \"year_o\":Merged.loc[i, \"year\"], \"journal_o\":Merged.loc[i, \"journal\"]} \n",
    "    filename=base_path+\"new_gpt/\"+Merged.loc[i,\"ID\"]+\"_chatgpt.json\"\n",
    "    if os.path.exists(filename):\n",
    "        count=count+1\n",
    "        # print(paper_id)\n",
    "        ref_count=0\n",
    "        paper=open_json(filename)\n",
    "        ke=paper[paper_id].keys()\n",
    "        # print(ke)\n",
    "        if 'choices' in ke:\n",
    "            ke=['single']\n",
    "        pages=[]\n",
    "        for x in ke:\n",
    "            if x=='single':\n",
    "                content=paper[paper_id]['choices']['message']['content']\n",
    "            else:\n",
    "                content=paper[paper_id][x]['choices']['message']['content']\n",
    "            # print(content)\n",
    "            js=js+1\n",
    "            ref_split=re.findall(\"{[^{}]*}\", content)\n",
    "            # print(len(ref_split))\n",
    "            # print(ref_split)\n",
    "            if len(ref_split)==0:\n",
    "                # print(x)\n",
    "                # print(content)\n",
    "                pages.append(0)\n",
    "            else:\n",
    "                pages.append(1)\n",
    "\n",
    "            for k in ref_split:\n",
    "                ref_single=k.split(\"\\n\")\n",
    "                # print(k)\n",
    "                if len(ref_single)<5:\n",
    "                    continue\n",
    "                \n",
    "                i_ref={}\n",
    "               \n",
    "                for r in ref_single:\n",
    "                    reg_groups=re.search('\\s+\"([^:]*?)\": \"(.*)\"(|,)',r)\n",
    "                    if reg_groups is not None:\n",
    "                        a=reg_groups.groups()\n",
    "                        i_ref[a[0]]=a[1]\n",
    "                        keys.append(a[0])\n",
    "                ref_count+=1\n",
    "\n",
    "                if set([\"authors\", \"year\", \"title\"]).issubset(list(i_ref.keys())) and (set(i_ref.keys()).intersection(ref_names)):\n",
    "                    ref_label=list(set(i_ref.keys()).intersection(ref_names))[0]\n",
    "\n",
    "                    if ((i_ref[\"title\"]==\"NA\")&(i_ref[\"year\"]==\"NA\"))|(i_ref[\"title\"]==\"NA\")&(i_ref[\"authors\"]==\"NA\")|(i_ref[ref_label]==\"NA\"):\n",
    "                        continue\n",
    "                    if i_ref[ref_label]==\"NA\":\n",
    "                        continue\n",
    "                        \n",
    "                    lx=re.sub(r\"[‘’]\",\"'\", i_ref[\"title\"].lower())\n",
    "                    lx=re.sub(r\"[“”]\",'\"', lx)\n",
    "                    lx=re.sub(r\"''\",'\"',lx)\n",
    "                    lx=re.sub(r'\"\"','\"',lx)\n",
    "                    lx=re.sub(r'\\'\"\\'','\"',lx)\n",
    "                    lx=re.sub(r\"(?<=\\D)(- )(?=\\D)\", \"\", lx)\n",
    "                    \n",
    "                    rx=re.sub(r\"[“”]\",'\"',i_ref[ref_label].lower())\n",
    "                    rx=re.sub(r\"[‘’]\",\"'\", rx)\n",
    "                    rx=re.sub(r\"''\",'\"',rx)\n",
    "                    rx=re.sub(r'\"\"','\"',rx)\n",
    "                    rx=re.sub(r'\\'\"\\'','\"',rx)\n",
    "                    rx=re.sub(r\"(?<=\\D)(- )(?=\\D)\", \"\", rx)\n",
    "                    \n",
    "                    \n",
    "                    lx_x=re.sub(\"[()\\[\\]'*]\",\".\",lx)\n",
    "                    lx_x=regex.sub(r'\\\\(\\d)','\\1',lx_x)\n",
    "                    rx_x=re.sub(\"[\\[\\]]\",\".\",rx)\n",
    "                    \n",
    "                    l_check.append(rx)\n",
    "                    \n",
    "                    i_ref[\"status\"]=True\n",
    "                    if (lx not in rx):\n",
    "                        r = regex.compile('(%s){e<=5}' % lx_x)\n",
    "                        if r.search(rx_x) is None:\n",
    "                            print(\"***** issue *****\")\n",
    "                            print(lx)\n",
    "                            print(rx)\n",
    "                            print(lx_x)\n",
    "                            print(rx_x)\n",
    "                            print(\"***** issue *****\")\n",
    "                            i_ref['status']=False\n",
    "\n",
    "                    reg1=r'(?<!\".+)([^()\":0-9]+)[\\(]*(\\d+\\D*?|na|forthcoming|undated)[\\)]*[:. ]+\"(.+)\"[\\'\\\"-+,\\. ]+([^\"\\d]+?)(vol.*|\\d.*)(\\[.+\\]|)'\n",
    "                    reg2=r'(?<!\".+)([^()\":0-9]+)[\\(]*(\\d{2,5}\\D{0,2}?|na|forthcoming|undated)[:. \\)]+(\".+|)'\n",
    "                    reg3=r'(\\D+).(\\d+[^0-9.]*?|na).([^.]*).(.+?)(\\d+):(.*)'\n",
    "                    reg4=r'(?<!\".+)([^()\":0-9]+)[:. ]+\"(.+)\"[\\'\\\"-+,\\. ]+([^\"\\d]+)(vol.*|\\d*)'\n",
    "                    if regex.search(reg1,rx) is not None:\n",
    "                        i_ref[\"alt_j\"]= regex.search(reg1,rx).groups()[3]\n",
    "#                         print(\"found\")\n",
    "#                         print(rx)\n",
    "                        i_ref['regex']={\"pattern\":reg1, \"type\":1}\n",
    "                        chap=regex.search(\"^chap|^chapter |^ch. | chap.|chapter\", i_ref[\"alt_j\"].strip())\n",
    "                        ed=regex.search('ed\\. | eds\\. |edited by|editor| ed\\.|\\(ed\\.|eds\\.\\)', i_ref[\"alt_j\"].strip())\n",
    "                        if \"ed.\" in rx or \"eds.\" in rx or \"edited by\" in rx or \"editor\" in rx:\n",
    "                            book+=1\n",
    "                        has_in=regex.search(r\"^in .+\",i_ref[\"alt_j\"].strip())\n",
    "                        http=regex.search(r'http:|https:', rx)\n",
    "                        accessed_at=regex.search(r'accessed at http',rx)\n",
    "                        dis_paper=regex.search(\"discussion paper\",rx)\n",
    "                        work_paper=regex.search(\"working paper\", rx)\n",
    "                        un_pub=regex.search(\"unpublished .*\", i_ref[\"alt_j\"])\n",
    "                        report=regex.search(\"^report\", i_ref[\"alt_j\"].strip())\n",
    "                        if chap is not None or ed is not None or has_in is not None:\n",
    "                            print(chap is not None)\n",
    "                            print(ed is not None)\n",
    "                            print(has_in is not None)\n",
    "                            \n",
    "                        else:\n",
    "                            print(i_ref[\"alt_j\"])\n",
    "                        if http is not None:\n",
    "                            print(http is not None)\n",
    "                            print(rx)\n",
    "                        jour.append(i_ref[\"alt_j\"].strip())\n",
    "                    \n",
    "                    elif regex.search(reg2,rx) is not None:\n",
    "#                         print(\"found likely chicago style pattern but not journal reference pattern\")\n",
    "                        i_ref['regex']={\"pattern\":reg2, \"type\":2, \"match_target\":rx}\n",
    "#                         print(regex.search(reg2,rx).groups())\n",
    "                        alt.append(rx)\n",
    "                    elif regex.search(reg4,rx) is not None:\n",
    "                        i_ref[\"alt_j\"]= regex.search(reg4,rx).groups()[2]\n",
    "                        i_ref['regex']={\"pattern\":reg4, \"type\":4, \"match_target\":rx}\n",
    "\n",
    "                        alt3.append(rx)\n",
    "                    elif regex.search(reg3,rx) is not None:\n",
    "                        i_ref[\"alt_j\"]= regex.search(reg3,rx).groups()[4]\n",
    "#                         print(\"found alternative style pattern\")\n",
    "                        i_ref['regex']={\"pattern\":reg3, \"type\":3, \"match_target\":rx}\n",
    "                        alt2.append(rx)\n",
    "                    \n",
    "\n",
    "                    else:\n",
    "                        nj.append(rx)\n",
    "                        print(\"not found\")\n",
    "                        i_ref['regex']={\"pattern\":None, \"type\":None, \"match_target\":rx}\n",
    "                        # print(lx_x)\n",
    "                        # print(rx)\n",
    "                        print(\"\\n\")\n",
    "                        probs.append(paper_id)\n",
    "                        print(i_ref)\n",
    "#                     # t2=time.time()\n",
    "# #                     print(t2-t1)\n",
    "                # pprint(i_ref)\n",
    "                \n",
    "                p_ref[\"refs\"].append(i_ref)\n",
    "        # else:\n",
    "        #     js_6+=1\n",
    "        #     issue_papers.append(paper_id)\n",
    "        # av=av+1\n",
    "        if ((len(ke)-1)>sum(pages))&(Merged.loc[i,'year']<1985):\n",
    "            print(paper_id)\n",
    "            print('potential issue')\n",
    "            print((len(ke)-1))\n",
    "            print(sum(pages))\n",
    "            print(Merged.loc[i,'year'])\n",
    "                       \n",
    "            print(Merged.loc[i,'journal'])\n",
    "\n",
    "        references[paper_id]=p_ref\n",
    "# #         print(\"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f198c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors', 'full_reference', 'month', 'pages', 'publisher', 'title', 'year'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd8255b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10254\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(js)\n",
    "print(js_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43097514",
   "metadata": {},
   "outputs": [],
   "source": [
    "format=[]\n",
    "\n",
    "for i in references.keys():\n",
    "    # print(i)\n",
    "    temp_ref=references[i][\"refs\"]\n",
    "    k=0\n",
    "    for j in temp_ref:            \n",
    "        format.append({\"year_o\":references[i][\"year_o\"], \"journal_o\": references[i][\"journal_o\"], \"id_o\": i, \"ref_ord\": k}|j)\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857cf161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=pd.DataFrame(format)\n",
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3436e646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155782, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c248e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_r=output.replace(\"NA\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "641129b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_r[output_r['status']==False].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33177ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
      "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
      "       'regex'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(output_r.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ef6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_f=output_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffde197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_f['f_key']='tesseract_'+str(output_f.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e6c8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26010600373972587"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alt)\n",
    "len(alt2)\n",
    "len(alt3)\n",
    "book\n",
    "(len(nj)+172)/(len(jour) +len(alt)+len(alt3)+len(nj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b1f41aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38499\n"
     ]
    }
   ],
   "source": [
    "print(len(probs))\n",
    "p_list=list(set(probs))\n",
    "\n",
    "data=[]\n",
    "for i in references.keys():\n",
    "    hal=0\n",
    "    for k in references[i][\"refs\"]:\n",
    "        if \"status\" not in k.keys():\n",
    "            continue\n",
    "        if k['status']==False:\n",
    "            hal+=1\n",
    "    data.append({'ID':i,'total':len(references[i][\"refs\"]), 'probs':probs.count(i), \"hal\":hal,'journal':j_data[j_data.ID==i]['journal'].values[0]})\n",
    "\n",
    "out=pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d3c42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out['rat']=out.probs/out.total\n",
    "out=out.sort_values(by=[\"probs\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b8240f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f418d97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american economic review          1496\n",
       "journal of political economy       316\n",
       "quarterly journal of economics     298\n",
       "review of economic studies          69\n",
       "econometrica                        45\n",
       "Name: journal, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[out.rat>0][\"journal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0366f634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american economic review          2617\n",
       "journal of political economy       608\n",
       "quarterly journal of economics     304\n",
       "econometrica                       274\n",
       "review of economic studies         201\n",
       "Name: journal, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"journal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a4a6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_list=list(set(jour))\n",
    "j_list.sort()\n",
    "len(j_list)\n",
    "len(jour)\n",
    "j_list=list(set(j_list))\n",
    "\n",
    "book_chaps=0\n",
    "h_link=0\n",
    "man=0\n",
    "mim=0\n",
    "for i in range(len(j_list)):\n",
    "    if j_list[i][:3]==\"in \":\n",
    "        # print(j_list[i])\n",
    "        book_chaps+=1\n",
    "        continue  \n",
    "    if (j_list[i][:9]==\"accessed \")|(j_list[i][:10]==\"available \")|(j_list[i][:14]==\"last accessed \"):\n",
    "        h_link+=1\n",
    "        continue\n",
    "    if \"manuscript\" in j_list[i][:15]:\n",
    "        man+=1\n",
    "        continue\n",
    "    if \"mimeo\" in j_list[i]:\n",
    "        mim+=1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9531ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18974\n",
      "7184\n",
      "24124\n"
     ]
    }
   ],
   "source": [
    "publishers=list(output_f[output_f['publisher'].isna()==False]['publisher'].str.strip().str.upper().unique())\n",
    "publishers.sort()\n",
    "print(len(publishers))\n",
    "\n",
    "alt_j=list(output_f[output_f['alt_j'].isna()==False]['alt_j'].str.strip().str.upper().unique())\n",
    "alt_j.sort()\n",
    "print(len(alt_j))\n",
    "\n",
    "\n",
    "recon_pubs=alt_j+publishers\n",
    "recon_pubs=list(set(recon_pubs))\n",
    "recon_pubs.sort()\n",
    "print(len(recon_pubs))\n",
    "\n",
    "# new_j={}\n",
    "# for i in rep_names:\n",
    "#     new_j[i]=[]\n",
    "#     for j in rep_names[i]:\n",
    "#         new_j[i].append(j.strip().upper())\n",
    "#     new_j[i]=list(set(new_j[i]))\n",
    "#     new_j[i].sort()\n",
    "\n",
    "# with open('save_v2.json', 'w') as f:\n",
    "#     json.dump(new_j, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8c0c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_names=open_json(\"./031_recon/gpt_alt_j_v2.json\")\n",
    "rep_names_expand={}\n",
    "for i in rep_names.keys():\n",
    "    for j in list(set(rep_names[i])):\n",
    "        rep_names_expand[j]=i\n",
    "\n",
    "rep_keys=rep_names_expand.keys()\n",
    "for i in output_f.index:\n",
    "    if (pd.isna(output_f.loc[i,\"publisher\"])==False):\n",
    "        if (output_f.loc[i,\"publisher\"].strip().upper() in rep_keys):\n",
    "            output_f.loc[i,\"publisher_proc\"]=rep_names_expand[output_f.loc[i,\"publisher\"].strip().upper()]\n",
    "    if (pd.isna(output_f.loc[i,\"alt_j\"])==False):\n",
    "        if (output_f.loc[i,\"alt_j\"].strip().upper() in rep_keys):\n",
    "            output_f.loc[i,\"alt_j_proc\"]=rep_names_expand[output_f.loc[i,\"alt_j\"].strip().upper()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ae1cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(recon_pubs)):\n",
    "    if recon_pubs[i] in rep_names_expand.keys():\n",
    "        recon_pubs[i]=rep_names_expand[recon_pubs[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaf872f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23671\n"
     ]
    }
   ],
   "source": [
    "recon_pubs=list(set(recon_pubs))\n",
    "print(len(recon_pubs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "650583a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "years=list(output_f[output_f['year'].isna()==False]['year'].str.strip().unique())\n",
    "years.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50b8407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "years=open_json(\"./031_recon/gpt_years_v2.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7799662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_year(x):\n",
    "    y=x.replace(\";\",\",\")\n",
    "    y=y.replace(\" \",\"\")\n",
    "    p=[]\n",
    "    for m in y.split(','):\n",
    "        for n in m.split('-'):\n",
    "            p.append(int(n))\n",
    "\n",
    "    return [min(p),max(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c3426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1cda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "158e7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_keys=['a.e.r.', 'econometrica', 'j.p.e.', 'q.j.e.', 'r.e.s.', 'ibid']\n",
    "j_keys =['J. P. E.', 'A. E. R.', 'ECONOMETRICA', 'Q. J. E.', 'R. E. S.', 'THIS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "98e82bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26304, 17)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_f[(output_f['publisher_proc'].isna()==False) | (output_f['alt_j_proc'].isna()==False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2a0bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensured\n",
      "(4198, 17)\n",
      "no publisher or alternate picked up\n",
      "(129478, 17)\n",
      "no publisher but alternate top 5 found\n",
      "(4022, 17)\n",
      "no publisher but alternate journal found\n",
      "(0, 17)\n",
      "publisher found that is not top 5 and no alternate\n",
      "(0, 17)\n",
      "publisher found that is top 5 and no alternate\n",
      "(18084, 17)\n",
      "publisher found that is not top 5 and alternate found that is top 5\n",
      "(0, 17)\n",
      "publisher found that is top 5 and alternate found that is top 5\n",
      "(4198, 17)\n",
      "publisher found that is not top 5 and alt is found but alt is not in top 5\n",
      "(0, 17)\n",
      "publisher found that is top 5 and alt is found that is not in top 5\n",
      "(0, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"ensured\") #publisher exists, publisher in key, alt exists, alt in key\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==False)&(output_f[\"publisher_proc\"].isin(j_keys)==True)&(output_f[\"alt_j_proc\"].isna()==False)& (output_f[\"publisher_proc\"]==output_f[\"alt_j_proc\"])].shape)\n",
    "\n",
    "print(\"no publisher or alternate picked up\")\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==True)&(output_f[\"alt_j_proc\"].isna()==True)].shape)\n",
    "\n",
    "print(\"no publisher but alternate top 5 found\")\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==True)&(output_f[\"alt_j_proc\"].isna()==False)& (output_f[\"alt_j_proc\"].isin(j_keys)==True)].shape)\n",
    "print(\"no publisher but alternate journal found\")\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==True)&(output_f[\"alt_j_proc\"].isna()==False)& (output_f[\"alt_j_proc\"].isin(j_keys)==False)].shape)\n",
    "\n",
    "print(\"publisher found that is not top 5 and no alternate\")\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==False)&(output_f[\"alt_j_proc\"].isna()==True)& (output_f[\"publisher_proc\"].isin(j_keys)==False)].shape)\n",
    "print(\"publisher found that is top 5 and no alternate\")\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==False)&(output_f[\"alt_j_proc\"].isna()==True)& (output_f[\"publisher_proc\"].isin(j_keys)==True)].shape)\n",
    "\n",
    "print(\"publisher found that is not top 5 and alternate found that is top 5\")\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==False)&(output_f[\"alt_j_proc\"].isna()==False)& (output_f[\"alt_j_proc\"].isin(j_keys)==True)& (output_f[\"publisher_proc\"].isin(j_keys)==False)].shape)\n",
    "print(\"publisher found that is top 5 and alternate found that is top 5\")\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==False)&(output_f[\"alt_j_proc\"].isna()==False)& (output_f[\"alt_j_proc\"].isin(j_keys)==True)& (output_f[\"publisher_proc\"].isin(j_keys)==True)].shape)\n",
    "\n",
    "print(\"publisher found that is not top 5 and alt is found but alt is not in top 5\")\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==False)&(output_f[\"alt_j_proc\"].isna()==False)& (output_f[\"alt_j_proc\"].isin(j_keys)==False)& (output_f[\"publisher_proc\"].isin(j_keys)==False)].shape)\n",
    "print(\"publisher found that is top 5 and alt is found that is not in top 5\")\n",
    "print(output_f[(output_f[\"publisher_proc\"].isna()==False)&(output_f[\"alt_j_proc\"].isna()==False)& (output_f[\"alt_j_proc\"].isin(j_keys)==False)& (output_f[\"publisher_proc\"].isin(j_keys)==True)].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "badb2511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26304"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4198+4022+18084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36bd3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_a=output_f[(output_f[\"publisher_proc\"].isna()==False)&(output_f[\"publisher_proc\"].isin(j_keys)==True)& (output_f[\"publisher_proc\"]==output_f[\"alt_j_proc\"])].reset_index(drop=True)\n",
    "match_b=output_f[(output_f[\"publisher_proc\"].isna()==False)&(output_f[\"alt_j_proc\"].isna()==True)& (output_f[\"publisher_proc\"].isin(j_keys)==True)].reset_index(drop=True)\n",
    "match_c=output_f[(output_f[\"publisher_proc\"].isna()==True)&(output_f[\"alt_j_proc\"].isna()==False)& (output_f[\"alt_j_proc\"].isin(j_keys)==True)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65e01e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4198, 17)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35009868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     154102\n",
       "False        52\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_f['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6999011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18084, 17)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1850e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8864617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4022, 17)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f6f4ff",
   "metadata": {},
   "source": [
    "## Reconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a088f88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ba7eca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2eb8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bafa476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a44adbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Utility function to compute similarity\n",
    "def similar(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "transform={\n",
    "    \"Q. J. E.\":'quarterly journal of economics', \n",
    "    'R. E. S.':'review of economic studies',\n",
    "    'ECONOMETRICA':'econometrica', \n",
    "    'J. P. E.':'journal of political economy',\n",
    "    \"A. E. R.\":'american economic review'\n",
    "}\n",
    "\n",
    "def construct(j_data, journal,year,use_year, title):\n",
    "    temp=j_data[(j_data[\"journal\"]==journal)&(j_data[\"year\"]<=(year+2))&(j_data[\"year\"]>=(use_year-10))][\"title_proc\"].apply(lambda y: similar(y, title))\n",
    "    o=temp[temp>=(max(temp)-0.15)]\n",
    "    return {\"index\": list(o.index), \"m_val\":list(o)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa74fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4cbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94dca9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_proc(match_in, years,outfile_name, use_j):\n",
    "    match_in[\"use_year\"]='0'\n",
    "    match_in[\"use_journal\"]=''\n",
    "    match_in[\"use_title\"]=''\n",
    "    match_in=match_in.fillna('0')\n",
    "    for i in match_in.index:\n",
    "        # print(match_in.loc[i,'year'].strip())\n",
    "        match_in.loc[i,'year_proc']=years[match_in.loc[i,'year'].strip()]\n",
    "        year_temp=match_in.loc[i, 'year_proc']\n",
    "        if (\",\" in year_temp)|(\"-\" in year_temp):\n",
    "            match_in.loc[i, \"year_latest\"]=proc_year(year_temp)[1]\n",
    "            match_in.loc[i, \"year_earliest\"]=proc_year(year_temp)[0]\n",
    "        elif year_temp in [\"FORTHCOMING\"]:\n",
    "            match_in.loc[i, \"year_latest\"]=int(match_in.loc[i, 'year_o'])+2\n",
    "            match_in.loc[i, \"year_earliest\"]=int(match_in.loc[i, 'year_o'])\n",
    "        elif year_temp in [\"NA\", \"NONE\", \"VARIOUS\"]:\n",
    "            match_in.loc[i, \"year_earliest\"]='0'\n",
    "            match_in.loc[i, \"year_latest\"]='0'\n",
    "        else:\n",
    "            match_in.loc[i, \"year_latest\"]=match_in.loc[i, 'year_proc']\n",
    "            match_in.loc[i, \"year_earliest\"]=match_in.loc[i, 'year_proc']\n",
    "    print(list(match_in['year_latest'].unique()))\n",
    "    print(match_in.columns)\n",
    "    # match_a=pd.read_excel(\"match_a.xlsx\")\n",
    "    for i in match_in.index:\n",
    "\n",
    "        use_year=int(match_in.loc[i,'year_o'])+2\n",
    "        use_journal=''\n",
    "        if match_in.loc[i,use_j] in ['CURRENT', \"THIS\"]:\n",
    "            use_journal=match_in.loc[i, 'journal_o']\n",
    "        elif match_in.loc[i,use_j]=='ibid':\n",
    "            if match_in[(match_in['ref_ord']==(match_in.loc[i,'ref_ord']-1)) & (match_in['id_o']==match_in.loc[i,'id_o'])].shape[0]==1:\n",
    "                # print(i)\n",
    "                use_journal=list(match_in.loc[(match_in['ref_ord']==(match_in.loc[i,'ref_ord']-1)) & (match_in['id_o']==match_in.loc[i,'id_o']), 'use_journal'])[0]\n",
    "                # print(use_journal)\n",
    "            else:\n",
    "                use_journal=None\n",
    "                continue\n",
    "        else:\n",
    "            use_journal=transform[match_in.loc[i,use_j]]\n",
    "        \n",
    "        use_title=match_in.loc[i,'title'].lower()\n",
    "        match_in.loc[i,\"use_title\"]=use_title\n",
    "        match_in.loc[i,\"use_journal\"]=use_journal\n",
    "        match_in.loc[i,\"use_year\"]=use_year\n",
    "\n",
    "        # print(construct(j_data, use_journal,use_year,use_title))\n",
    "    print(match_in[use_j].value_counts())\n",
    "    # match_a[0:100].apply(lambda x:construct(j_data, x['use_journal'],x['use_year'],x['use_title']), axis=1)\n",
    "    match_in.to_excel(outfile_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8f5f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016', '2006', '2017', '2020', '2018', '1998', '2005', '2009', '2000', '2013', '1999', '1989', '2012', '2014', '2001', '2011', '1950', '1994', '2007', '2019', '1995', '2004', '1991', '1987', '1980', '2010', '1992', '1996', '2015', '2002', '1969', '1943', '2008', '1982', '1997', '1993', '1979', '1960', '1958', '1986', '2003', '1990', '1977', '1988', '1985', '1941', '1983', '1965', '1972', '1984', '1976', '1978', '1971', '1933', '1970', '1949', '1967', '1968', '1981', '1975', '1973', '1961', '1963', '1962', '1955', '1956', '1925', '1953', '1948', '1954', '1959', '1966', '1974', '0', '1964', '1951', '1928', '1945', '1938', '1919', '1911', '1939', '1924', '1913', '1937', '1931', '1952', '1936', '1957', 1954, '1934', '1892']\n",
      "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
      "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
      "       'regex', 'f_key', 'publisher_proc', 'alt_j_proc', 'use_year',\n",
      "       'use_journal', 'use_title', 'year_proc', 'year_latest',\n",
      "       'year_earliest'],\n",
      "      dtype='object')\n",
      "A. E. R.        1617\n",
      "ECONOMETRICA     768\n",
      "Q. J. E.         744\n",
      "J. P. E.         669\n",
      "R. E. S.         400\n",
      "Name: publisher_proc, dtype: int64\n",
      "['2013', '2012', '2020', '2001', '2009', '2010', '1968', '2014', '2017', '1991', '2007', '2004', '2005', '1999', '0', '2015', '2018', '2016', '2011', '2006', '1948', '1989', '1981', '1997', '2019', '2003', '2008', '1987', '1998', '1993', '1982', '1985', '2000', '1974', 2022, '1992', '2002', '1973', '1988', '1986', '1977', '1994', '1995', '1978', 2021, '1963', '1956', '1949', '1967', '1947', '1911', '1990', '1996', '1950', 2020, '1984', '1980', '1965', '1958', '1983', '1972', '1961', '1976', 2019, '1979', '1951', '1970', '1945', '1931', '1975', '1954', 2018, '1969', '1964', 2017, '1966', 2016, '1971', '1952', '1953', '1922', '1916', '1957', '1905', 2014, '1933', '1955', '1962', 2013, '1960', '1941', '1917', 2011, '1937', 2010, 2009, 2008, '1940', '1943', 1954, '1959', '1946', '1923', '1930', '1924', '1934', '1938', '1906', '1907', '1944', '1932', '1895', '1908', '1925', '1939', '1935', '1942', '1896', '1936', 1984, '1927', 1978, 1957, 1969, 1949, 1897, 1956, '1909', '1921', 2015, '1920', 1946, 1950, '1904', '1892', '1889', 1970]\n",
      "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
      "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
      "       'regex', 'f_key', 'publisher_proc', 'alt_j_proc', 'use_year',\n",
      "       'use_journal', 'use_title', 'year_proc', 'year_latest',\n",
      "       'year_earliest'],\n",
      "      dtype='object')\n",
      "A. E. R.        6362\n",
      "ECONOMETRICA    3778\n",
      "Q. J. E.        3106\n",
      "J. P. E.        3042\n",
      "R. E. S.        1796\n",
      "Name: publisher_proc, dtype: int64\n",
      "['2003', '1991', '2007', '2012', '2005', '2015', '2004', '2014', '2010', '2017', '2016', '1972', '2006', '1999', '2013', '1933', '1978', '2019', '2018', '1997', '1980', '2000', '2020', '1989', '1981', '1985', '2009', '2011', '1995', '2002', '1984', '1998', '2008', '1993', '1963', '1970', '1983', '1934', '1944', '1996', '2001', '1990', '1973', '1992', '1955', '1982', '1988', '1994', '1986', '1977', '1974', '1956', '1961', '1979', '1964', '1975', '1968', '1976', '1971', '1950', '1966', '1953', '1959', '1948', '1937', '1987', '1957', '1938', '1952', '1965', '1954', '1958', '1962', '1947', '1960', '1969', '1911', '1931', '1945', '1939', '1909', '1967', '1951', '1932', '0', '1922', '1949', '1946', '1935', '1943', '1936', '1892', '1940', '1941', '1928', '1899', '1907', '1903', '1894', '1896', '1895', '1904', '1893', '1900', 1956, 1957, '1929', '1925', '1942', '1912', '1889', '1890', '1886']\n",
      "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
      "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
      "       'regex', 'f_key', 'publisher_proc', 'alt_j_proc', 'use_year',\n",
      "       'use_journal', 'use_title', 'year_proc', 'year_latest',\n",
      "       'year_earliest'],\n",
      "      dtype='object')\n",
      "A. E. R.        1341\n",
      "J. P. E.         931\n",
      "ECONOMETRICA     708\n",
      "Q. J. E.         663\n",
      "R. E. S.         368\n",
      "THIS              11\n",
      "Name: alt_j_proc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "output_proc(match_a, open_json(\"./031_recon/gpt_years_v2.json\"),\"./031_recon/gpt_match_a_v2.xlsx\", 'publisher_proc')\n",
    "output_proc(match_b, open_json(\"./031_recon/gpt_years_v2.json\"),\"./031_recon/gpt_match_b_v2.xlsx\", 'publisher_proc')\n",
    "output_proc(match_c, open_json(\"./031_recon/gpt_years_v2.json\"),\"./031_recon/gpt_match_c_v2.xlsx\", 'alt_j_proc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3df67620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years=list(match_d['year'].fillna('0').unique())\n",
    "# year_struc={}\n",
    "# for i in years:\n",
    "#     year_struc[i]=i\n",
    "# with open('years_d.json', 'w') as f:\n",
    "#     json.dump(year_struc, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af539c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_a=pd.DataFrame(open_json(\"./031_recon/outcomes_match_a_v2_full.json\"))\n",
    "matches_b=pd.DataFrame(open_json(\"./031_recon/outcomes_match_b_v2_full.json\"))\n",
    "matches_c=pd.DataFrame(open_json(\"./031_recon/outcomes_match_c_v2_full.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bac529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_a=[]\n",
    "for i in matches_a.index:\n",
    "    inds=matches_a.loc[i,'outcome']['index']\n",
    "    m_vals=matches_a.loc[i,'outcome']['m_val']\n",
    "    # print(inds)\n",
    "    # print(m_vals)\n",
    "    counter_a.append(len(inds))\n",
    "    # if len(inds)==1:\n",
    "        # print(j_data.iloc[inds])\n",
    "\n",
    "counter_b=[]\n",
    "for i in matches_b.index:\n",
    "    inds=matches_b.loc[i,'outcome']['index']\n",
    "    m_vals=matches_b.loc[i,'outcome']['m_val']\n",
    "    # print(inds)\n",
    "    # print(m_vals)\n",
    "    counter_b.append(len(inds))\n",
    "\n",
    "counter_c=[]\n",
    "for i in matches_c.index:\n",
    "    inds=matches_c.loc[i,'outcome']['index']\n",
    "    m_vals=matches_c.loc[i,'outcome']['m_val']\n",
    "    # print(inds)\n",
    "    # print(m_vals)\n",
    "    counter_c.append(len(inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f1671dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_a['btch']='a'\n",
    "matches_b['btch']='b'\n",
    "matches_c['btch']='c'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8e9fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_article=pd.concat([matches_a,\n",
    "                            matches_b,\n",
    "                            matches_c\n",
    "                            ]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6d909f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'publisher_proc', 'alt_j_proc', 'use_year',\n",
       "       'use_journal', 'use_title', 'year_proc', 'year_latest', 'year_earliest',\n",
       "       'outcome', 'btch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4bc84e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81339323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alias(names):\n",
    "    a_fin=[]\n",
    "    b_fin=[]\n",
    "    # print(names)\n",
    "    if pd.isna(names):\n",
    "        return None, None, None\n",
    "    a_temp=names.lower().split(' and ')\n",
    "    for k in range(len(a_temp)):\n",
    "        fn=a_temp[k].split(' ')\n",
    "        init=''\n",
    "        for l in range(len(fn)-1):\n",
    "            init+=fn[l][0]+\". \"\n",
    "        a_fin.append(init+fn[-1])\n",
    "        b_fin.append(fn[0][0]+'. '+fn[-1])\n",
    "    return \"; \".join(a_fin), \", \".join(b_fin), \" \".join(a_fin), \" \".join(b_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6723d857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'publisher_proc', 'alt_j_proc', 'use_year',\n",
       "       'use_journal', 'use_title', 'year_proc', 'year_latest', 'year_earliest',\n",
       "       'outcome', 'btch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5555c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_data[\"at_var\"]=j_data.apply(lambda x: alias(x['author']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_article['match_url']=None\n",
    "found=[]\n",
    "confirmed={\n",
    "    1:[0,0],\n",
    "    2:[0,0],\n",
    "    3:[0,0],\n",
    "    4:[0,0],\n",
    "    5:[0,0],\n",
    "}\n",
    "vary=0\n",
    "vary2=0\n",
    "bad=0\n",
    "re=0\n",
    "for i in fullset_article.index:\n",
    "    # if i ==200:\n",
    "    #     break\n",
    "    count=len(fullset_article.loc[i,\"outcome\"]['index'])\n",
    "    found.append(count)\n",
    "    test=pd.concat([j_data.loc[fullset_article.loc[i,\"outcome\"]['index'], [\"title\",'author','URL','year','at_var']].reset_index(drop=True),pd.DataFrame(fullset_article.loc[i,\"outcome\"])], axis=1)\n",
    "    test=test[test['author'].isna()==False].reset_index(drop=True)\n",
    "    if (test.shape[0]==0) | (count==0):\n",
    "        fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "        print(\"no_match\")\n",
    "        bad+=1\n",
    "        continue\n",
    "    elif count==1:\n",
    "        a=test.loc[0,'author'].lower()\n",
    "        b=fullset_article.loc[i,\"authors\"].lower().replace(\"; \",\" \")\n",
    "        c=fuzz.token_sort_ratio(a,b)\n",
    "        d=test.loc[0,'at_var']\n",
    "        m=test.loc[0,'m_val']\n",
    "\n",
    "        if (m>=0.7)&((c>=80)|(fuzz.token_sort_ratio(b,d[2])>=80)|(fuzz.token_sort_ratio(b,d[3])>=80)):\n",
    "            fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "\n",
    "        elif (m>=0.7)&(int(fullset_article.loc[i,'year_latest'])==int(test.loc[0,'year'])):\n",
    "            fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "        elif ((fullset_article.loc[i,'year_latest']=='0')|(fullset_article.loc[i,'year_latest']==0)) & ((fullset_article.loc[i,'authors']==0)|(fullset_article.loc[i,'authors']=='0'))&(m>=0.95):\n",
    "            fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "        else:\n",
    "            print(\"single\")\n",
    "            print(fullset_article.loc[i,\"outcome\"]['m_val'])\n",
    "            print(fullset_article.loc[i,[\"use_title\",'year_proc', 'authors','btch']])\n",
    "            print(j_data.loc[fullset_article.loc[i,\"outcome\"]['index'],['title_proc','year','author']])\n",
    "            fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "\n",
    "    elif count>1:\n",
    "        if sum(test[\"m_val\"]==1)==1:\n",
    "            a=list(test[test[\"m_val\"]==1]['author'])[0]\n",
    "            b=fullset_article.loc[i,\"authors\"]\n",
    "            d=list(test[test[\"m_val\"]==1]['at_var'])[0]\n",
    "            if pd.isna(a)==True:\n",
    "                fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "                continue\n",
    "            if (fuzz.token_sort_ratio(a.lower(),b.lower())>=80)|(fuzz.token_sort_ratio(b,d[2])>=80)|(fuzz.token_sort_ratio(b,d[3])>=80):\n",
    "                # confirmed[count][0]+=1\n",
    "                fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "                continue\n",
    "\n",
    "        if (sum(test[\"m_val\"]>0.65)>0):\n",
    "            if sum(test[\"year\"]==fullset_article.loc[i,\"year_proc\"])==1:\n",
    "                print(\"year match\")\n",
    "                a=similar(str(list(test[test[\"year\"]==fullset_article.loc[i,\"year_proc\"]]['authors'])[0]), str(fullset_article.loc[i,\"authors\"]))\n",
    "                b=similar(str(list(test[test[\"year\"]==fullset_article.loc[i,\"year_proc\"]]['authors'])[0]).split(' ')[-1], str(fullset_article.loc[i,\"authors\"]).split(' ')[-1])\n",
    "                if (a>0.8) or (b>0.8):\n",
    "                    fullset_article.loc[i,'match_url']=list(test[test[\"year\"]==fullset_article.loc[i,\"year_proc\"]][\"URL\"])[0]\n",
    "                    vary2+=1\n",
    "                else:\n",
    "                    fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "            vary+=1\n",
    "            \n",
    "        else:\n",
    "            print(\"unlikely match\")\n",
    "            fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "            bad+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c4a3aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    260\n",
       "a     38\n",
       "c     32\n",
       "Name: btch, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article[fullset_article[\"match_url\"]==\"CHECKREQ\"]['btch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "632e3f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011072339283317675"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article[fullset_article[\"match_url\"]==\"CHECKREQ\"].shape[0]/fullset_article.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b8b7bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9076"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullset_article[\"match_url\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc25605e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    18084\n",
       "a     7698\n",
       "c     4022\n",
       "Name: btch, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article['btch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78336d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29474, 26)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article[fullset_article[\"match_url\"]!=\"CHECKREQ\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c682248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_url(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    elif x==\"CHECKREQ\":\n",
    "        return None\n",
    "    else:\n",
    "        return x.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0e85410",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_article['match_id']=fullset_article.apply(lambda x: proc_url(x['match_url']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24efe628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct(j_data, journal,year,title):\n",
    "    if pd.isna(journal)==True:\n",
    "        return {'index':[],\"m_val\":[]}\n",
    "    if journal==\"\":\n",
    "        return {'index':[],\"m_val\":[]}\n",
    "    temp=j_data[(j_data[\"journal\"]==journal)&(j_data[\"year\"]<=(year+2))&(j_data[\"year\"]>=(year-20))][\"title_proc\"].apply(lambda y: similar(y, title))\n",
    "    if len(temp)>0:\n",
    "        o=temp[temp>=(max(temp)-0.15)]\n",
    "        return {\"index\": list(o.index), \"m_val\":list(o)}\n",
    "    else:\n",
    "        return {'index':[],\"m_val\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe48118c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'publisher_proc', 'alt_j_proc', 'use_year',\n",
       "       'use_journal', 'use_title', 'year_proc', 'year_latest', 'year_earliest',\n",
       "       'outcome', 'btch', 'match_url', 'match_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cacfbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j_data[['issue_url', 'URL', 'journal', 'number', 'publisher', 'title',\n",
    "#         'volume', 'year', 'abstract', 'author', 'pages',\n",
    "#        'reviewed-author', 'uploaded', 'author_split', 'title_10',\n",
    "#        'content_type', 'ID',\n",
    "#        'title_proc']].to_excel('jstor_data_v2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6616c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(\n",
    "    left=output_f, \n",
    "    right=fullset_article[['year_o', 'journal_o', 'id_o', 'ref_ord','use_year', 'use_journal', 'use_title', 'year_proc',\n",
    "       'year_latest','year_earliest', 'outcome', 'btch', 'match_url', 'match_id']],\n",
    "    how='left',\n",
    "    left_on=['year_o', 'journal_o', 'id_o', 'ref_ord'],\n",
    "    right_on=['year_o', 'journal_o', 'id_o', 'ref_ord'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a06df8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'publisher_proc', 'alt_j_proc', 'use_year',\n",
       "       'use_journal', 'use_title', 'year_proc', 'year_latest', 'year_earliest',\n",
       "       'outcome', 'btch', 'match_url', 'match_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c557c2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'publisher_proc', 'alt_j_proc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78fdd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['f_key']='tesseract_'+new_df.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4167d390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'publisher_proc', 'alt_j_proc', 'use_year',\n",
       "       'use_journal', 'use_title', 'year_proc', 'year_latest', 'year_earliest',\n",
       "       'outcome', 'btch', 'match_url', 'match_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e162c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_excel('./031_recon/refs_post_1970_v2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d63edd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_article_sub=new_df[(new_df['id_o']!=new_df['match_id'])&(new_df['match_id'].isna()==False)].reset_index(drop=True).drop_duplicates(subset = ['id_o', 'match_id'], keep='first').reset_index(drop=True)[['id_o', 'match_id','f_key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75440c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_article_sub.to_excel('./031_recon/network_cit_post_v2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816c0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
