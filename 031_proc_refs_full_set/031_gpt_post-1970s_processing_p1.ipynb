{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29ab82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import regex\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2b6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/sijiawu/Work/Thesis/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee45cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/5mt219qj6l552yrf3l89xgdh0000gn/T/ipykernel_39795/2610317099.py:14: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  j_data[i]=pd.read_excel(base_path+'Combined/'+i+'_M_sco_du.xlsx')\n"
     ]
    }
   ],
   "source": [
    "# Merged=pd.read_excel(base_path+'/Combined/AER_M_sco_du.xlsx')\n",
    "# Merged.loc[Merged['journal']=='The American Economic Review','journal']='AER'\n",
    "JOURNALS= [\n",
    "    'AER', \n",
    "    'JPE', \n",
    "    'ECTA', \n",
    "    'RES', \n",
    "    'QJE'\n",
    "]\n",
    "\n",
    "#read in all processed masterlists\n",
    "j_data={}\n",
    "for i in JOURNALS:\n",
    "    j_data[i]=pd.read_excel(base_path+'Combined/'+i+'_M_sco_du.xlsx')\n",
    "#Create a batch file\n",
    "j_data=pd.concat(j_data.values(), ignore_index=True)\n",
    "j_data=j_data[j_data.duplicated()==False].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Replace the journal names with Acronyms\n",
    "j_data.loc[j_data['journal']==\"Econometrica\",'journal']='econometrica'\n",
    "j_data.loc[j_data['journal']=='The Quarterly Journal of Economics','journal']='quarterly journal of economics'\n",
    "j_data.loc[j_data['journal']=='The Review of Economic Studies','journal']='review of economic studies'\n",
    "j_data.loc[j_data['journal']=='Journal of Political Economy','journal']='journal of political economy'\n",
    "j_data.loc[j_data['journal']=='The American Economic Review','journal']='american economic review'\n",
    "\n",
    "#some corrections to the issue\n",
    "j_data.loc[j_data[\"number\"]==\"2023-03-04 00:00:00\",\"number\"]=\"3--4\"\n",
    "j_data.loc[j_data[\"number\"]==\"4-5\",\"number\"]=\"4--5\"\n",
    "j_data.loc[j_data[\"number\"]==\"1-2\",\"number\"]=\"1--2\"\n",
    "\n",
    "j_data[\"ID\"]=j_data[\"URL\"].str.split(\"/\").str[-1]\n",
    "j_data[\"title_proc\"]=j_data[\"title\"].fillna(\"none\").astype(str).str.lower()\n",
    "\n",
    "\n",
    "Merged=j_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa0c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(filepath):\n",
    "    with open(filepath) as json_data:\n",
    "        d = json.load(json_data)\n",
    "        json_data.close()\n",
    "        return d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72fbea08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c96dea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f27b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_check=[]\n",
    "ref_names=[\"full reference in Chicago referencing style\",'reference','full reference','full_reference']\n",
    "av=0\n",
    "js=0\n",
    "js_6=0\n",
    "issue=[]\n",
    "references={}\n",
    "manu=[]\n",
    "manu2=[]\n",
    "ex1=[]\n",
    "ex2=[]\n",
    "keys=[]\n",
    "jour=[]\n",
    "alt=[]\n",
    "alt2=[]\n",
    "alt3=[]\n",
    "nj=[]\n",
    "probs=[]\n",
    "eds=[]\n",
    "count=0\n",
    "book=0\n",
    "al=[]\n",
    "issue_papers=[]\n",
    "for i in Merged.index:\n",
    "    count=count+1\n",
    "    paper_id=Merged.loc[i,\"ID\"]\n",
    "    p_ref={\"refs\":[], \"year_o\":Merged.loc[i, \"year\"], \"journal_o\":Merged.loc[i, \"journal\"]} \n",
    "    filename=base_path+\"old_gpt/\"+Merged.loc[i,\"ID\"]+\"_chatgpt.json\"\n",
    "#     if paper_id!=\"45217222\":\n",
    "#         continue\n",
    "    if os.path.exists(filename):\n",
    "        # print(filename)\n",
    "        ref_count=0\n",
    "        # print(paper_id)\n",
    "        content=open_json(filename)[paper_id]['choices'][0]['message']['content']\n",
    "        # print(content)\n",
    "        if content[0]==\"{\":\n",
    "            js=js+1\n",
    "            # print(content)\n",
    "            ref_split=re.findall(\"{[^{}]*}\", content)\n",
    "            for k in ref_split:\n",
    "                ref_single=k.split(\"\\n\")\n",
    "#                 print(k)\n",
    "                if len(ref_single)<5:\n",
    "                    continue\n",
    "                \n",
    "                i_ref={}\n",
    "               \n",
    "                for r in ref_single:\n",
    "                    reg_groups=re.search('\\s+\"([^:]*?)\": \"(.*)\"(|,)',r)\n",
    "                    reg_groups_2=re.search('\\s*?\"([^:]*?)\": \"(.*)\"(|,)',r)\n",
    "\n",
    "                    if reg_groups is not None:\n",
    "                        a=reg_groups.groups()\n",
    "                        i_ref[a[0]]=a[1]\n",
    "                        keys.append(a[0])\n",
    "                    elif reg_groups_2 is not None:\n",
    "                        print(\"reg 2 execute\")\n",
    "                        a=reg_groups_2.groups()\n",
    "                        i_ref[a[0]]=a[1]\n",
    "                        keys.append(a[0])\n",
    "                \n",
    "                \n",
    "                if set([\"authors\", \"year\", \"title\"]).issubset(list(i_ref.keys())) and (set(i_ref.keys()).intersection(ref_names)):\n",
    "                    ref_label=list(set(i_ref.keys()).intersection(ref_names))[0]\n",
    "\n",
    "                    if ((i_ref[\"title\"]==\"NA\")&(i_ref[\"year\"]==\"NA\"))|(i_ref[\"title\"]==\"NA\")&(i_ref[\"authors\"]==\"NA\")|(i_ref[ref_label]==\"NA\"):\n",
    "                        continue\n",
    "                    if i_ref[ref_label]==\"NA\":\n",
    "                        continue\n",
    "                        \n",
    "                    lx=re.sub(r\"[‘’]\",\"'\", i_ref[\"title\"].lower())\n",
    "                    lx=re.sub(r\"[“”]\",'\"', lx)\n",
    "                    lx=re.sub(r\"''\",'\"',lx)\n",
    "                    lx=re.sub(r'\"\"','\"',lx)\n",
    "                    lx=re.sub(r'\\'\"\\'','\"',lx)\n",
    "                    lx=re.sub(r\"(?<=\\D)(- )(?=\\D)\", \"\", lx)\n",
    "                    \n",
    "                    rx=re.sub(r\"[“”]\",'\"',i_ref[ref_label].lower())\n",
    "                    rx=re.sub(r\"[‘’]\",\"'\", rx)\n",
    "                    rx=re.sub(r\"''\",'\"',rx)\n",
    "                    rx=re.sub(r'\"\"','\"',rx)\n",
    "                    rx=re.sub(r'\\'\"\\'','\"',rx)\n",
    "                    rx=re.sub(r\"(?<=\\D)(- )(?=\\D)\", \"\", rx)\n",
    "                    \n",
    "                    \n",
    "                    lx_x=re.sub(\"[()\\[\\]'*]\",\".\",lx)\n",
    "                    lx_x=regex.sub(r'\\\\(\\d)','\\1',lx_x)\n",
    "                    rx_x=re.sub(\"[\\[\\]]\",\".\",rx)\n",
    "                    \n",
    "                    l_check.append(rx)\n",
    "                    \n",
    "                    if regex.search(\"MANUSCRIPT RECEIVED|CO-EDITOR.*HANDLED THIS MANUSCRIPT\".lower(),i_ref[ref_label].lower()) is not None:\n",
    "                        manu.append(i_ref[ref_label])\n",
    "                        continue\n",
    "                        \n",
    "                    if (regex.search(\"MANUSCRIPT RECEIVED|CO-EDITOR.*HANDLED THIS MANUSCRIPT\".lower(),i_ref[\"title\"].lower()) is not None):\n",
    "                        manu2.append(i_ref[\"title\"])\n",
    "                        continue\n",
    "                    i_ref[\"status\"]=True\n",
    "                    if (lx not in rx):\n",
    "                        r = regex.compile('(%s){e<=5}' % lx_x)\n",
    "                        if r.search(rx_x) is None:\n",
    "                            print(\"***** issue *****\")\n",
    "                            print(lx)\n",
    "                            print(rx)\n",
    "                            print(lx_x)\n",
    "                            print(rx_x)\n",
    "                            print(\"***** issue *****\")\n",
    "                            i_ref['status']=False\n",
    "                    t1=time.time()\n",
    "\n",
    "                    reg1=r'(?<!\".+)([^()\":0-9]+)[\\(]*(\\d+\\D*?|na|forthcoming|undated)[\\)]*[:. ]+\"(.+)\"[\\'\\\"-+,\\. ]+([^\"\\d]+?)(vol.*|\\d.*)(\\[.+\\]|)'\n",
    "                    reg2=r'(?<!\".+)([^()\":0-9]+)[\\(]*(\\d{2,5}\\D{0,2}?|na|forthcoming|undated)[:. \\)]+(\".+|)'\n",
    "                    reg3=r'(\\D+).(\\d+[^0-9.]*?|na).([^.]*).(.+?)(\\d+):(.*)'\n",
    "                    reg4=r'(?<!\".+)([^()\":0-9]+)[:. ]+\"(.+)\"[\\'\\\"-+,\\. ]+([^\"\\d]+)(vol.*|\\d*)'\n",
    "                    if regex.search(reg1,rx) is not None:\n",
    "                        i_ref[\"alt_j\"]= regex.search(reg1,rx).groups()[3]\n",
    "#                         print(\"found\")\n",
    "#                         print(rx)\n",
    "                        i_ref['regex']={\"pattern\":reg1, \"type\":1}\n",
    "                        chap=regex.search(\"^chap|^chapter |^ch. | chap.|chapter\", i_ref[\"alt_j\"].strip())\n",
    "                        ed=regex.search('ed\\. | eds\\. |edited by|editor| ed\\.|\\(ed\\.|eds\\.\\)', i_ref[\"alt_j\"].strip())\n",
    "                        if \"ed.\" in rx or \"eds.\" in rx or \"edited by\" in rx or \"editor\" in rx:\n",
    "                            book+=1\n",
    "                        has_in=regex.search(r\"^in .+\",i_ref[\"alt_j\"].strip())\n",
    "                        http=regex.search(r'http:|https:', rx)\n",
    "                        accessed_at=regex.search(r'accessed at http',rx)\n",
    "                        dis_paper=regex.search(\"discussion paper\",rx)\n",
    "                        work_paper=regex.search(\"working paper\", rx)\n",
    "                        un_pub=regex.search(\"unpublished .*\", i_ref[\"alt_j\"])\n",
    "                        report=regex.search(\"^report\", i_ref[\"alt_j\"].strip())\n",
    "#                         if chap is not None or ed is not None or has_in is not None:\n",
    "#                             print(chap is not None)\n",
    "#                             print(ed is not None)\n",
    "#                             print(has_in is not None)\n",
    "                            \n",
    "#                         else:\n",
    "#                             print(i_ref[\"alt_j\"])\n",
    "#                         if http is not None:\n",
    "#                             print(http is not None)\n",
    "#                             print(rx)\n",
    "                        jour.append(i_ref[\"alt_j\"].strip())\n",
    "                    \n",
    "                    elif regex.search(reg2,rx) is not None:\n",
    "#                         print(\"found likely chicago style pattern but not journal reference pattern\")\n",
    "                        i_ref['regex']={\"pattern\":reg2, \"type\":2, \"match_target\":rx}\n",
    "#                         print(regex.search(reg2,rx).groups())\n",
    "                        alt.append(rx)\n",
    "                    elif regex.search(reg4,rx) is not None:\n",
    "                        i_ref[\"alt_j\"]= regex.search(reg4,rx).groups()[2]\n",
    "                        i_ref['regex']={\"pattern\":reg4, \"type\":4, \"match_target\":rx}\n",
    "\n",
    "                        alt3.append(rx)\n",
    "                    elif regex.search(reg3,rx) is not None:\n",
    "                        i_ref[\"alt_j\"]= regex.search(reg3,rx).groups()[4]\n",
    "#                         print(\"found alternative style pattern\")\n",
    "                        i_ref['regex']={\"pattern\":reg3, \"type\":3, \"match_target\":rx}\n",
    "                        alt2.append(rx)\n",
    "                    \n",
    "\n",
    "                    else:\n",
    "                        nj.append(rx)\n",
    "                        # print(\"not found\")\n",
    "                        i_ref['regex']={\"pattern\":None, \"type\":None, \"match_target\":rx}\n",
    "                        # print(lx_x)\n",
    "                        # print(rx)\n",
    "                        # print(\"\\n\")\n",
    "                        probs.append(paper_id)\n",
    "                        # print(i_ref)\n",
    "                    # t2=time.time()\n",
    "#                     print(t2-t1)\n",
    "\n",
    "                p_ref[\"refs\"].append(i_ref)\n",
    "        else:\n",
    "            js_6+=1\n",
    "            issue_papers.append(paper_id)\n",
    "            os.remove(filename)\n",
    "        av=av+1\n",
    "        references[paper_id]=p_ref\n",
    "#         print(\"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9cd8255b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16675\n"
     ]
    }
   ],
   "source": [
    "print(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b04e6c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "43097514",
   "metadata": {},
   "outputs": [],
   "source": [
    "format=[]\n",
    "\n",
    "for i in references.keys():\n",
    "    # print(i)\n",
    "    temp_ref=references[i][\"refs\"]\n",
    "    k=0\n",
    "    for j in temp_ref:            \n",
    "        format.append({\"year_o\":references[i][\"year_o\"], \"journal_o\": references[i][\"journal_o\"], \"id_o\": i, \"ref_ord\": k}|j)\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "857cf161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'publisher/journal', 'publisher or journal', 'full reference',\n",
       "       'journal', 'full reference in Chicago referencing style', 'reference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=pd.DataFrame(format)\n",
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b822bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321390, 20)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "641129b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_r=output.replace(\"NA\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "efd5082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "no\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "for l in output_r[(output_r['journal'].isna()==False)|(output_r['publisher/journal'].isna()==False)].index:\n",
    "    # print(output_r.loc[l]['jstor_id'])\n",
    "    if output_r.loc[l][\"journal\"]==output_r.loc[l]['publisher']:\n",
    "        output_r.loc[l,\"journal\"]=np.nan\n",
    "    else:\n",
    "        if pd.isna(output_r.loc[l][\"publisher\"]):\n",
    "            output_r.loc[l, \"publisher\"]=output_r.loc[l, \"journal\"]\n",
    "            output_r.loc[l,\"journal\"]=np.nan\n",
    "        else:\n",
    "            print(\"no\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21738af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_r[(output_r['publisher/journal'].isna()==False)].index:\n",
    "    # print(output_r.loc[l]['jstor_id'])\n",
    "    if output_r.loc[l][\"publisher/journal\"]==output_r.loc[l]['publisher']:\n",
    "        output_r.loc[l,\"publisher/journal\"]=np.nan\n",
    "    else:\n",
    "        if pd.isna(output_r.loc[l][\"publisher\"]):\n",
    "            output_r.loc[l, \"publisher\"]=output_r.loc[l, \"publisher/journal\"]\n",
    "            output_r.loc[l,\"publisher/journal\"]=np.nan\n",
    "        else:\n",
    "            print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f9406b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_r[(output_r['publisher or journal'].isna()==False)].index:\n",
    "    # print(output_r.loc[l]['jstor_id'])\n",
    "    if output_r.loc[l][\"publisher or journal\"]==output_r.loc[l]['publisher']:\n",
    "        output_r.loc[l,\"publisher or journal\"]=np.nan\n",
    "    else:\n",
    "        if pd.isna(output_r.loc[l][\"publisher\"]):\n",
    "            output_r.loc[l, \"publisher\"]=output_r.loc[l, \"publisher or journal\"]\n",
    "            output_r.loc[l,\"publisher or journal\"]=np.nan\n",
    "        else:\n",
    "            print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef81878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_r[(output_r['full_reference'].isna())==True].index:\n",
    "    a=pd.isna(output_r.loc[l][\"full reference\"])\n",
    "    b=pd.isna(output_r.loc[l][\"full reference in Chicago referencing style\"])\n",
    "    c=pd.isna(output_r.loc[l]['reference'])\n",
    "    if (a + b +c) == 2:\n",
    "        if a:\n",
    "            output_r.loc[l, \"full_reference\"]=output_r.loc[l][\"full reference\"]\n",
    "        if b:\n",
    "            output_r.loc[l, \"full_reference\"]=output_r.loc[l][\"full reference in Chicago referencing style\"]\n",
    "        if c:\n",
    "            output_r.loc[l, \"full_reference\"]=output_r.loc[l][\"full reference in Chicago referencing style\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce579cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_f=output_r.drop(columns=[\"full reference in Chicago referencing style\",'reference','full reference','publisher/journal','publisher or journal','journal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffde197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_f['f_key']='tesseract_'+str(output_f.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e6c8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031415769686357314"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alt)\n",
    "len(alt2)\n",
    "len(alt3)\n",
    "book\n",
    "(len(nj)+172)/(len(jour) +len(alt)+len(alt3)+len(nj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b1f41aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9588\n"
     ]
    }
   ],
   "source": [
    "print(len(probs))\n",
    "p_list=list(set(probs))\n",
    "\n",
    "data=[]\n",
    "for i in references.keys():\n",
    "    hal=0\n",
    "    for k in references[i][\"refs\"]:\n",
    "        if \"status\" not in k.keys():\n",
    "            continue\n",
    "        if k['status']==False:\n",
    "            hal+=1\n",
    "    data.append({'ID':i,'total':len(references[i][\"refs\"]), 'probs':probs.count(i), \"hal\":hal,'journal':j_data[j_data.ID==i]['journal'].values[0]})\n",
    "\n",
    "out=pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d3c42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out['rat']=out.probs/out.total\n",
    "out=out.sort_values(by=[\"probs\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b8240f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f418d97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american economic review          1583\n",
       "econometrica                       847\n",
       "journal of political economy       759\n",
       "review of economic studies         618\n",
       "quarterly journal of economics     556\n",
       "Name: journal, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[out.rat>0][\"journal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0366f634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american economic review          5784\n",
       "econometrica                      3982\n",
       "journal of political economy      2700\n",
       "review of economic studies        2519\n",
       "quarterly journal of economics    1689\n",
       "Name: journal, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"journal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a4a6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_list=list(set(jour))\n",
    "j_list.sort()\n",
    "len(j_list)\n",
    "len(jour)\n",
    "j_list=list(set(j_list))\n",
    "\n",
    "book_chaps=0\n",
    "h_link=0\n",
    "man=0\n",
    "mim=0\n",
    "for i in range(len(j_list)):\n",
    "    if j_list[i][:3]==\"in \":\n",
    "        # print(j_list[i])\n",
    "        book_chaps+=1\n",
    "        continue  \n",
    "    if (j_list[i][:9]==\"accessed \")|(j_list[i][:10]==\"available \")|(j_list[i][:14]==\"last accessed \"):\n",
    "        h_link+=1\n",
    "        continue\n",
    "    if \"manuscript\" in j_list[i][:15]:\n",
    "        man+=1\n",
    "        continue\n",
    "    if \"mimeo\" in j_list[i]:\n",
    "        mim+=1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50b8407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3849\n",
      "62\n",
      "72\n",
      "219\n"
     ]
    }
   ],
   "source": [
    "print(book_chaps)\n",
    "print(h_link)\n",
    "print(man)\n",
    "print(mim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fd0f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_names=open_json(\"./031_recon/gpt_bulk_journal_recon.json\")\n",
    "rep_names_expand={}\n",
    "for i in rep_names.keys():\n",
    "    for j in list(set(rep_names[i])):\n",
    "        rep_names_expand[j]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d1c5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_keys=rep_names_expand.keys()\n",
    "for i in output_f.index:\n",
    "    if (pd.isna(output_f.loc[i,\"publisher\"])==False):\n",
    "        if (output_f.loc[i,\"publisher\"].lower() in rep_keys):\n",
    "            output_f.loc[i,\"publisher\"]=rep_names_expand[output_f.loc[i,\"publisher\"].lower()]\n",
    "    if (pd.isna(output_f.loc[i,\"alt_j\"])==False):\n",
    "        if (output_f.loc[i,\"alt_j\"].lower() in rep_keys):\n",
    "            output_f.loc[i,\"alt_j\"]=rep_names_expand[output_f.loc[i,\"alt_j\"].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c1cda9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a.e.r.', 'econometrica', 'j.p.e.', 'q.j.e.', 'r.e.s.', 'current', 'ibid'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_keys=rep_names.keys()\n",
    "j_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "158e7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_keys=['a.e.r.', 'econometrica', 'j.p.e.', 'q.j.e.', 'r.e.s.', 'ibid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e82bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2a0bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensured\n",
      "(41377, 15)\n",
      "no publisher or alternate picked up\n",
      "(25678, 15)\n",
      "no publisher but alternate top 5 found\n",
      "(36203, 15)\n",
      "no publisher but alternate journal found\n",
      "(46114, 15)\n",
      "publisher found that is not top 5 and no alternate\n",
      "(69807, 15)\n",
      "publisher found that is top 5 and no alternate\n",
      "(5036, 15)\n",
      "publisher found that is not top 5 and alternate found that is top 5\n",
      "(419, 15)\n",
      "publisher found that is top 5 and alternate found that is top 5\n",
      "(41384, 15)\n",
      "publisher found that is not top 5 and alt is found but alt is not in top 5\n",
      "(96801, 15)\n",
      "publisher found that is top 5 and alt is found that is not in top 5\n",
      "(143, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"ensured\") #publisher exists, publisher in key, alt exists, alt in key\n",
    "print(output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"publisher\"].isin(j_keys)==True)& (output_f[\"publisher\"]==output_f[\"alt_j\"])].shape)\n",
    "\n",
    "print(\"no publisher or alternate picked up\")\n",
    "print(output_f[(output_f[\"publisher\"].isna()==True)&(output_f[\"alt_j\"].isna()==True)].shape)\n",
    "\n",
    "print(\"no publisher but alternate top 5 found\")\n",
    "print(output_f[(output_f[\"publisher\"].isna()==True)&(output_f[\"alt_j\"].isna()==False)& (output_f[\"alt_j\"].isin(j_keys)==True)].shape)\n",
    "print(\"no publisher but alternate journal found\")\n",
    "print(output_f[(output_f[\"publisher\"].isna()==True)&(output_f[\"alt_j\"].isna()==False)& (output_f[\"alt_j\"].isin(j_keys)==False)].shape)\n",
    "\n",
    "print(\"publisher found that is not top 5 and no alternate\")\n",
    "print(output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"alt_j\"].isna()==True)& (output_f[\"publisher\"].isin(j_keys)==False)].shape)\n",
    "print(\"publisher found that is top 5 and no alternate\")\n",
    "print(output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"alt_j\"].isna()==True)& (output_f[\"publisher\"].isin(j_keys)==True)].shape)\n",
    "\n",
    "print(\"publisher found that is not top 5 and alternate found that is top 5\")\n",
    "print(output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"alt_j\"].isna()==False)& (output_f[\"alt_j\"].isin(j_keys)==True)& (output_f[\"publisher\"].isin(j_keys)==False)].shape)\n",
    "print(\"publisher found that is top 5 and alternate found that is top 5\")\n",
    "print(output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"alt_j\"].isna()==False)& (output_f[\"alt_j\"].isin(j_keys)==True)& (output_f[\"publisher\"].isin(j_keys)==True)].shape)\n",
    "\n",
    "print(\"publisher found that is not top 5 and alt is found but alt is not in top 5\")\n",
    "print(output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"alt_j\"].isna()==False)& (output_f[\"alt_j\"].isin(j_keys)==False)& (output_f[\"publisher\"].isin(j_keys)==False)].shape)\n",
    "print(\"publisher found that is top 5 and alt is found that is not in top 5\")\n",
    "print(output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"alt_j\"].isna()==False)& (output_f[\"alt_j\"].isin(j_keys)==False)& (output_f[\"publisher\"].isin(j_keys)==True)].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613e5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "badb2511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83042"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36203+5036+419+41384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36bd3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_a=output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"publisher\"].isin(j_keys)==True)& (output_f[\"publisher\"]==output_f[\"alt_j\"])].reset_index(drop=True)\n",
    "# match_a.to_excel(\"post_1970_match_1.xlsx\", index=False)\n",
    "match_b=output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"alt_j\"].isna()==True)& (output_f[\"publisher\"].isin(j_keys)==True)].reset_index(drop=True)\n",
    "# match_b.to_excel('post_1970_match_2.xlsx', index=False)\n",
    "match_c=output_f[(output_f[\"publisher\"].isna()==True)&(output_f[\"alt_j\"].isna()==False)& (output_f[\"alt_j\"].isin(j_keys)==True)].reset_index(drop=True)\n",
    "# match_c.to_excel(\"post_1970_match_3.xlsx\", index=False)\n",
    "match_d=output_f[(output_f[\"publisher\"].isna()==False)&(output_f[\"alt_j\"].isna()==False)& (output_f[\"alt_j\"].isin(j_keys)==True)& (output_f[\"publisher\"].isin(j_keys)==False)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65e01e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321585, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35009868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     310492\n",
       "False       193\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_f['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f6f4ff",
   "metadata": {},
   "source": [
    "## Reconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a088f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j_list_3=list(set(output_f[output_f['publisher'].isna()==False]['publisher'].str.lower()))\n",
    "# j_list_3.sort()\n",
    "# with open('publist_2.json', 'w') as f:\n",
    "#     json.dump(j_list_3, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ba7eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j_list_2=list(set(output_f[output_f[\"alt_j\"].isna()==False]['alt_j'].str.lower()))\n",
    "# j_list_2.sort()\n",
    "# with open('alt_j_2.json', 'w') as f:\n",
    "    # json.dump(j_list_2, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2eb8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bafa476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn=\"/Users/sijiawu/Work/Thesis/Data/data_18_11_23.json\"\n",
    "# fullset=open_json(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a44adbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Utility function to compute similarity\n",
    "def similar(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "transform={\n",
    "    \"q.j.e.\":'quarterly journal of economics', \n",
    "    'r.e.s.':'review of economic studies',\n",
    "    'econometrica':'econometrica', \n",
    "    'j.p.e.':'journal of political economy',\n",
    "    \"a.e.r.\":'american economic review'\n",
    "}\n",
    "\n",
    "def construct(j_data, journal,year,use_year, title):\n",
    "    temp=j_data[(j_data[\"journal\"]==journal)&(j_data[\"year\"]<=(year+2))&(j_data[\"year\"]>=(use_year-10))][\"title_proc\"].apply(lambda y: similar(y, title))\n",
    "    o=temp[temp>=(max(temp)-0.15)]\n",
    "    return {\"index\": list(o.index), \"m_val\":list(o)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0aa74fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4cbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94dca9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_proc(match_in, years,outfile_name, use_j):\n",
    "    match_in[\"use_year\"]='0'\n",
    "    match_in[\"use_journal\"]=''\n",
    "    match_in[\"use_title\"]=''\n",
    "    match_in=match_in.fillna('0')\n",
    "    for i in match_in.index:\n",
    "        match_in.loc[i,'year_proc']=years[match_in.loc[i,'year']]\n",
    "        year_temp=match_in.loc[i, 'year_proc']\n",
    "        if \",\" in year_temp:\n",
    "            match_in.loc[i, 'year_latest']=year_temp.split(',')[-1]\n",
    "        elif \"-\" in year_temp:\n",
    "            match_in.loc[i, \"year_latest\"]=year_temp.split(\"-\")[-1]\n",
    "        elif year_temp==\"FORTHCOMING\":\n",
    "            match_in.loc[i, \"year_latest\"]=int(match_in.loc[i, 'year_o'])+2\n",
    "        elif year_temp==\"THIS\":\n",
    "            match_in.loc[i, \"year_latest\"]=match_in.loc[i, 'year_o']\n",
    "        elif year_temp.lower()==\"none\":\n",
    "            match_in.loc[i, \"year_latest\"]='0'\n",
    "        else:\n",
    "            match_in.loc[i, \"year_latest\"]=match_in.loc[i, 'year_proc']\n",
    "    print(list(match_in['year_latest'].unique()))\n",
    "    print(match_in.columns)\n",
    "    # match_a=pd.read_excel(\"match_a.xlsx\")\n",
    "    for i in match_in.index:\n",
    "\n",
    "        use_year=int(match_in.loc[i,'year_o'])+2\n",
    "\n",
    "        use_journal=''\n",
    "        if match_in.loc[i,use_j] =='current':\n",
    "            use_journal=match_in.loc[i, 'journal_o']\n",
    "        elif match_in.loc[i,use_j]=='ibid':\n",
    "            if match_in[(match_in['ref_ord']==(match_in.loc[i,'ref_ord']-1)) & (match_in['id_o']==match_in.loc[i,'id_o'])].shape[0]==1:\n",
    "                # print(i)\n",
    "                use_journal=list(match_in.loc[(match_in['ref_ord']==(match_in.loc[i,'ref_ord']-1)) & (match_in['id_o']==match_in.loc[i,'id_o']), 'use_journal'])[0]\n",
    "                # print(use_journal)\n",
    "            else:\n",
    "                use_journal=None\n",
    "                continue\n",
    "        else:\n",
    "            use_journal=transform[match_in.loc[i,use_j]]\n",
    "        \n",
    "        use_title=match_in.loc[i,'title'].lower()\n",
    "        match_in.loc[i,\"use_title\"]=use_title\n",
    "        match_in.loc[i,\"use_journal\"]=use_journal\n",
    "        match_in.loc[i,\"use_year\"]=use_year\n",
    "\n",
    "        # print(construct(j_data, use_journal,use_year,use_title))\n",
    "    print(match_in[use_j].value_counts())\n",
    "    # match_a[0:100].apply(lambda x:construct(j_data, x['use_journal'],x['use_year'],x['use_title']), axis=1)\n",
    "    match_in.to_excel(outfile_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_proc(match_a, open_json(\"./031_recon/gpt_years_a.json\"),\"./031_recon/gpt_match_a.xlsx\", 'publisher')\n",
    "output_proc(match_b, open_json(\"./031_recon/gpt_years_b.json\"),\"./031_recon/gpt_match_b.xlsx\", 'publisher')\n",
    "output_proc(match_c, open_json(\"./031_recon/gpt_years_c.json\"),\"./031_recon/gpt_match_c.xlsx\", 'alt_j')\n",
    "output_proc(match_d, open_json(\"./031_recon/gpt_years_d.json\"),\"./031_recon/gpt_match_d.xlsx\", 'alt_j')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3df67620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years=list(match_d['year'].fillna('0').unique())\n",
    "# year_struc={}\n",
    "# for i in years:\n",
    "#     year_struc[i]=i\n",
    "# with open('years_d.json', 'w') as f:\n",
    "#     json.dump(year_struc, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af539c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_a=pd.DataFrame(open_json(\"./031_recon/outcomes_match_a_full.json\"))\n",
    "matches_b=pd.DataFrame(open_json(\"./031_recon/outcomes_match_b_full.json\"))\n",
    "matches_c=pd.DataFrame(open_json(\"./031_recon/outcomes_match_c_full.json\"))\n",
    "matches_d=pd.DataFrame(open_json(\"./031_recon/outcomes_match_d_full.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bac529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_a=[]\n",
    "for i in matches_a.index:\n",
    "    inds=matches_a.loc[i,'outcome']['index']\n",
    "    m_vals=matches_a.loc[i,'outcome']['m_val']\n",
    "    # print(inds)\n",
    "    # print(m_vals)\n",
    "    counter_a.append(len(inds))\n",
    "    # if len(inds)==1:\n",
    "        # print(j_data.iloc[inds])\n",
    "\n",
    "counter_b=[]\n",
    "for i in matches_b.index:\n",
    "    inds=matches_b.loc[i,'outcome']['index']\n",
    "    m_vals=matches_b.loc[i,'outcome']['m_val']\n",
    "    # print(inds)\n",
    "    # print(m_vals)\n",
    "    counter_b.append(len(inds))\n",
    "\n",
    "counter_c=[]\n",
    "for i in matches_c.index:\n",
    "    inds=matches_c.loc[i,'outcome']['index']\n",
    "    m_vals=matches_c.loc[i,'outcome']['m_val']\n",
    "    # print(inds)\n",
    "    # print(m_vals)\n",
    "    counter_c.append(len(inds))\n",
    "\n",
    "counter_d=[]\n",
    "for i in matches_d.index:\n",
    "    inds=matches_d.loc[i,'outcome']['index']\n",
    "    m_vals=matches_d.loc[i,'outcome']['m_val']\n",
    "    # print(inds)\n",
    "    # print(m_vals)\n",
    "    counter_d.append(len(inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f1671dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_a['btch']='a'\n",
    "matches_b['btch']='b'\n",
    "matches_c['btch']='c'\n",
    "matches_d['btch']='d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8e9fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_article=pd.concat([matches_a, matches_b,matches_c,matches_d]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6d909f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'use_year', 'use_journal', 'use_title', 'year_proc',\n",
       "       'year_latest', 'outcome', 'btch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bc84e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81339323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alias(names):\n",
    "    a_fin=[]\n",
    "    b_fin=[]\n",
    "    # print(names)\n",
    "    if pd.isna(names):\n",
    "        return None, None, None\n",
    "    a_temp=names.lower().split(' and ')\n",
    "    for k in range(len(a_temp)):\n",
    "        fn=a_temp[k].split(' ')\n",
    "        init=''\n",
    "        for l in range(len(fn)-1):\n",
    "            init+=fn[l][0]+\". \"\n",
    "        a_fin.append(init+fn[-1])\n",
    "        b_fin.append(fn[0][0]+'. '+fn[-1])\n",
    "    return \"; \".join(a_fin), \", \".join(b_fin), \" \".join(a_fin), \" \".join(b_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6723d857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'use_year', 'use_journal', 'use_title', 'year_proc',\n",
       "       'year_latest', 'outcome', 'btch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5555c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_data[\"at_var\"]=j_data.apply(lambda x: alias(x['author']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_article['match_url']=None\n",
    "found=[]\n",
    "confirmed={\n",
    "    1:[0,0],\n",
    "    2:[0,0],\n",
    "    3:[0,0],\n",
    "    4:[0,0],\n",
    "    5:[0,0],\n",
    "}\n",
    "vary=0\n",
    "vary2=0\n",
    "bad=0\n",
    "re=0\n",
    "for i in fullset_article.index:\n",
    "    # if i ==200:\n",
    "    #     break\n",
    "    count=len(fullset_article.loc[i,\"outcome\"]['index'])\n",
    "    found.append(count)\n",
    "    test=pd.concat([j_data.loc[fullset_article.loc[i,\"outcome\"]['index'], [\"title\",'author','URL','year','at_var']].reset_index(drop=True),pd.DataFrame(fullset_article.loc[i,\"outcome\"])], axis=1)\n",
    "    test=test[test['author'].isna()==False].reset_index(drop=True)\n",
    "    if (test.shape[0]==0) | (count==0):\n",
    "        fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "        print(\"no_match\")\n",
    "        bad+=1\n",
    "        continue\n",
    "    elif count==1:\n",
    "        a=test.loc[0,'author'].lower()\n",
    "        b=fullset_article.loc[i,\"authors\"].lower().replace(\"; \",\" \")\n",
    "        c=fuzz.token_sort_ratio(a,b)\n",
    "        d=test.loc[0,'at_var']\n",
    "        m=test.loc[0,'m_val']\n",
    "\n",
    "        if (m>=0.7)&((c>=80)|(fuzz.token_sort_ratio(b,d[2])>=80)|(fuzz.token_sort_ratio(b,d[3])>=80)):\n",
    "            fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "\n",
    "        elif (m>=0.7)&(int(fullset_article.loc[i,'year_latest'])==int(test.loc[0,'year'])):\n",
    "            fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "        elif ((fullset_article.loc[i,'year_latest']=='0')|(fullset_article.loc[i,'year_latest']==0)) & ((fullset_article.loc[i,'authors']==0)|(fullset_article.loc[i,'authors']=='0'))&(m>=0.95):\n",
    "            fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "        else:\n",
    "            print(\"single\")\n",
    "            print(fullset_article.loc[i,\"outcome\"]['m_val'])\n",
    "            print(fullset_article.loc[i,[\"use_title\",'year_proc', 'authors','btch']])\n",
    "            print(j_data.loc[fullset_article.loc[i,\"outcome\"]['index'],['title_proc','year','author']])\n",
    "            fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "\n",
    "    elif count>1:\n",
    "        if sum(test[\"m_val\"]==1)==1:\n",
    "            a=list(test[test[\"m_val\"]==1]['author'])[0]\n",
    "            b=fullset_article.loc[i,\"authors\"]\n",
    "            d=list(test[test[\"m_val\"]==1]['at_var'])[0]\n",
    "            if pd.isna(a)==True:\n",
    "                fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "                continue\n",
    "            if (fuzz.token_sort_ratio(a.lower(),b.lower())>=80)|(fuzz.token_sort_ratio(b,d[2])>=80)|(fuzz.token_sort_ratio(b,d[3])>=80):\n",
    "                # confirmed[count][0]+=1\n",
    "                fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "                continue\n",
    "\n",
    "        if (sum(test[\"m_val\"]>0.65)>0):\n",
    "            if sum(test[\"year\"]==fullset_article.loc[i,\"year_proc\"])==1:\n",
    "                print(\"year match\")\n",
    "                a=similar(str(list(test[test[\"year\"]==fullset_article.loc[i,\"year_proc\"]]['authors'])[0]), str(fullset_article.loc[i,\"authors\"]))\n",
    "                b=similar(str(list(test[test[\"year\"]==fullset_article.loc[i,\"year_proc\"]]['authors'])[0]).split(' ')[-1], str(fullset_article.loc[i,\"authors\"]).split(' ')[-1])\n",
    "                if (a>0.8) or (b>0.8):\n",
    "                    fullset_article.loc[i,'match_url']=list(test[test[\"year\"]==fullset_article.loc[i,\"year_proc\"]][\"URL\"])[0]\n",
    "                    vary2+=1\n",
    "                else:\n",
    "                    fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "            vary+=1\n",
    "            \n",
    "        else:\n",
    "            print(\"unlikely match\")\n",
    "            fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "            bad+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7108e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c4a3aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c    383\n",
       "a    368\n",
       "b    144\n",
       "d     60\n",
       "Name: btch, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article[fullset_article[\"match_url\"]==\"CHECKREQ\"]['btch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "632e3f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011501174203649064"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article[fullset_article[\"match_url\"]==\"CHECKREQ\"].shape[0]/fullset_article.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b8b7bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14681"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullset_article[\"match_url\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc25605e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    41377\n",
       "c    36203\n",
       "b     5036\n",
       "d      419\n",
       "Name: btch, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article['btch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78336d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82080, 23)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article[fullset_article[\"match_url\"]!=\"CHECKREQ\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c682248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_url(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    elif x==\"CHECKREQ\":\n",
    "        return None\n",
    "    else:\n",
    "        return x.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0e85410",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_article['match_id']=fullset_article.apply(lambda x: proc_url(x['match_url']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24efe628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct(j_data, journal,year,title):\n",
    "    if pd.isna(journal)==True:\n",
    "        return {'index':[],\"m_val\":[]}\n",
    "    if journal==\"\":\n",
    "        return {'index':[],\"m_val\":[]}\n",
    "    temp=j_data[(j_data[\"journal\"]==journal)&(j_data[\"year\"]<=(year+2))&(j_data[\"year\"]>=(year-20))][\"title_proc\"].apply(lambda y: similar(y, title))\n",
    "    if len(temp)>0:\n",
    "        o=temp[temp>=(max(temp)-0.15)]\n",
    "        return {\"index\": list(o.index), \"m_val\":list(o)}\n",
    "    else:\n",
    "        return {'index':[],\"m_val\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe48118c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'use_year', 'use_journal', 'use_title', 'year_proc',\n",
       "       'year_latest', 'outcome', 'btch', 'match_url', 'match_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cacfbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_data[['issue_url', 'URL', 'journal', 'number', 'publisher', 'title',\n",
    "        'volume', 'year', 'abstract', 'author', 'pages',\n",
    "       'reviewed-author', 'uploaded', 'author_split', 'title_10',\n",
    "       'content_type', 'ID',\n",
    "       'title_proc']].to_excel('./031_recon/jstor_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6616c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(\n",
    "    left=output_f, \n",
    "    right=fullset_article[['year_o', 'journal_o', 'id_o', 'ref_ord','use_year', 'use_journal', 'use_title', 'year_proc',\n",
    "       'year_latest', 'outcome', 'btch', 'match_url', 'match_id']],\n",
    "    how='left',\n",
    "    left_on=['year_o', 'journal_o', 'id_o', 'ref_ord'],\n",
    "    right_on=['year_o', 'journal_o', 'id_o', 'ref_ord'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a06df8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'use_year', 'use_journal', 'use_title', 'year_proc',\n",
       "       'year_latest', 'outcome', 'btch', 'match_url', 'match_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c557c2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78fdd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['f_key']='tesseract_'+new_df.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4167d390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_o', 'journal_o', 'id_o', 'ref_ord', 'authors', 'year', 'title',\n",
       "       'month', 'publisher', 'pages', 'full_reference', 'status', 'alt_j',\n",
       "       'regex', 'f_key', 'use_year', 'use_journal', 'use_title', 'year_proc',\n",
       "       'year_latest', 'outcome', 'btch', 'match_url', 'match_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e162c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_excel('./031_recon/refs_post_1970.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d63edd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_article_sub=new_df[(new_df['id_o']!=new_df['match_id'])&(new_df['match_id'].isna()==False)].reset_index(drop=True).drop_duplicates(subset = ['id_o', 'match_id'], keep='first').reset_index(drop=True)[['id_o', 'match_id','f_key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75440c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_article_sub.to_excel('./031_recon/network_cit_post.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816c0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
