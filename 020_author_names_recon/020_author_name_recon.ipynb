{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67772a04",
   "metadata": {},
   "source": [
    "# Author Name Recon\n",
    "\n",
    "This notebook cleans the author names of each paper for the top 5 economic journals for all time using jstor metadata. Running through the cells produces a reconciliation file for the author names as they appear in the masterlists in a raw format. ie: what went in for each author name of an article, what came out and possible aliases. I exclude Miscellaneous content only.\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Going through this data, some of the citation files for JPE acquired from the chicago journals website has an error where special characters are not encoding properly. I have created a manual resolution of these files, but this should be fixed further up the pipeline. There are only 33 names with this problem and you can't resolve it by using the unidecode library. But, specifically, these files:\n",
    "\n",
    "{'uchicago_jpe126_1.bib',\n",
    " 'uchicago_jpe126_3.bib',\n",
    " 'uchicago_jpe126_5.bib',\n",
    " 'uchicago_jpe126_6.bib',\n",
    " 'uchicago_jpe126_S1.bib',\n",
    " 'uchicago_jpe127_1.bib',\n",
    " 'uchicago_jpe127_2.bib',\n",
    " 'uchicago_jpe127_3.bib',\n",
    " 'uchicago_jpe127_4.bib',\n",
    " 'uchicago_jpe127_5.bib',\n",
    " 'uchicago_jpe128_1.bib',\n",
    " 'uchicago_jpe128_10.bib',\n",
    " 'uchicago_jpe128_11.bib',\n",
    " 'uchicago_jpe128_12.bib',\n",
    " 'uchicago_jpe128_2.bib',\n",
    " 'uchicago_jpe128_4.bib',\n",
    " 'uchicago_jpe128_5.bib',\n",
    " 'uchicago_jpe128_7.bib',\n",
    " 'uchicago_jpe128_8.bib',\n",
    " 'uchicago_jpe128_9.bib'} \n",
    "* Resolution of some special characters results in empty string using unicodedata.normalize() function. For example the danish o (o with a slash) does not result in o but rather an empty string. So I have made a function and a accompanying recon file that fixes this.\n",
    "* There are some authors which:\n",
    "    * have only their initials (even the last name is contracted)\n",
    "    * they are just referred to by their last name because of how well known they are. \n",
    "    * there are so many authors that only the primary author is mentioned and the others are contracted into a catch-all term like \"other\", \"company\" or \"co.\". \n",
    "    \n",
    "    These are limited and recommend resolving here as they are easily picked out. Todo: Construct a recon file manually compiled to replace these.\n",
    "\n",
    "**Input**: \n",
    "* each of the cleaned masterlists with file ending in \\_M_sco_du.xlsx \n",
    "\n",
    "**Output**: \n",
    "* a json file of reconciliated and cleaned author names and associated article URLs\n",
    "* a list of UTF-8 characters and the ascii equivalent to which they should resolve.\n",
    "* a list of author name corrections for JPE errors\n",
    "* TODO: a list of author name corrections for contraction cases, need to do article URL matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295123c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f95ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "# set column options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812c029",
   "metadata": {},
   "source": [
    "## Read in input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f648623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOURNALS= ['AER', 'JPE', 'ECTA', 'RES', 'QJE']\n",
    "base_path=\"/Users/sijiawu/Work/Thesis/Data\"\n",
    "input_base_path=base_path+\"/013_split_data\"\n",
    "output_base_path=base_path+\"/020_author_names_recon\"\n",
    "#read in all processed masterlists\n",
    "\n",
    "#NB this is the output from notebook 013_split_data\n",
    "j_data=pd.read_pickle(input_base_path+\"/013_merged_proc_scopus_inception_2020_w_counts.pkl\")\n",
    "j_data['year']=j_data[\"year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "add79db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['issue_url', 'author', 'title', 'journal', 'volume', 'number', 'pages',\n",
       "       'year', 'ISSN', 'abstract', 'URL', 'publisher', 'content_type', 'type',\n",
       "       'jid', 'author_split', 'urldate', 'reviewed-author', 'uploaded',\n",
       "       'title_10', 'URL_og', 'number_og', 'title_og', 'author_og', 'pages_og',\n",
       "       'j_fix', 'scopus_jid', 'scopus_id', 'scopus_authorgroup',\n",
       "       'scopus_authors', 'scopus_affiliations', 'scopus_references',\n",
       "       'scopus_author_full_names', 'scopus_title', 'scopus_year',\n",
       "       'scopus_source_title', 'scopus_volume', 'scopus_issue', 'scopus_art_no',\n",
       "       'scopus_page_start', 'scopus_page_end', 'scopus_page_count',\n",
       "       'scopus_cited_by', 'scopus_doi', 'scopus_abstract', 'scopus_publisher',\n",
       "       'scopus_document_type', 'scopus_publication_stage',\n",
       "       'scopus_open_access', 'scopus_source', 'scopus_eid', 'scopus_title_og',\n",
       "       'scopus_volume_og', 'scopus_issue_og', 'scopus_page_start_og',\n",
       "       'scopus_page_end_og', 'scopus_year_og', 's_fix', 'scopus_pages',\n",
       "       'scopus_indicator', 'id', 'authors_lower', 'page_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_data.columns # verify headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "abce6603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62257"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(j_data[\"URL\"].unique()) #number of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1bac3d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['https://www.jstor.org/stable/10.2307/i27804949',\n",
       "        'Victoria Ivashina and David Scharfstein',\n",
       "        'loan syndication and credit cycles',\n",
       "        'The American Economic Review', 100, '2', '57-61', 2010, 28282,\n",
       "        nan, 'https://www.jstor.org/stable/27804963',\n",
       "        'American Economic Association', 'Article', 'S', 'aer', nan,\n",
       "        datetime.datetime(2023, 9, 4, 0, 0), nan, 1.0,\n",
       "        'Loan Syndication and Credit Cycles',\n",
       "        'https://www.jstor.org/stable/27804963', '2',\n",
       "        'Loan Syndication and Credit Cycles', nan, '57-61', 1.0, 'aer',\n",
       "        '10.1257/aer.100.2.57', True, True, True, True,\n",
       "        'Ivashina, Victoria (26323576100); Scharfstein, David (7003408304)',\n",
       "        'loan syndication and credit cycles', '2010',\n",
       "        'American Economic Review', '100', '2', nan, '57', '61', 4.0,\n",
       "        65.0, '10.1257/aer.100.2.57', '[No abstract available]', nan,\n",
       "        'Conference paper', 'Final', nan, 'Scopus', '2-s2.0-77956122893',\n",
       "        'Loan syndication and credit cycles', 100.0, '2', '57', '61',\n",
       "        2010.0, 0.0, '57-61', 0, '27804963',\n",
       "        'victoria ivashina and david scharfstein', 5.0]], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_data[j_data['URL']==\"https://www.jstor.org/stable/27804963\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d9571bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content_type\n",
       "Article       32678\n",
       "Review        13813\n",
       "MISC          12542\n",
       "Comment        1419\n",
       "Reply           832\n",
       "Discussion      742\n",
       "Rejoinder       153\n",
       "Errata           78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# must account for duplicates due to scopus duplication - scopus has one jstor to many scopus entries\n",
    "j_data[['content_type', 'URL']].drop_duplicates()['content_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fa3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4bf8759",
   "metadata": {},
   "source": [
    "## Create a restricted character set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "106a9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set=\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ,'.-\"\n",
    "chars=[*char_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443d65e",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7abcf1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles that do not matter\n",
    "auth_ad=[\n",
    "    \"c.p.a.\",\n",
    "    \"m.e.\",\n",
    "    \"m.d.\",\n",
    "    \"s.j.\", #society of jesus\n",
    "    \"s. j.\", #society of jesus\n",
    "    # \"wm.\",  #contraction of the given name William\n",
    "]\n",
    "\n",
    "# suffixes that matter for distinguishing authors\n",
    "auth_ad2=[\n",
    "    \"2nd\",\n",
    "    \"3rd\",\n",
    "    \"jr.\", #junior\n",
    "    \"yr.\" #misspelling of junior. Yordon case\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b9a441",
   "metadata": {},
   "source": [
    "## Resolve the JPE formatting issue\n",
    "\n",
    "Please generate the file using the code block at the end of the notebook and manually resolve the errors. Rename the file and run the next two codeblocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "09fcc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_base_path+'/jpe_problem_names.json') as f: \n",
    "    data = f.read() \n",
    "names_repl = json.loads(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d36643ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in j_data.index:\n",
    "    if j_data.loc[i, \"author\"] in names_repl.keys():\n",
    "         j_data.loc[i, \"author\"]=names_repl[j_data.loc[i, \"author\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c47de",
   "metadata": {},
   "source": [
    "## Resolve special characters outside ascii\n",
    "\n",
    "As above, generate the file using code at the end of the notebook. Or copy in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3f10ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_base_path+'/spec_char_replacement.json') as f: \n",
    "    data = f.read() \n",
    "js = json.loads(data) \n",
    "\n",
    "def replace_spec_chars(str_in):\n",
    "    hold=\"\"\n",
    "    for o in str_in:\n",
    "        if o.lower() in js.keys():\n",
    "            hold=hold+js[o.lower()]\n",
    "        else:\n",
    "            hold=hold+o\n",
    "    return hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f1d99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in j_data.index:\n",
    "    if pd.isna(j_data.loc[i, \"author\"])==False:\n",
    "        j_data.loc[i,'author']=re.sub('\\xa0',\" \",j_data.loc[i,'author'])\n",
    "        j_data.loc[i,'author']=re.sub(r'\\s+', \" \", j_data.loc[i,'author'])\n",
    "        if j_data.loc[i, \"author\"].isascii()==True:\n",
    "            continue\n",
    "        j_data.loc[i, \"author\"]=replace_spec_chars(j_data.loc[i,\"author\"])\n",
    "        if j_data.loc[i, \"author\"].isascii()==False:\n",
    "            print(j_data.loc[i, [\"author\",\"URL\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c891a99",
   "metadata": {},
   "source": [
    "Create a new column where all author names are split by \" and \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10abf607",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_data['author_split']=j_data['author'].str.split(\" and \")\n",
    "j_data['author_count']=j_data['author_split'].apply(lambda x: len(x) if isinstance(x, list) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63986c4",
   "metadata": {},
   "source": [
    "## Process author names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9dc7858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the aliases in lists for comparison later\n",
    "a1=[]\n",
    "a2=[]\n",
    "i1=[]\n",
    "ln=[]\n",
    "\n",
    "\n",
    "#function for creating aliases\n",
    "#todo annotate function\n",
    "def proc_auth(auth_str):\n",
    "#     print(auth_str)\n",
    "    suff=\"\"\n",
    "    auth_split=auth_str.split(\" \")\n",
    "    if \",\" in auth_str:\n",
    "        suff=\", \"+auth_str.split(\", \")[-1]\n",
    "        auth_split=auth_str.split(\",\")[0].split(\" \")\n",
    "        # print(suff)\n",
    "    check=0\n",
    "    for j in auth_split:\n",
    "        if \".\" in j:\n",
    "            check=check+1\n",
    "    if check==len(auth_split):\n",
    "        return [auth_str, auth_str, auth_str, auth_str, 0]\n",
    "    \n",
    "    if len(auth_split)>1:\n",
    "        init_auth=auth_split[0][0]+'. '+auth_split[-1]\n",
    "        alt_auth=\"\"\n",
    "        alt_2_auth=auth_split[0]+\" \"\n",
    "        if len(auth_split)>2:\n",
    "            for k in auth_split[1:-1]:\n",
    "                alt_2_auth+=k[0]+'. '\n",
    "        alt_2_auth+=auth_split[-1]\n",
    "        \n",
    "        \n",
    "        for k in auth_split[:-1]:\n",
    "            alt_auth+=k[0]+'. '\n",
    "        alt_auth+=auth_split[-1]\n",
    "        ln.append(auth_split[-1])\n",
    "        a1.append(alt_2_auth+suff)\n",
    "        a2.append(alt_auth+suff)\n",
    "        i1.append(init_auth+suff)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return [alt_2_auth, alt_auth, init_auth, auth_split[-1]]\n",
    "    else:\n",
    "         return[auth_str, auth_str, auth_str, auth_str, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "21ac1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in j_data.index:\n",
    "    authors=j_data.loc[i,\"author_split\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1559963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['qje', 'aer', 'ecta', 'jpe', 'res'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_data['jid'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a279f-fd1b-4dfc-84d5-9f0b4212309f",
   "metadata": {},
   "source": [
    "Note that there was a bug in the code below that has not resolved the case of authors having a designation like m.e. at the end of their name. This is resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ccd48233",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1\n",
    "all_authors=[]\n",
    "all_authors_a=[]\n",
    "autht=0\n",
    "proc_auths_all={}\n",
    "for i in j_data.index:\n",
    "    authors=j_data.loc[i,\"author_split\"]\n",
    "    proc_auths={\n",
    "                \"authors\":{}, \n",
    "                \"year\":j_data.loc[i,\"year\"], \n",
    "                'content_type':j_data.loc[i, \"content_type\"],\n",
    "                'jid':j_data.loc[i, \"jid\"]\n",
    "                }\n",
    "    if pd.isna(j_data.loc[i,\"author\"])==False:\n",
    "        for j in range(len(authors)):\n",
    "            sa=authors[j].lower()\n",
    "            all_authors_a.append(str(sa))\n",
    "            autht=autht+1\n",
    "\n",
    "            o=[]\n",
    "            \n",
    "            # remove the author titles that are not necessary if present\n",
    "            for k in auth_ad:\n",
    "                p=\", \"+k\n",
    "                if (p in sa):\n",
    "                    if 'yr' in p:\n",
    "                        print(sa)\n",
    "                    sa=re.sub(p,'',sa)\n",
    "                    # print(sa)\n",
    "                    break\n",
    "\n",
    "            # remove and store the suffixes of an author if present\n",
    "            for k in auth_ad2:\n",
    "                # print(\"case 2\")\n",
    "\n",
    "                r=\", \"+k\n",
    "                if r in sa[-len(r):]:\n",
    "                    # print(\"case 2.1\")\n",
    "                    o.append(k)\n",
    "                    sa=re.sub(r,'',sa)\n",
    "                    # print(sa)\n",
    "                    break\n",
    "                elif \" \"+k in sa[-len(\" \"+k):]:\n",
    "                    # print(\"case 2.2\")\n",
    "                    t1=sa.split(\" \"+k)\n",
    "                    sa=re.sub(\" \"+k,\"\",sa)\n",
    "                    # print(sa)\n",
    "                    o.append(k)\n",
    "                    break\n",
    "                    \n",
    "                        \n",
    "            if \",\" in sa:\n",
    "                reorg=sa.split(r\", \")\n",
    "                sa=reorg[1].strip()+ \" \"+ reorg[0].strip()\n",
    "           \n",
    "            all_authors.append(sa)\n",
    "            proc_auths[\"authors\"][j]={}\n",
    "            proc_auths[\"authors\"][j][\"raw\"]=authors[j]\n",
    "            proc_auths[\"authors\"][j][\"init\"]=sa\n",
    "            proc_auths[\"authors\"][j]['auth_suffix']=o\n",
    "            aliases=proc_auth(sa)\n",
    "            if len(aliases)==5:\n",
    "                k=1\n",
    "                # print(sa)\n",
    "                # print(j_data.loc[i,\"author\"])\n",
    "                # print(j_data.loc[i, \"URL\"])\n",
    "                # print(j_data.loc[i, \"year\"])\n",
    "                # print(j_data.loc[i, \"journal\"])\n",
    "\n",
    "            proc_auths[\"authors\"][j][\"a1\"]=aliases[0]\n",
    "            proc_auths[\"authors\"][j][\"a2\"]=aliases[1]\n",
    "            proc_auths[\"authors\"][j][\"a3\"]=aliases[2]\n",
    "\n",
    "            if (\"[\" in sa) or (\"(\" in sa):\n",
    "                k=1\n",
    "                # print(sa)\n",
    "                # print(j_data.loc[i,\"author\"])\n",
    "                # print(j_data.loc[i, \"year\"])\n",
    "                # print(j_data.loc[i, \"journal\"])\n",
    "                # print(j_data.loc[i, \"URL\"])\n",
    "\n",
    "    else:\n",
    "        a=a+1\n",
    "    proc_auths_all[j_data.loc[i,\"URL\"]]=proc_auths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dca98c",
   "metadata": {},
   "source": [
    "## Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da83634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(output_base_path+\"/020_author_proc.json\", \"w\") as outfile: \n",
    "    json.dump(proc_auths_all, outfile, indent=4, default=int)\n",
    "\n",
    "j_data.to_pickle(output_base_path+\"/020_merged_proc_scopus_inception_with_auth_split_2020.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "563f52dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['issue_url', 'author', 'title', 'journal', 'volume', 'number', 'pages',\n",
       "       'year', 'ISSN', 'abstract', 'URL', 'publisher', 'content_type', 'type',\n",
       "       'jid', 'author_split', 'urldate', 'reviewed-author', 'uploaded',\n",
       "       'title_10', 'URL_og', 'number_og', 'title_og', 'author_og', 'pages_og',\n",
       "       'j_fix', 'scopus_jid', 'scopus_id', 'scopus_authorgroup',\n",
       "       'scopus_authors', 'scopus_affiliations', 'scopus_references',\n",
       "       'scopus_author_full_names', 'scopus_title', 'scopus_year',\n",
       "       'scopus_source_title', 'scopus_volume', 'scopus_issue', 'scopus_art_no',\n",
       "       'scopus_page_start', 'scopus_page_end', 'scopus_page_count',\n",
       "       'scopus_cited_by', 'scopus_doi', 'scopus_abstract', 'scopus_publisher',\n",
       "       'scopus_document_type', 'scopus_publication_stage',\n",
       "       'scopus_open_access', 'scopus_source', 'scopus_eid', 'scopus_title_og',\n",
       "       'scopus_volume_og', 'scopus_issue_og', 'scopus_page_start_og',\n",
       "       'scopus_page_end_og', 'scopus_year_og', 's_fix', 'scopus_pages',\n",
       "       'scopus_indicator', 'id', 'authors_lower', 'page_count',\n",
       "       'author_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560836f",
   "metadata": {},
   "source": [
    "## Compute some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e8750d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_summary=[]\n",
    "auth_t=list(set(all_authors_a))\n",
    "u_auth=list(set(all_authors))\n",
    "u_a1=list(set(a1))\n",
    "u_a2=list(set(a2))\n",
    "u_a3=list(set(i1))\n",
    "u_ln=list(set(ln))\n",
    "auth_summary.append({\"description\":\"The total number of authors\", \"total\": len(all_authors)})\n",
    "auth_summary.append({\"description\":\"The number of unique author names without editing\", \"total\":  len(auth_t)})\n",
    "auth_summary.append({\"description\":\"The number of unique author names after initial processing\", \"total\":  len(u_auth)})\n",
    "auth_summary.append({\"description\":\"Unique alias 1 type names (contracted middle names + last name)\", \"total\":  len(u_a1)})\n",
    "auth_summary.append({\"description\":\"Unique alias 2 type names (contracted first names + last name)\", \"total\":  len(u_a2)})\n",
    "auth_summary.append({\"description\":\"Unique alias 3 type names (contracted first name + last name)\", \"total\":  len(u_a3)})\n",
    "auth_summary.append({\"description\":\"Unique last names\", \"total\":  len(u_ln)})\n",
    "\n",
    "pd.DataFrame(auth_summary).to_csv(output_base_path+\"/summary_author_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf569c6",
   "metadata": {},
   "source": [
    "# NO SIGNIFICANT OUTPUT AFTER THIS POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26e763-1494-4766-a47f-6abfbbe04e19",
   "metadata": {},
   "source": [
    "## Computing similarity to find duplicates\n",
    "Methodology with 20000 names, we can precommpile the set of potential names using last names and first names as a way to determine duplicates. \n",
    "1. allocate authors to a dictionary by last names.\n",
    "2. Function by process of elimination. Assumption: first letter of last name and first letter of first name will always be correct.\n",
    "3. format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea80a76-c1c6-4768-87e9-6305f66927a6",
   "metadata": {},
   "source": [
    "# Three cases of ambiguity:\n",
    "\n",
    "1. same name, different person\n",
    "   - is in same time period -> require affiliations\n",
    "   - not in same time period -> resolve with significant significant publishing year barrier\n",
    "2. similar name or alias, same person\n",
    "   - has multiple resolution from no middle name to has middle name: require affiliations\n",
    "   - spelling error possibilities. Direct correction in data - require research on individual articles for resolution, restricted to this data set only\n",
    "3. has multiple resolutions from contraction: require affiliations\n",
    "   - generate list of contractions and associated possibilities if full name exists\n",
    "   - modify by \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0532fb",
   "metadata": {},
   "source": [
    "## Top 20 Author Output Ranked for all time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c513a3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   \n",
       "frank h. knight         113\n",
       "george j. stigler        95\n",
       "a. b. wolfe              92\n",
       "paul a. samuelson        91\n",
       "daron acemoglu           85\n",
       "f. w. taussig            84\n",
       "william j. baumol        83\n",
       "m. bronfenbrenner        81\n",
       "j. m. clark              79\n",
       "jean tirole              77\n",
       "joseph e. stiglitz       75\n",
       "paul h. douglas          71\n",
       "h. parker willis         68\n",
       "wesley c. mitchell       67\n",
       "milton friedman          66\n",
       "franklin m. fisher       64\n",
       "harry g. johnson         63\n",
       "t. n. carver             60\n",
       "chester w. wright        57\n",
       "j. laurence laughlin     57\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after initial process\n",
    "pd.DataFrame(all_authors).value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1228bc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 \n",
       "frank h. knight       113\n",
       "george j. stigler      95\n",
       "a. b. wolfe            92\n",
       "paul a. samuelson      91\n",
       "j. m. clark            88\n",
       "daron acemoglu         85\n",
       "f. w. taussig          84\n",
       "william j. baumol      83\n",
       "m. bronfenbrenner      81\n",
       "jean tirole            77\n",
       "joseph e. stiglitz     75\n",
       "paul h. douglas        71\n",
       "h. p. willis           70\n",
       "wesley c. mitchell     67\n",
       "milton friedman        66\n",
       "franklin m. fisher     64\n",
       "harry g. johnson       63\n",
       "frank a. fetter        60\n",
       "t. n. carver           60\n",
       "chester w. wright      58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using a1\n",
    "pd.DataFrame(a1).value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ea7b09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                \n",
       "f. h. knight         133\n",
       "m. bronfenbrenner    101\n",
       "j. m. clark           97\n",
       "p. a. samuelson       96\n",
       "g. j. stigler         95\n",
       "a. b. wolfe           94\n",
       "w. j. baumol          90\n",
       "f. w. taussig         86\n",
       "j. e. stiglitz        86\n",
       "d. acemoglu           85\n",
       "j. tirole             77\n",
       "w. c. mitchell        75\n",
       "h. p. willis          74\n",
       "p. h. douglas         73\n",
       "f. m. fisher          66\n",
       "m. friedman           66\n",
       "a. p. lerner          65\n",
       "t. n. carver          64\n",
       "f. a. fetter          63\n",
       "h. g. johnson         63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using a2\n",
    "pd.DataFrame(a2).value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6e3cdaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                \n",
       "f. knight            133\n",
       "j. clark             112\n",
       "f. fetter            111\n",
       "r. gordon            101\n",
       "m. bronfenbrenner    101\n",
       "j. stiglitz           98\n",
       "p. samuelson          98\n",
       "g. stigler            97\n",
       "a. wolfe              94\n",
       "w. baumol             92\n",
       "f. taussig            86\n",
       "d. acemoglu           85\n",
       "w. mitchell           83\n",
       "m. feldstein          78\n",
       "j. tirole             77\n",
       "h. willis             74\n",
       "v. smith              74\n",
       "p. douglas            74\n",
       "j. robinson           73\n",
       "c. wright             71\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using a3\n",
    "pd.DataFrame(i1).value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb57a0",
   "metadata": {},
   "source": [
    "## Frequency of Authors scale of output for all time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c731918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurences</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 &lt; x &lt;= 1</td>\n",
       "      <td>12658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 &lt; x &lt;= 2</td>\n",
       "      <td>3595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 &lt; x &lt;= 5</td>\n",
       "      <td>3452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 &lt; x &lt;= 10</td>\n",
       "      <td>1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 &lt; x &lt;= 50</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50 &lt; x &lt;= 100</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100 &lt; x &lt;= 200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200 &lt; x &lt;= 1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        occurences  number\n",
       "0       0 < x <= 1   12658\n",
       "1       1 < x <= 2    3595\n",
       "2       2 < x <= 5    3452\n",
       "3      5 < x <= 10    1614\n",
       "4     10 < x <= 50    1177\n",
       "5    50 < x <= 100      33\n",
       "6   100 < x <= 200       1\n",
       "7  200 < x <= 1000       0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after initial processing\n",
    "summary=[]\n",
    "seq=[0,1,2,5,10,50,100,200,1000]\n",
    "nms=pd.DataFrame(pd.DataFrame(all_authors).value_counts()).reset_index()\n",
    "for i in range(len(seq)-1):\n",
    "#     print(\"between \"+str(seq[i])+\" exclusive and \"+str(seq[i+1])+ \" inclusive\")\n",
    "#     print(nms[(nms[\"count\"]<=seq[i+1])&(nms[\"count\"]>seq[i])].shape[0])\n",
    "    summary.append({\"occurences\":str(seq[i])+\" < x <= \"+str(seq[i+1]), \"number\":nms[(nms[\"count\"]<=seq[i+1])&(nms[\"count\"]>seq[i])].shape[0]})\n",
    "    \n",
    "pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "41d1a9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurences</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 &lt; x &lt;= 1</td>\n",
       "      <td>8662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 &lt; x &lt;= 2</td>\n",
       "      <td>2838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 &lt; x &lt;= 5</td>\n",
       "      <td>3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 &lt; x &lt;= 10</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 &lt; x &lt;= 50</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50 &lt; x &lt;= 100</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100 &lt; x &lt;= 200</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200 &lt; x &lt;= 1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        occurences  number\n",
       "0       0 < x <= 1    8662\n",
       "1       1 < x <= 2    2838\n",
       "2       2 < x <= 5    3139\n",
       "3      5 < x <= 10    1641\n",
       "4     10 < x <= 50    1374\n",
       "5    50 < x <= 100      44\n",
       "6   100 < x <= 200       5\n",
       "7  200 < x <= 1000       0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first initial + last name\n",
    "summary=[]\n",
    "seq=[0,1,2,5,10,50,100,200,1000]\n",
    "nms=pd.DataFrame(pd.DataFrame(i1).value_counts()).reset_index()\n",
    "for i in range(len(seq)-1):\n",
    "#     print(\"between \"+str(seq[i])+\" exclusive and \"+str(seq[i+1])+ \" inclusive\")\n",
    "#     print(nms[(nms[\"count\"]<=seq[i+1])&(nms[\"count\"]>seq[i])].shape[0])\n",
    "    summary.append({\"occurences\":str(seq[i])+\" < x <= \"+str(seq[i+1]), \"number\":nms[(nms[\"count\"]<=seq[i+1])&(nms[\"count\"]>seq[i])].shape[0]})\n",
    "    \n",
    "pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e5e9f2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between 0 exclusive and 1 inclusive\n",
      "10725\n",
      "between 1 exclusive and 2 inclusive\n",
      "3251\n",
      "between 2 exclusive and 5 inclusive\n",
      "3351\n",
      "between 5 exclusive and 10 inclusive\n",
      "1640\n",
      "between 10 exclusive and 50 inclusive\n",
      "1257\n",
      "between 50 exclusive and 100 inclusive\n",
      "39\n",
      "between 100 exclusive and 200 inclusive\n",
      "2\n",
      "between 200 exclusive and 1000 inclusive\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurences</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 &lt; x &lt;= 1</td>\n",
       "      <td>10725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 &lt; x &lt;= 2</td>\n",
       "      <td>3251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 &lt; x &lt;= 5</td>\n",
       "      <td>3351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 &lt; x &lt;= 10</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 &lt; x &lt;= 50</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50 &lt; x &lt;= 100</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100 &lt; x &lt;= 200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200 &lt; x &lt;= 1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        occurences  number\n",
       "0       0 < x <= 1   10725\n",
       "1       1 < x <= 2    3251\n",
       "2       2 < x <= 5    3351\n",
       "3      5 < x <= 10    1640\n",
       "4     10 < x <= 50    1257\n",
       "5    50 < x <= 100      39\n",
       "6   100 < x <= 200       2\n",
       "7  200 < x <= 1000       0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initials and last name\n",
    "summary=[]\n",
    "seq=[0,1,2,5,10,50,100,200,1000]\n",
    "nms=pd.DataFrame(pd.DataFrame(a2).value_counts()).reset_index()\n",
    "for i in range(len(seq)-1):\n",
    "    print(\"between \"+str(seq[i])+\" exclusive and \"+str(seq[i+1])+ \" inclusive\")\n",
    "    print(nms[(nms[\"count\"]<=seq[i+1])&(nms[\"count\"]>seq[i])].shape[0])\n",
    "    summary.append({\"occurences\":str(seq[i])+\" < x <= \"+str(seq[i+1]), \"number\":nms[(nms[\"count\"]<=seq[i+1])&(nms[\"count\"]>seq[i])].shape[0]})\n",
    "    \n",
    "pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de603ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurences</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 &lt; x &lt;= 1</td>\n",
       "      <td>12285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 &lt; x &lt;= 2</td>\n",
       "      <td>3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 &lt; x &lt;= 5</td>\n",
       "      <td>3419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 &lt; x &lt;= 10</td>\n",
       "      <td>1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 &lt; x &lt;= 50</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50 &lt; x &lt;= 100</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100 &lt; x &lt;= 200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200 &lt; x &lt;= 1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        occurences  number\n",
       "0       0 < x <= 1   12285\n",
       "1       1 < x <= 2    3536\n",
       "2       2 < x <= 5    3419\n",
       "3      5 < x <= 10    1621\n",
       "4     10 < x <= 50    1193\n",
       "5    50 < x <= 100      34\n",
       "6   100 < x <= 200       1\n",
       "7  200 < x <= 1000       0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contracted middle names\n",
    "summary=[]\n",
    "seq=[0,1,2,5,10,50,100,200,1000]\n",
    "nms=pd.DataFrame(pd.DataFrame(a1).value_counts()).reset_index()\n",
    "for i in range(len(seq)-1):\n",
    "#     print(\"between \"+str(seq[i])+\" exclusive and \"+str(seq[i+1])+ \" inclusive\")\n",
    "#     print(nms[(nms[\"count\"]<=seq[i+1])&(nms[\"count\"]>seq[i])].shape[0])\n",
    "    summary.append({\"occurences\":str(seq[i])+\" < x <= \"+str(seq[i+1]), \"number\":nms[(nms[\"count\"]<=seq[i+1])&(nms[\"count\"]>seq[i])].shape[0]})\n",
    "    \n",
    "pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aca1e8-b3c4-4775-904d-e7b3284babf4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e4272-eeb0-4682-a8d5-06553c782265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4ccdb-7f27-4b85-96d3-21212723d43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d892",
   "metadata": {},
   "source": [
    "## Resolving problem names for JPE\n",
    "\n",
    "It is just read in above but this is how it should be generated if the file above is not applied to the variable j_data. They are printed to a json file with a unique timestamp please resolve each name, using the URLs below to check for the author name on the article page if the names were cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0ff983a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff={}\n",
    "# for i in j_data.index:\n",
    "#     authors=j_data.loc[i,\"author\"]\n",
    "#     if authors is not np.NaN:\n",
    "#         sa=authors.lower()\n",
    "#         if (\"{\" in sa) or (\"\\\\\" in sa):\n",
    "#             print(j_data.loc[i,\"author\"])\n",
    "#             print(j_data.loc[i, \"URL\"])\n",
    "#             stuff[j_data.loc[i, \"author\"]]=j_data.loc[i, \"author\"]\n",
    "#             print()\n",
    "\n",
    "# with open(output_base_path+\"/jpe_problem_names_\"+str(time.time())+\".json\", \"w\") as outfile: \n",
    "#     json.dump(stuff, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc189a8a",
   "metadata": {},
   "source": [
    "## Resolving special characters\n",
    "\n",
    "Todo: optimize this code.\n",
    "As above, add in the the unresolvable characters directly in the file and rename it to match the file name above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "91a04e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_char_set={}\n",
    "\n",
    "# spec_chars=[]\n",
    "# def process_string(str_in):\n",
    "#     if str_in.isascii()==True:\n",
    "#         return str_in\n",
    "#     hold=\"\"\n",
    "#     for o in str_in:\n",
    "#         if o.isascii()==False:\n",
    "#             spec_chars.append(o)\n",
    "#             print(str_in)\n",
    "\n",
    "# for i in j_data.index:\n",
    "#     authors=j_data.loc[i,\"author\"]\n",
    "#     if authors is not np.NaN:\n",
    "#         sa=authors.lower()\n",
    "#         process_string(sa)\n",
    "        \n",
    "# u_spec_chars=list(set(spec_chars))\n",
    "# u_spec_chars.sort()\n",
    "\n",
    "# for o in u_spec_chars:\n",
    "#     spec_char_set[o]=unicodedata.normalize(\"NFKD\", o).encode('ascii', 'ignore').decode('utf-8')\n",
    "#     if len(spec_char_set[o])==0:\n",
    "#         print(o)\n",
    "        \n",
    "# print(\"end\")\n",
    "        \n",
    "# with open(output_base_path+\"/spec_char_replacement_\"+str(time.time())+\".json\", \"w\") as outfile: \n",
    "#     json.dump(spec_char_set, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1287d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
