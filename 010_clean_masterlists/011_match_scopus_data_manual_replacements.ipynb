{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## This section aims to match up Scopus records and Jstor articles\n",
    "If an article's affiliations, citations or abstracts are recorded on Scopus, I want to exclude them from the set of pdf's that are sent to docParser. Matching up the Scopus data is also useful for comparing the textual accuracy of OCR parsers.\n",
    "\n",
    "1. An exact match is if title, year, issue, pages and journal names match. \n",
    "2. A direct match is if it is explicitly matched from the scopus id to the jstor id via a manually compiled dictionary\n",
    "3. An approximate match is if the jstor and scopus titles fuzzy match with atleast a 95 % score, the first listed author has a fuzzy match of atleast 95 % and year, issue, pages and journal names match\n",
    "\n",
    "If the matching algorithm does not produce an approximate match that satisfies the criteria in 3., then the algorithm records the best match according to title similarity which one is expected to use to check for errors against the scopus or jstor metadata. I use this best match list to:\n",
    "- Resolve errors in page numbering, assigned year, trivial title errors or issue numbers in the scopus data and jstor data\n",
    "- Compile a list of scopus ids to exclude that are not in top 5 or have erroneous data - each scopus id on this list has a documented reason for its exclusion\n",
    "- Compile a list for 2. because 3 and 1 would fail. The case occurs if either jstor or scopus are missing author names for the entry. This usually occurs with scopus data, in which case it is not feasable to fill this in because there is an associated author id.\n",
    "- Compile a list of scopus ids that match to miscellaneous articles for exclusion. I don't expect to analyze miscellaneous articles, they also often lack the author or are trivial e.g. a back matter. Reports by committee members and publisher originated content count as miscellaneous as for jstor articles but errata and corrections are not considered miscellaneous.\n",
    "- Compile a list of cases where many scopus ids are assigned to the same jstor article and many jstor articles are assigned to the same scopus id. The latter is usually an error and gets added to the exclusion list.\n",
    "\n",
    "This reconciliation is compiled in a json file called scopus_recon.json. The two largest correction categories are the title field and the pages field in both datasets, I correct whichever dataset entry is incorrect after googling so that as many cases as possible are adjusted to an exact match. \n",
    "\n",
    "Why not match the scopus id and jstor id/doi directly? The scopus id is often the DOI of the article. And for older articles, the jstor url id is recorded as the doi. However, scopus occasionally gets assigns the wrong data (title, author, pages, references etc.) to an unrelated DOI hence we cannot assume scopus ids match DOI/Jstor ids.\n",
    "\n",
    "\n",
    "### Reasons for page differences:\n",
    "- scopus is off by 1 or 2 pages because there is an extra blank page in the journal that scopus counts but jstor does not.\n",
    "- scopus is off because it doesn't count the first page of the paper because it did not have a page number on it.\n",
    "- scopus forgot to count the last page or cuts off early leaving off the reference list or lists the appendix separately.\n",
    "- scopus if off by a page\n",
    "- scopus has two articles erroneously assigned to the same doi/entry on it's records. the references of the two articles are also combined together to imply the same article. \n",
    "\n",
    "- jstor is off by 1 page because it does not count the first page which given a title page does not have a page number on it\n",
    "- jstor actually has two articles erroneously assigned to the same article eg: the comment and it's reply but indexes the article by only the author of the first and second articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher as sq\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import datetime\n",
    "import pickle\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/sijiawu/Work/Thesis/Data\"\n",
    "\n",
    "jid=[\"aer\", 'ecta', 'jpe', 'res', 'qje']\n",
    "cleaned={}\n",
    "\n",
    "for i in jid:\n",
    "    # print(i)\n",
    "    cleaned[i]=pd.read_excel(base_path+'/Processed/'+i.upper()+'_processed.xlsx')\n",
    "    # print(j_data[i].dtypes)\n",
    "    cleaned[i]['volume']=cleaned[i]['volume'].astype(int)\n",
    "    cleaned[i]['year']=cleaned[i]['year'].astype(int)\n",
    "    cleaned[i]['pages']=cleaned[i]['pages'].str.strip()\n",
    "    cleaned[i]['number']=cleaned[i]['number'].astype(str).str.strip()\n",
    "    cleaned[i]=cleaned[i].drop_duplicates(subset=['URL'], keep=\"last\").reset_index(drop=True)\n",
    "    cleaned[i]['jid']=i\n",
    "\n",
    "\n",
    "scopus_base = pd.read_excel(base_path+'/SCOPUS/api_output/scopus_all.xlsx')\n",
    "cleaned=pd.concat(cleaned.values()).reset_index(drop=True)\n",
    "\n",
    "scopus_base['scopus_title_og']=scopus_base['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cleaned=[\n",
    "{   'issue_url':'https://academic.oup.com//qje/issue/135/3',\n",
    "    'author':\"Enke, Benjamin\",\n",
    "    'title' :'What You See Is All There Is*',\n",
    "    'journal' :\"The Quarterly Journal of Economics\",\n",
    "    'volume' :'135',\n",
    "    'number' :'3',\n",
    "    'pages' :'1363-1398',\n",
    "    'year' :'2020',\n",
    "    'ISSN' :'0033-5533',\n",
    "    'abstract' :\"News reports and communication are inherently constrained by space, time, and attention. As a result, news sources often condition the decision of whether to share a piece of information on the similarity between the signal and the prior belief of the audience, which generates a sample selection problem. This article experimentally studies how people form beliefs in these contexts, in particular the mechanisms behind errors in statistical reasoning. I document that a substantial fraction of experimental participants follows a simple “what you see is all there is” heuristic, according to which participants exclusively consider information that is right in front of them, and directly use the sample mean to estimate the population mean. A series of treatments aimed at identifying mechanisms suggests that for many participants, unobserved signals do not even come to mind. I provide causal evidence that the frequency of such incorrect mental models is a function of the computational complexity of the decision problem. These results point to the context dependence of what comes to mind and the resulting errors in belief updating.\",\n",
    "    \"URL\" :\"https://doi.org/10.1093/qje/qjaa012\",\n",
    "    \"publisher\":\"Oxford University Press\",\n",
    "    'content_type':'Article',\n",
    "    'type':'N',\n",
    "    'jid':'qje',\n",
    "    'author_split':\"['Enke, Benjamin']\"\n",
    "}]\n",
    "cleaned=pd.concat([pd.DataFrame(missing_cleaned),cleaned]).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the JSON file\n",
    "with open('scopus_recon.json', 'r') as file:\n",
    "    recon_scopus = json.load(file)\n",
    "\n",
    "s_fix=recon_scopus['scopus_fix'] #done\n",
    "ignore_misc_scopus_ids=recon_scopus['ignore_misc'] #done\n",
    "scopus_exclusion=recon_scopus['scopus_exclusion'].keys() #done\n",
    "match_direct=recon_scopus['match_direct'] #done\n",
    "msoj=recon_scopus['ManyScoToOneJstor'] #\n",
    "mjos=recon_scopus['ManyJstorToOneSco'] #\n",
    "fix_cleaned=recon_scopus['fix_cleaned_jstor'] #done\n",
    "\n",
    "many_match=list(set(list(mjos.keys())+sum(msoj.values(),[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create originals for comparison\n",
    "for i in ['Volume', 'Issue', 'Page start', 'Page end', 'Title', 'Year']:\n",
    "    scopus_base['scopus_'+i.lower().replace(' ','_')+'_og']=scopus_base[i]\n",
    "\n",
    "for i in ['URL', 'number', 'title', 'author', 'pages']:\n",
    "    cleaned[i+'_og']=cleaned[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/5mt219qj6l552yrf3l89xgdh0000gn/T/ipykernel_32947/2998217743.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2015' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  scopus_base.loc[scopus_base['scopus_id']==i['scopus_id'], j]=i[j]\n"
     ]
    }
   ],
   "source": [
    "scopus_base['s_fix']=0\n",
    "for i in s_fix:\n",
    "    for j in i.keys():\n",
    "        if (j!='scopus_id'):\n",
    "            scopus_base.loc[scopus_base['scopus_id']==i['scopus_id'], j]=i[j]\n",
    "    scopus_base.loc[scopus_base['scopus_id']==i['scopus_id'], 's_fix']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_var(df, field):\n",
    "    df[field]=df[field].astype(str)\n",
    "    for i in df.index:\n",
    "        if df.loc[i, field]=='nan':\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                df.loc[i, field]=str(int(float(df.loc[i, field]))).strip()\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                df.loc[i, field]=str(df.loc[i, field]).strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cleaned.index:\n",
    "    if pd.isna(cleaned.loc[i, 'pages'])==True:\n",
    "        continue\n",
    "    if cleaned.loc[i, 'pages'][0:3]==\"p. \":\n",
    "        cleaned.loc[i, 'pages']=cleaned.loc[i, 'pages'][3:]\n",
    "\n",
    "proc_var(cleaned,'year')\n",
    "proc_var(cleaned, 'pages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_var(scopus_base,'Volume')\n",
    "proc_var(scopus_base,'Year')\n",
    "proc_var(scopus_base,'Issue')\n",
    "proc_var(scopus_base,'Page start')\n",
    "proc_var(scopus_base,'Page end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pages\n"
     ]
    }
   ],
   "source": [
    "scopus_base['scopus_pages']='nan'\n",
    "for i in scopus_base.index:\n",
    "    if scopus_base.loc[i,\"Page end\"].lower().strip()==\"nan\":\n",
    "        if scopus_base.loc[i, \"Page start\"]==\"nan\":\n",
    "            print(\"No pages\")\n",
    "        else:\n",
    "            scopus_base.loc[i, \"scopus_pages\"]=scopus_base.loc[i,\"Page start\"].lower().strip()\n",
    "    else:\n",
    "        if scopus_base.loc[i, \"Page start\"].lower().strip()==scopus_base.loc[i,\"Page end\"].lower().strip():\n",
    "            scopus_base.loc[i, \"scopus_pages\"]=str(scopus_base.loc[i, \"Page start\"]).lower().strip()\n",
    "        else:\n",
    "            scopus_base.loc[i, \"scopus_pages\"]=(str(scopus_base.loc[i, \"Page start\"]).lower()+\"-\"+str(scopus_base.loc[i,\"Page end\"]).lower()).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_scopus={\n",
    " 'jid': 'scopus_jid',\n",
    " 'scopus_id': 'scopus_id',\n",
    " 'authorgroup': 'scopus_authorgroup',\n",
    " 'authors': 'scopus_authors',\n",
    " 'affiliations': 'scopus_affiliations',\n",
    " 'references': 'scopus_references',\n",
    " 'Author full names': 'scopus_author_full_names',\n",
    " 'Title': 'scopus_title',\n",
    " 'Year': 'scopus_year',\n",
    " 'Source title': 'scopus_source_title',\n",
    " 'Volume': 'scopus_volume',\n",
    " 'Issue': 'scopus_issue',\n",
    " 'Art. No.': 'scopus_art_no',\n",
    " 'Page start': 'scopus_page_start',\n",
    " 'Page end': 'scopus_page_end',\n",
    " 'Page count': 'scopus_page_count',\n",
    " 'Cited by': 'scopus_cited_by',\n",
    " 'DOI': 'scopus_doi',\n",
    " 'Abstract': 'scopus_abstract',\n",
    " 'Publisher': 'scopus_publisher',\n",
    " 'Document Type': 'scopus_document_type',\n",
    " 'Publication Stage': 'scopus_publication_stage',\n",
    " 'Open Access': 'scopus_open_access',\n",
    " 'Source': 'scopus_source',\n",
    " 'EID': 'scopus_eid'\n",
    "}\n",
    "\n",
    "scopus_base = scopus_base.rename(columns=rename_scopus)\n",
    "\n",
    "scopus_base['scopus_title']=scopus_base['scopus_title'].str.lower().str.strip().str.replace('‘',\"'\").str.replace('’',\"'\").str.replace('\"',\"'\").str.replace('–','-').str.replace('‐','-').str.replace('™','').str.replace('- ','-').str.replace(' -','-').str.replace('“',\"'\").str.replace(\"*\",\"\").str.replace('”',\"'\").str.replace('behaviour','behavior').str.strip()\n",
    "scopus_base['scopus_title']=scopus_base['scopus_title'].str.strip().str.split().apply(' '.join).str.strip()\n",
    "for i in scopus_base.index:\n",
    "    if '†' in scopus_base.loc[i, 'scopus_title']:\n",
    "        scopus_base.loc[i, 'scopus_title']=scopus_base.loc[i, 'scopus_title'].strip()[:-1].strip()\n",
    "    if scopus_base.loc[i, 'scopus_title'].strip()[-1]==\".\":\n",
    "        scopus_base.loc[i, 'scopus_title']=scopus_base.loc[i, 'scopus_title'].strip()[:-1].strip()\n",
    "\n",
    "\n",
    "cleaned['title']=cleaned['title'].str.lower().str.strip().str.replace('‘',\"'\").str.replace('’',\"'\").str.replace('\"',\"'\").str.replace('–','-').str.replace('‐','-').str.replace('™','').str.replace('- ','-').str.replace(' -','-').str.replace('“',\"'\").str.replace('”',\"'\").str.replace(\"*\",\"\").str.replace('behaviour','behavior').str.strip()\n",
    "cleaned['title']=cleaned['title'].str.strip().str.split().apply(' '.join).str.strip()\n",
    "for i in cleaned.index:\n",
    "    if '†' in cleaned.loc[i, 'title']:\n",
    "        cleaned.loc[i, 'title']=cleaned.loc[i, 'title'].strip()[:-1].strip()\n",
    "    if str(cleaned.loc[i, 'title']).strip()[-1]==\".\":\n",
    "        cleaned.loc[i, 'title']=cleaned.loc[i, 'title'].strip()[:-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.loc[cleaned[\"number\"]==datetime.datetime(2023, 5, 6, 0, 0),'number']='5-6'\n",
    "cleaned.loc[cleaned[\"number\"]==datetime.datetime(2023, 3, 4, 0, 0),'number']='3-4'\n",
    "cleaned.loc[cleaned[\"number\"]==datetime.datetime(2023, 1, 2, 0, 0),'number']='1-2'\n",
    "\n",
    "\n",
    "cleaned['j_fix']=0\n",
    "for i in fix_cleaned:\n",
    "    for j in i.keys():\n",
    "        if j!='URL':\n",
    "            cleaned.loc[cleaned['URL']==i['URL'],j]=i[j]\n",
    "    cleaned.loc[cleaned['URL']==i['URL'], 'j_fix']=1\n",
    "\n",
    "\n",
    "cleaned['title']=cleaned['title'].str.lower()\n",
    "scopus_base['scopus_title']=scopus_base['scopus_title'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus_base.loc[scopus_base['scopus_issue']=='5 Part 2', 'scopus_issue']='5'\n",
    "scopus_base.loc[scopus_base['scopus_issue']=='5 Part 1', 'scopus_issue']='5'\n",
    "scopus_base.loc[scopus_base['scopus_issue']=='6 PART 1', 'scopus_issue']='6'\n",
    "scopus_base.loc[scopus_base['scopus_issue']=='6 PART 2', 'scopus_issue']='6'\n",
    "\n",
    "cleaned.loc[cleaned['number']=='2023-05-06 00:00:00', 'number']='5-6'\n",
    "cleaned.loc[cleaned['number']=='2023-03-04 00:00:00', 'number']='3-4'\n",
    "cleaned.loc[cleaned['number']=='2023-01-02 00:00:00', 'number']='1-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15653, 33)\n",
      "(828, 33)\n",
      "(164, 33)\n",
      "(44, 33)\n",
      "(45, 33)\n",
      "(45, 33)\n",
      "(14527, 33)\n"
     ]
    }
   ],
   "source": [
    "#discard scopus titles that are post 2020\n",
    "year_range=[]\n",
    "for i in range(1940,2021):\n",
    "    year_range.append(str(i))\n",
    "\n",
    "ex_years=['2021', '2022', '2023', '2024']\n",
    "\n",
    "scopus_plus=scopus_base[(scopus_base[\"scopus_year\"].isin(ex_years)==True)].reset_index(drop=True)\n",
    "scopus_ignore=scopus_base[(scopus_base[\"scopus_year\"].isin(ex_years)==False)&(scopus_base[\"scopus_id\"].isin(ignore_misc_scopus_ids)==True)].reset_index(drop=True)\n",
    "scopus_wrong=scopus_base[(scopus_base['scopus_id'].isin(scopus_exclusion)==True)].reset_index(drop=True)\n",
    "scopus_many=scopus_base[(scopus_base['scopus_id'].isin(many_match)==True)].reset_index(drop=True)\n",
    "scopus_direct=scopus_base[scopus_base['scopus_id'].isin(list(match_direct.values()))].reset_index(drop=True)\n",
    "scopus=scopus_base[(scopus_base[\"scopus_year\"].isin(ex_years)==False)&(scopus_base['scopus_id'].isin(list(match_direct.values()))==False)&(scopus_base['scopus_id'].isin(many_match)==False)&(scopus_base[\"scopus_id\"].isin(ignore_misc_scopus_ids)==False)&(scopus_base['scopus_id'].isin(scopus_exclusion)==False)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(scopus_base.shape)\n",
    "\n",
    "print(scopus_plus.shape)\n",
    "print(scopus_ignore.shape)\n",
    "print(scopus_wrong.shape)\n",
    "print(scopus_many.shape)\n",
    "print(scopus_direct.shape)\n",
    "print(scopus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15613"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "828+164+14577+44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=pd.merge(cleaned, scopus, how='left', left_on=['title', 'year', 'jid','number','pages'], right_on=['scopus_title', 'scopus_year', 'scopus_jid', 'scopus_issue','scopus_pages']).reset_index(drop=True)\n",
    "\n",
    "#indicator for whether the merge was automatic on relavant fields '0' or because of approximate matches '1' \n",
    "merged[\"scopus_indicator\"]=0\n",
    "\n",
    "for item in match_direct.keys():\n",
    "    target=scopus_direct[scopus_direct['scopus_id']==match_direct[item]]\n",
    "    for j in scopus_direct.columns:\n",
    "        merged.loc[merged['URL']==item,j]=target[j].values[0]\n",
    "        # print(target[j].values[0])\n",
    "    merged.loc[merged['URL']==item, 'scopus_indicator']=2\n",
    "\n",
    "\n",
    "m_add=[]\n",
    "j_fields=['title_10', 'abstract', 'year', 'pages_og', 'content_type', 'volume', 'urldate', 'number', 'URL', 'author', 'author_og', 'type', 'ISSN', 'scopus_indicator', 'journal', 'title_og', 'publisher', 'number_og', 'pages', 'issue_url', 'reviewed-author', 'author_split', 'uploaded', 'jid', 'title', 'URL_og']\n",
    "for i in mjos:\n",
    "    # print(i)\n",
    "    for j in mjos[i]:\n",
    "        m_add.append(merged[merged[\"URL\"]==j][j_fields].to_dict(\"records\")[0]|\n",
    "                     scopus_many[scopus_many['scopus_id']==i].to_dict('records')[0]|\n",
    "                     {\"scopus_indicator\":3})\n",
    "\n",
    "for i in msoj:\n",
    "    # print(i)\n",
    "    for j in msoj[i]:\n",
    "        m_add.append(merged[merged[\"URL\"]==i][j_fields].to_dict(\"records\")[0]|\n",
    "                     scopus_many[scopus_many['scopus_id']==j].to_dict('records')[0]|\n",
    "                     {\"scopus_indicator\":4})\n",
    "\n",
    "add=pd.DataFrame(m_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=merged[merged[\"URL\"].isin(add['URL'].to_list())==False].reset_index(drop=True)\n",
    "merged=pd.concat([merged, add]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aer\n",
      "ecta\n",
      "jpe\n",
      "res\n",
      "qje\n"
     ]
    }
   ],
   "source": [
    "scopus_mis={}\n",
    "for i in jid:\n",
    "    print(i)\n",
    "    sids=list(merged[merged['jid']==i]['scopus_id'].unique())\n",
    "    temp=scopus[(scopus[\"scopus_id\"].isin(sids)==False)&(scopus[\"scopus_jid\"]==i)].reset_index(drop=True)\n",
    "    scopus_mis[i]=temp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aer\n",
      "ecta\n",
      "jpe\n",
      "res\n",
      "qje\n"
     ]
    }
   ],
   "source": [
    "scopus_recon={}\n",
    "# for each journal\n",
    "for l in jid:\n",
    "    print(l)\n",
    "    a=0\n",
    "    ff=[]\n",
    "    b=0\n",
    "    check=[]\n",
    "\n",
    "    for i in scopus_mis[l].index:\n",
    "        # print(i)\n",
    "        found=0\n",
    "        max_r=0\n",
    "        sim=0\n",
    "        m_sim=0\n",
    "        fuzz_max=0\n",
    "        fuzz_found=0\n",
    "        target=None\n",
    "        # if scopus_mis[l].loc[i,'scopus_id']!='10.1086/261724':\n",
    "        #     continue\n",
    "        for j in merged[(merged['year']==scopus_mis[l].loc[i, 'scopus_year'])&(merged['number']==scopus_mis[l].loc[i, 'scopus_issue'])&(merged['jid']==l)].index:\n",
    "            # print(merged.loc[j, 'title'])\n",
    "            seq_rat=sq(None, scopus_mis[l].loc[i,'scopus_title'],merged.loc[j, 'title']).ratio()\n",
    "            # fuzz_rat=0\n",
    "            # for k in str(merged.loc[j,'author']).split(' and '):\n",
    "            #     if fuzz.token_sort_ratio(str(scopus_mis[l].loc[i,'scopus_author_full_names']).split('(')[0], k)>fuzz_rat:\n",
    "            fuzz_rat=fuzz.token_sort_ratio(str(scopus_mis[l].loc[i,'scopus_author_full_names']).split('(')[0], str(merged.loc[j,'author']).split(' and ')[0])\n",
    "            # print(merged.loc[j,'title'])\n",
    "            if (seq_rat>=sim):\n",
    "                if (fuzz_rat>=fuzz_max) | (pd.isna(merged.loc[j,'author'])) | (pd.isna(scopus_mis[l].loc[i,'scopus_author_full_names'])):\n",
    "                    if (seq_rat==sim):\n",
    "                        fuzz_found+=1\n",
    "                    sim=seq_rat\n",
    "                    m_sim=j\n",
    "                    fuzz_max=fuzz_rat\n",
    "                \n",
    "            if (seq_rat>0.95) & (fuzz_rat>95)& (str(scopus_mis[l].loc[i,'scopus_issue'])==str(merged.loc[j,'number'])) & (pd.isna(merged.loc[j,'scopus_id'])==True):\n",
    "                # print(\"execute\")\n",
    "                # print(scopus_mis[l].loc[i,'scopus_pages'])\n",
    "                # print(merged.loc[j,'pages'])\n",
    "                if (seq_rat>max_r)&((scopus_mis[l].loc[i,'scopus_pages'].lower()==merged.loc[j,'pages'].lower())|((scopus_mis[l].loc[i,'scopus_pages'].lower()+'-'+scopus_mis[l].loc[i,'scopus_pages'].lower())==merged.loc[j,'pages'].lower())):\n",
    "                    max_r=seq_rat\n",
    "                    target=j\n",
    "                    found+=1\n",
    "                # print(found)\n",
    "                # print(scopus_mis[l].loc[i,'scopus_title'])\n",
    "                # print('----match----'+merged.loc[j, 'title']+'    '+str(seq_rat))\n",
    "                # print(scopus_mis[l].loc[i,'scopus_issue']+ '    '+str(merged.loc[j,'number']))\n",
    "                # print(str(scopus_mis[l].loc[i,'scopus_author_full_names']).split('(')[0]+ '    '+str(merged.loc[j,'author']).split(' and ')[0])\n",
    "                a+=1\n",
    "                # print('\\n')\n",
    "        if found>1:\n",
    "            ff.append({i:target})\n",
    "            for k in scopus.columns:\n",
    "                merged.loc[target,k]=scopus_mis[l].loc[i,k]\n",
    "        elif found==1:\n",
    "            # print(target)\n",
    "            for k in scopus.columns:\n",
    "                merged.loc[target,k]=scopus_mis[l].loc[i,k]\n",
    "            merged.loc[target, 'scopus_indicator']=1\n",
    "        else:\n",
    "            \n",
    "            if sim!=0:\n",
    "                # print(sim)\n",
    "                # print(str(scopus_mis[l].loc[i,'scopus_author_full_names']).split('(')[0])\n",
    "                # print(str(merged.loc[m_sim, 'author']).split(' and ')[0])\n",
    "                # print(fuzz.token_sort_ratio(str(scopus_mis[l].loc[i,'scopus_author_full_names']).split('(')[0], str(merged.loc[m_sim, 'author']).split(' and ')[0]))\n",
    "                # print(str(scopus_mis[l].loc[i,'scopus_issue']))\n",
    "                # print(str(merged.loc[m_sim,'number']))\n",
    "                # print(temp.loc[i,'scopus_title'])\n",
    "                # print(sim)\n",
    "                # print(m_sim)\n",
    "                # print('{\"scopus_id\":\"'+temp.loc[i,'scopus_id'] + '\", \"Title\":\"'+merged.loc[m_sim, 'title']+'\"}')\n",
    "                check.append({\n",
    "                    \"scopus_id\":scopus_mis[l].loc[i,'scopus_id'],\n",
    "                    \"title\":merged.loc[m_sim, 'title'],\n",
    "                    \"title_scopus\":scopus_mis[l].loc[i,'scopus_title'],\n",
    "                    \"sim\":sim, #similarity score\n",
    "                    \"as\":scopus_mis[l].loc[i,'scopus_author_full_names'],\n",
    "                    \"v\":scopus_mis[l].loc[i,'scopus_volume'],\n",
    "                    \"is\":scopus_mis[l].loc[i,'scopus_issue'],\n",
    "                    'i':merged.loc[m_sim, 'number'],\n",
    "                    'ps':scopus_mis[l].loc[i,'scopus_pages'],\n",
    "                    \"a\":merged.loc[m_sim, 'author'],\n",
    "                    \"URL\":merged.loc[m_sim, 'URL'],\n",
    "                    'p':merged.loc[m_sim, 'pages'],\n",
    "                    'y': merged.loc[m_sim, 'year'],\n",
    "                    'ys':scopus_mis[l].loc[i,'scopus_year'],\n",
    "                    'jid':merged.loc[m_sim, 'jid'],\n",
    "\n",
    "                })\n",
    "                b+=1\n",
    "\n",
    "    scopus_recon[l]={\n",
    "        \"found_count\": a, \n",
    "        \"check_count\": b, \n",
    "        \"conflict_match\": ff, \n",
    "        \"check\": check\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aer': {'found_count': 127,\n",
       "  'check_count': 0,\n",
       "  'conflict_match': [],\n",
       "  'check': []},\n",
       " 'ecta': {'found_count': 37,\n",
       "  'check_count': 0,\n",
       "  'conflict_match': [],\n",
       "  'check': []},\n",
       " 'jpe': {'found_count': 58,\n",
       "  'check_count': 0,\n",
       "  'conflict_match': [],\n",
       "  'check': []},\n",
       " 'res': {'found_count': 164,\n",
       "  'check_count': 0,\n",
       "  'conflict_match': [],\n",
       "  'check': []},\n",
       " 'qje': {'found_count': 196,\n",
       "  'check_count': 0,\n",
       "  'conflict_match': [],\n",
       "  'check': []}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scopus_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_scopus=[]\n",
    "\n",
    "# for i in jid:\n",
    "#     if i != 'qje':\n",
    "#         continue\n",
    "#     for j in scopus_recon[i]['check']:\n",
    "#         check_scopus.append(j)\n",
    "\n",
    "# check_scopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['year'].isin(year_range)]['issue_url'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=['Article', 'Comment', 'Reply', 'Rejoinder']\n",
    "content_ex=['MISC','Discussion','Review', 'Review2', 'Errata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_summary=[]\n",
    "scopus_summary=[]\n",
    "for i in jid:\n",
    "    sids=list(merged[(merged['jid']==i)&(merged['scopus_id'].isna()==False)][\"scopus_id\"].unique())\n",
    "    sids_n=merged[(merged['jid']==i)&(merged['scopus_id'].isna()==False)].shape[0]\n",
    "    nrm_merged=merged[(merged['jid']==i)&(merged['content_type'].isin(content)==True)&(merged['year'].isin(year_range)==True)].shape[0]\n",
    "\n",
    "    temp=scopus[(scopus[\"scopus_id\"].isin(sids)==False)&(scopus[\"scopus_jid\"]==i)&(scopus[\"scopus_year\"].isin(ex_years)==False)].reset_index(drop=True)\n",
    "    scopus_mis[i]=temp\n",
    "\n",
    "    gr_2020=scopus_plus[scopus_plus['scopus_jid']==i].shape[0]\n",
    "    ign_misc=scopus_ignore[scopus_ignore['scopus_jid']==i].shape[0]\n",
    "    sc_err=scopus_wrong[scopus_wrong['scopus_jid']==i].shape[0]\n",
    "\n",
    "    scopus_count=scopus_base[(scopus_base['scopus_jid']==i)&(scopus_base['scopus_year'].isin(ex_years)==False)].shape[0]\n",
    "    result=len(sids)*100/scopus_count\n",
    "\n",
    "    result3=sids_n*100/merged[(merged['jid']==i)]['URL'].unique().shape[0]\n",
    "    \n",
    "    sids_nrm=list(merged[(merged['jid']==i)&(merged['year'].isin(year_range)==True)&(merged['scopus_id'].isna()==False)&(merged['content_type'].isin(content)==True)]['scopus_id'].unique())\n",
    "    sids_nrm_n=merged[(merged['jid']==i)&(merged['year'].isin(year_range)==True)&(merged['scopus_id'].isna()==False)&(merged['content_type'].isin(content)==True)].shape[0]\n",
    "\n",
    "    \n",
    "    result2=sids_nrm_n*100/nrm_merged\n",
    "\n",
    "    scopus_summary.append({\n",
    "        \"journal\": i,\n",
    "        \"articles on scopus\": scopus_base[(scopus_base['scopus_jid']==i)].shape[0],\n",
    "        \"article year > 2020\": gr_2020,\n",
    "        \"ignored misc articles\": ign_misc,\n",
    "        \"discarded metadata with errors\": sc_err,\n",
    "        \"scopus match candidates\": scopus_base[scopus_base['scopus_jid']==i].shape[0]-gr_2020-ign_misc-sc_err,\n",
    "        \"match %\": f\"{result:.4f}\",\n",
    "        \"many scopus one jstor\": len(merged[(merged['jid']==i)&(merged['scopus_indicator']==4)]['scopus_id'].unique()),\n",
    "        \"many jstor one scopus\": len(merged[(merged['jid']==i)&(merged['scopus_indicator']==3)]['scopus_id'].unique()),\n",
    "        \"direct match\": len(merged[(merged['jid']==i)&(merged['scopus_indicator']==2)]['scopus_id'].unique()),\n",
    "        \"scopus matched\": len(merged[(merged['jid']==i)&(merged['scopus_id'].isna()==False)&(merged['scopus_indicator']==0)&(merged['s_fix']!=1)]['scopus_id'].unique()),\n",
    "        \"scopus match on adj\": len(merged[(merged['jid']==i)&(merged['scopus_id'].isna()==False)&(merged['scopus_indicator']==0)&(merged['s_fix']==1)]['scopus_id'].unique()),\n",
    "        \"scopus approx. matched\": len(merged[(merged['jid']==i)&(merged['scopus_indicator']==1)]['scopus_id'].unique()),\n",
    "        \"scopus unmatched\": len(scopus[(scopus[\"scopus_jid\"]==i)&(scopus[\"scopus_id\"].isin(sids)==False)]['scopus_id'].unique()),\n",
    "    })\n",
    "\n",
    "    \n",
    "\n",
    "    match_summary.append({\n",
    "        \"journal\": i,\n",
    "        \"jstor <=2020\": merged[(merged['jid']==i)]['URL'].unique().shape[0],\n",
    "        \"scopus <=2020\": scopus_count,\n",
    "        \"matches*\": sids_n,\n",
    "        \"match %\": f\"{result3:.4f}\",\n",
    "        \"2020>= NMR >=1940\": nrm_merged,\n",
    "        \"2020>= NMR >=1940 matches\": sids_nrm_n,\n",
    "        \"2020>= NMR >=1940 match %\": f\"{result2:.4f}\",\n",
    "        # \"unmatched scopus articles\": temp.shape[0],\n",
    "        # \"unmatched scopus articles post 1940\": temp[temp['scopus_year'].isin(year_range)==True].shape[0],\n",
    "    })\n",
    "    # cids=cleaned['title'].unique()\n",
    "    # cids.sort()\n",
    "\n",
    "summary=pd.DataFrame(match_summary)\n",
    "summary.to_csv(base_path+\"/Combined/011_scopus_match_summary.csv\", index=False)\n",
    "\n",
    "sc_summary=pd.DataFrame(scopus_summary)\n",
    "sc_summary.to_csv(base_path+\"/Combined/011_scopus_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>jstor &lt;=2020</th>\n",
       "      <th>scopus &lt;=2020</th>\n",
       "      <th>matches*</th>\n",
       "      <th>match %</th>\n",
       "      <th>2020&gt;= NMR &gt;=1940</th>\n",
       "      <th>2020&gt;= NMR &gt;=1940 matches</th>\n",
       "      <th>2020&gt;= NMR &gt;=1940 match %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aer</td>\n",
       "      <td>27564</td>\n",
       "      <td>4360</td>\n",
       "      <td>4225</td>\n",
       "      <td>15.3280</td>\n",
       "      <td>12804</td>\n",
       "      <td>4198</td>\n",
       "      <td>32.7866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ecta</td>\n",
       "      <td>9339</td>\n",
       "      <td>1633</td>\n",
       "      <td>1605</td>\n",
       "      <td>17.1860</td>\n",
       "      <td>5348</td>\n",
       "      <td>1591</td>\n",
       "      <td>29.7494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jpe</td>\n",
       "      <td>14345</td>\n",
       "      <td>1293</td>\n",
       "      <td>1290</td>\n",
       "      <td>8.9927</td>\n",
       "      <td>4768</td>\n",
       "      <td>1276</td>\n",
       "      <td>26.7617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res</td>\n",
       "      <td>4140</td>\n",
       "      <td>3037</td>\n",
       "      <td>3019</td>\n",
       "      <td>72.9227</td>\n",
       "      <td>3242</td>\n",
       "      <td>2855</td>\n",
       "      <td>88.0629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qje</td>\n",
       "      <td>6869</td>\n",
       "      <td>4502</td>\n",
       "      <td>4485</td>\n",
       "      <td>65.2933</td>\n",
       "      <td>3700</td>\n",
       "      <td>3187</td>\n",
       "      <td>86.1351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  journal  jstor <=2020  scopus <=2020  matches*  match %  2020>= NMR >=1940  \\\n",
       "0     aer         27564           4360      4225  15.3280              12804   \n",
       "1    ecta          9339           1633      1605  17.1860               5348   \n",
       "2     jpe         14345           1293      1290   8.9927               4768   \n",
       "3     res          4140           3037      3019  72.9227               3242   \n",
       "4     qje          6869           4502      4485  65.2933               3700   \n",
       "\n",
       "   2020>= NMR >=1940 matches 2020>= NMR >=1940 match %  \n",
       "0                       4198                   32.7866  \n",
       "1                       1591                   29.7494  \n",
       "2                       1276                   26.7617  \n",
       "3                       2855                   88.0629  \n",
       "4                       3187                   86.1351  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary\n",
    "# *matches include duplicate matches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>articles on scopus</th>\n",
       "      <th>article year &gt; 2020</th>\n",
       "      <th>ignored misc articles</th>\n",
       "      <th>discarded metadata with errors</th>\n",
       "      <th>scopus match candidates</th>\n",
       "      <th>match %</th>\n",
       "      <th>many scopus one jstor</th>\n",
       "      <th>many jstor one scopus</th>\n",
       "      <th>direct match</th>\n",
       "      <th>scopus matched</th>\n",
       "      <th>scopus match on adj</th>\n",
       "      <th>scopus approx. matched</th>\n",
       "      <th>scopus unmatched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aer</td>\n",
       "      <td>4360</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>12</td>\n",
       "      <td>4219</td>\n",
       "      <td>96.7661</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4004</td>\n",
       "      <td>81</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ecta</td>\n",
       "      <td>1910</td>\n",
       "      <td>277</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1605</td>\n",
       "      <td>98.2854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1541</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jpe</td>\n",
       "      <td>1542</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1290</td>\n",
       "      <td>99.7680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1183</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res</td>\n",
       "      <td>3339</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3019</td>\n",
       "      <td>99.4073</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2682</td>\n",
       "      <td>154</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qje</td>\n",
       "      <td>4502</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4484</td>\n",
       "      <td>99.6002</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3968</td>\n",
       "      <td>262</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  journal  articles on scopus  article year > 2020  ignored misc articles  \\\n",
       "0     aer                4360                    0                    129   \n",
       "1    ecta                1910                  277                     27   \n",
       "2     jpe                1542                  249                      1   \n",
       "3     res                3339                  302                      3   \n",
       "4     qje                4502                    0                      4   \n",
       "\n",
       "   discarded metadata with errors  scopus match candidates  match %  \\\n",
       "0                              12                     4219  96.7661   \n",
       "1                               1                     1605  98.2854   \n",
       "2                               2                     1290  99.7680   \n",
       "3                              15                     3019  99.4073   \n",
       "4                              14                     4484  99.6002   \n",
       "\n",
       "   many scopus one jstor  many jstor one scopus  direct match  scopus matched  \\\n",
       "0                      2                      4             1            4004   \n",
       "1                      0                      0             1            1541   \n",
       "2                      0                      0             5            1183   \n",
       "3                      6                      0            13            2682   \n",
       "4                     32                      1            25            3968   \n",
       "\n",
       "   scopus match on adj  scopus approx. matched  scopus unmatched  \n",
       "0                   81                     127                 0  \n",
       "1                   26                      37                 0  \n",
       "2                   44                      58                 0  \n",
       "3                  154                     164                 0  \n",
       "4                  262                     196                 0  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_summary[['journal', 'articles on scopus', 'article year > 2020',\n",
    "       'ignored misc articles', 'discarded metadata with errors',\n",
    "       'scopus match candidates', 'match %']].to_csv(base_path+\"/Combined/011_scopus_summary_p1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_summary[['journal','scopus match candidates','many scopus one jstor',\n",
    "       'many jstor one scopus', 'direct match', 'scopus matched',\n",
    "       'scopus match on adj', 'scopus approx. matched', 'scopus unmatched']].to_csv(base_path+\"/Combined/011_scopus_summary_p2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['year']=merged['year'].astype(int)\n",
    "merged.to_pickle(base_path+\"/Combined/011_merged_proc_scopus_inception_2020.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Article', 'MISC', 'Comment', 'Reply', 'Errata', 'Rejoinder',\n",
       "       'Discussion', 'Review', 'Review2'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.content_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
