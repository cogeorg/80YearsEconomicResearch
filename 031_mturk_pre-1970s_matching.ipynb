{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9829c4a1",
   "metadata": {},
   "source": [
    "# Matching References pre-1970s\n",
    "The purpose of this notebook is to clean results obtained from mturk for journal articles that are from, on average, before 1970. There are two data sources which has resulted in slight differences in the raw data input structure.\n",
    "\n",
    "1. AWS MTURK - a service offered by AWS, output returns as a csv file\n",
    "2. fMTURK - a clone of AWS MTURK specific to scholarly publishing where the output returns as a json file\n",
    "\n",
    "Note that naming conventions for variables vary even though they are both structured data sets so combining them will require some trivial manipulation.\n",
    "\n",
    "Expected output: \n",
    "1. json files of reference matches \n",
    "2. json and csv files of references collected via manual interfaces\n",
    "3. csv file of all input data\n",
    "4. reconciliation of all input files vs output files to see which pages and files have been digitized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63915440",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13f51e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries required, please install pandas\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from datetime import date\n",
    "import json\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# set column options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46cab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change base path to point to the results of the mturk data\n",
    "# the expectation is that this was directly downloaded from the respective results interface\n",
    "mturk_files_out=\"/Users/sijiawu/Downloads/thesis_docs/mturk_process/output_files/\"\n",
    "mturk_files_in=\"/Users/sijiawu/Downloads/thesis_docs/mturk_process/input_files/\"\n",
    "fmturk_files_out=\"/Users/sijiawu/Downloads/thesis_docs/fmturk/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03795d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove leading and trailing non-ascii characters\n",
    "def strip_leading(_str):\n",
    "    k=0\n",
    "    l=len(_str)\n",
    "    while k!=len(_str):\n",
    "        if re.search('[,*\" \\'.:]',_str[k]) is not None:\n",
    "            k=k+1\n",
    "        else:\n",
    "            break\n",
    "    while l>0:\n",
    "        if re.search('[,*\" \\'.:]',_str[l-1]) is not None:\n",
    "            l=l-1\n",
    "        else:\n",
    "            break\n",
    "    return _str[k:l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd30924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/5mt219qj6l552yrf3l89xgdh0000gn/T/ipykernel_10911/344025660.py:6: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  j_data=pd.concat([pd.read_excel('/Users/sijiawu/Work/Thesis/Data/Combined/'+i+'_M_sco_du.xlsx'), j_data], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# load in journal metadata\n",
    "JOURNALS= ['AER', 'JPE', 'ECTA', 'RES', 'QJE']\n",
    "#read in all processed masterlists\n",
    "j_data=pd.DataFrame()\n",
    "for i in JOURNALS:\n",
    "    j_data=pd.concat([pd.read_excel('/Users/sijiawu/Work/Thesis/Data/Combined/'+i+'_M_sco_du.xlsx'), j_data], ignore_index=True)\n",
    "#Create a batch file\n",
    "\n",
    "j_data=j_data[j_data.duplicated()==False].reset_index().drop('index', axis=1)\n",
    "\n",
    "# Replace the journal names with Acronyms\n",
    "j_data.loc[j_data['journal']==\"Econometrica\",'journal']='econometrica'\n",
    "j_data.loc[j_data['journal']=='The Quarterly Journal of Economics','journal']='quarterly journal of economics'\n",
    "j_data.loc[j_data['journal']=='The Review of Economic Studies','journal']='review of economic studies'\n",
    "j_data.loc[j_data['journal']=='Journal of Political Economy','journal']='journal of political economy'\n",
    "j_data.loc[j_data['journal']=='The American Economic Review','journal']='american economic review'\n",
    "\n",
    "#some corrections to the issue\n",
    "j_data.loc[j_data[\"number\"]==\"2023-03-04 00:00:00\",\"number\"]=\"3--4\"\n",
    "j_data.loc[j_data[\"number\"]==\"4-5\",\"number\"]=\"4--5\"\n",
    "j_data.loc[j_data[\"number\"]==\"1-2\",\"number\"]=\"1--2\"\n",
    "\n",
    "j_data.journal.unique()\n",
    "\n",
    "j_data[\"id\"]=j_data[\"URL\"].str.split(\"/\").str[-1]\n",
    "j_data[\"title_proc\"]=j_data[\"title\"].fillna(\"none\").astype(str).str.lower()\n",
    "j_data[\"title_proc\"]=j_data[\"title_proc\"].apply(strip_leading,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0736e53e",
   "metadata": {},
   "source": [
    "## Matching Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a52ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset=pd.read_pickle(\"pre_1970s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c7e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset.type.value_counts()\n",
    "interest=[\"american economic review\",\"econometrica\", \"journal of political economy\", \"quarterly journal of economics\", \"review of economic studies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "213dde85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Utility function to compute similarity\n",
    "# Utility function to compute similarity\n",
    "def similar(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "def construct(j_data, journal,year,title, year_latest):\n",
    "    # print(year)\n",
    "    # print(journal)\n",
    "    if journal in interest:\n",
    "        temp=j_data[(j_data[\"journal\"]==journal)&(j_data[\"year\"]<=(year+2))&(j_data[\"year\"]>=(year_latest-10))][\"title_proc\"].apply(lambda y: similar(y, title))\n",
    "        # print(temp)\n",
    "        if len(temp)>0:\n",
    "            # print(list(temp))\n",
    "            # print(max(list(temp)))\n",
    "            o=temp[temp>=(max(temp)-0.15)]\n",
    "            return {\"index\": list(o.index), \"m_val\":list(o)}\n",
    "        else:\n",
    "            return {'index':[],\"m_val\":[]}\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7900870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_jstor=fullset[fullset[\"type\"]==8].reset_index(drop=True)\n",
    "fullset_article=fullset[fullset[\"type\"]==2].reset_index(drop=True)\n",
    "fullset_others=fullset[(fullset[\"type\"]!=2)&(fullset[\"type\"]!=8)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e2c45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_article[\"outcome\"]=fullset_article.apply(lambda x:construct(j_data, x['journal_proc'],int(x['year_o']),x['title_proc'], x[\"year_latest\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb1512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd07a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_j(df, jstor_id):\n",
    "    try:\n",
    "        t=int(jstor_id)\n",
    "        # print(list(j_data.loc[j_data[\"id\"]==str(t), 'URL'])[0])\n",
    "        s=list(df.loc[j_data[\"id\"]==str(t), 'URL'])\n",
    "        return s[0]\n",
    "    except:\n",
    "        return \"CHECKREQ\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f2b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_jstor['match_url']=fullset_jstor.apply(lambda x: construct_j(j_data, x[\"jstor\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac5a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "053a75c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 1.939e+03, 1.931e+03, 1.943e+03, 1.944e+03, 1.942e+03,\n",
       "       1.945e+03, 1.941e+03, 1.954e+03, 1.946e+03, 1.950e+03, 1.959e+03,\n",
       "       1.940e+03, 1.948e+03, 1.937e+03, 1.951e+03, 1.953e+03, 1.935e+03,\n",
       "       1.933e+03, 1.936e+03, 1.929e+03, 1.930e+03, 1.952e+03, 1.938e+03,\n",
       "       1.949e+03, 1.912e+03, 1.957e+03, 1.961e+03, 1.962e+03, 1.960e+03,\n",
       "       1.958e+03, 1.956e+03, 1.963e+03, 1.965e+03, 1.964e+03, 1.947e+03,\n",
       "       1.932e+03, 1.917e+03, 1.000e+00, 1.955e+03, 1.934e+03, 1.800e+03,\n",
       "       1.919e+03, 1.918e+03, 1.925e+03, 1.928e+03, 1.914e+03, 1.926e+03,\n",
       "       1.916e+03, 1.906e+03, 1.894e+03,       nan])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article[fullset_article['journal'].isin(interest)][\"year_latest\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "696e76af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tasknum', 'id_o', 'page_o', 'year_o', 'journal_o', 'authors_o',\n",
       "       'title_o', 'volume_o', 'issue_o', 'completer', 'pdf_url', 'type',\n",
       "       'author', 'title', 'journal', 'year', 'volume', 'issue', 'pages',\n",
       "       'chapter_title', 'location', 'publisher', 'text_full', 'jstor',\n",
       "       'journal_proc', 'year_proc', 'year_proc_split', 'year_latest',\n",
       "       'volume_proc', 'issue_proc', 'title_proc', 'outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a1624bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['issue_url', 'ISSN', 'URL', 'journal', 'number', 'publisher', 'title',\n",
       "       'urldate', 'volume', 'year', 'abstract', 'author', 'pages',\n",
       "       'reviewed-author', 'uploaded', 'content_type', 'author_split',\n",
       "       'title_10', 'type', 'authorsSCO', 'titleSCO', 'journalSCO', 'DOI',\n",
       "       'affiliations', 'abstractSCO', 'citations', 'document type',\n",
       "       'index keywords', 'author keywords', 'document_type', 'id',\n",
       "       'title_proc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1c98264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n",
      "no_match\n"
     ]
    }
   ],
   "source": [
    "fullset_article['match_url']=None\n",
    "found=[]\n",
    "confirmed={\n",
    "    1:[0,0],\n",
    "    2:[0,0],\n",
    "    3:[0,0],\n",
    "    4:[0,0],\n",
    "    5:[0,0],\n",
    "}\n",
    "vary=0\n",
    "vary2=0\n",
    "bad=0\n",
    "re=0\n",
    "for i in fullset_article.index:\n",
    "    if fullset_article.loc[i,\"journal_proc\"] in interest:\n",
    "        count=len(fullset_article.loc[i,\"outcome\"]['index'])\n",
    "        found.append(count)\n",
    "        # print(fullset_article.loc[i,'author'] + \" ### \"+fullset_article.loc[i,'title_proc'] + \" ## \" + str(fullset_article.loc[i,'year_proc'] ))\n",
    "        test=pd.concat([j_data.loc[fullset_article.loc[i,\"outcome\"]['index'], [\"title\",'author','URL','year']].reset_index(drop=True),pd.DataFrame(fullset_article.loc[i,\"outcome\"])], axis=1)\n",
    "        if count==1:\n",
    "            # print(test[['author','title','year']])\n",
    "            a=similar(str(list(test['author'])[0]), str(fullset_article.loc[i,\"author\"]))\n",
    "            b=similar(str(list(test['author'])[0]).split(' ')[-1], str(fullset_article.loc[i,\"author\"]).split(' ')[-1])\n",
    "            if (a>0.8) or (b>0.8):\n",
    "                confirmed[1][0]+=1\n",
    "                fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "            else:\n",
    "                fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "\n",
    "        elif count>1:\n",
    "            \n",
    "            if sum(test[\"m_val\"]==1)==1:\n",
    "                # print(test[test[\"m_val\"]==1][['author','title','year']])\n",
    "                # print(similar(str(list(test[test[\"m_val\"]==1]['author'])[0]), str(fullset_article.loc[i,\"author\"])))\n",
    "                a=similar(str(list(test[test[\"m_val\"]==1]['author'])[0]), str(fullset_article.loc[i,\"author\"]))\n",
    "                b=similar(str(list(test[test[\"m_val\"]==1]['author'])[0]).split(' ')[-1], str(fullset_article.loc[i,\"author\"]).split(' ')[-1])\n",
    "                if (a>0.8) or (b>0.8):\n",
    "                    # confirmed[count][0]+=1\n",
    "                    fullset_article.loc[i,'match_url']=list(test['URL'])[0]\n",
    "                else:\n",
    "                    fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "            elif sum(test[\"m_val\"]>0.65)>0:\n",
    "                if sum(test[\"year\"]==fullset_article.loc[i,\"year_proc\"])==1:\n",
    "                    # print(\"year match\")\n",
    "                    a=similar(str(list(test[test[\"year\"]==fullset_article.loc[i,\"year_proc\"]]['author'])[0]), str(fullset_article.loc[i,\"author\"]))\n",
    "                    b=similar(str(list(test[test[\"year\"]==fullset_article.loc[i,\"year_proc\"]]['author'])[0]).split(' ')[-1], str(fullset_article.loc[i,\"author\"]).split(' ')[-1])\n",
    "                    if (a>0.8) or (b>0.8):\n",
    "                        fullset_article.loc[i,'match_url']=list(test[test[\"year\"]==fullset_article.loc[i,\"year_proc\"]][\"URL\"])[0]\n",
    "                        vary2+=1\n",
    "                    else:\n",
    "                        fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "                vary+=1\n",
    "                # print(\"test for case of multiple author, multiple legs\")\n",
    "                # print(fullset_article.loc[i,\"outcome\"]['index'])\n",
    "                # print(fullset_article.loc[i,\"title_proc\"]+ \" \"+fullset_article.loc[i,\"author\"]+\" ##### \"+str(fullset_article.loc[i,\"year_proc\"]))\n",
    "                # print(test)\n",
    "            else:\n",
    "                # print(\"unlikely match\")\n",
    "                fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "                bad+=1\n",
    "        else:\n",
    "            print(\"no_match\")\n",
    "            fullset_article.loc[i,'match_url']=\"CHECKREQ\"\n",
    "            bad+=1\n",
    "    else:\n",
    "        fullset_article.loc[i,\"outcome\"]=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2b37e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5211, 34)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset_article[fullset_article[\"journal_proc\"].isin(interest)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa43d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_id_allocate(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    elif x==\"CHECKREQ\":\n",
    "        return None\n",
    "    else:\n",
    "        return x.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39b6fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_70=pd.concat([fullset_jstor, fullset_article, fullset_others], axis=0).reset_index(drop=True)\n",
    "all_70['match_id']=all_70.apply(lambda x: match_id_allocate(x['match_url']), axis=1)\n",
    "all_70['f_key']='mturk_'+all_70.index.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d46c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_jstor_match=all_70[(all_70['type']==8)&(all_70[\"match_url\"]!=\"CHECKREQ\")].reset_index(drop=True)\n",
    "fullset_article_match=all_70[(all_70['type']==2)&(all_70[\"match_url\"]!=\"CHECKREQ\")&(all_70[\"journal_proc\"].isin(interest))].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d9fad92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tasknum', 'id_o', 'page_o', 'year_o', 'journal_o', 'authors_o',\n",
       "       'title_o', 'volume_o', 'issue_o', 'completer', 'pdf_url', 'type',\n",
       "       'author', 'title', 'journal', 'year', 'volume', 'issue', 'pages',\n",
       "       'chapter_title', 'location', 'publisher', 'text_full', 'jstor',\n",
       "       'journal_proc', 'year_proc', 'year_proc_split', 'year_latest',\n",
       "       'volume_proc', 'issue_proc', 'title_proc', 'match_url', 'outcome',\n",
       "       'match_id', 'f_key'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_70.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c242134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_article_sub=all_70[(all_70['id_o']!=all_70['match_id'])&(all_70['match_id'].isna()==False)].reset_index(drop=True).drop_duplicates(subset = ['id_o', 'match_id'], keep='first').reset_index(drop=True)[['id_o', 'match_id','f_key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04eb3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_article_sub.to_excel('network_cit_pre.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f2b84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_70.to_excel(\"refs_pre_1970.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d746a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             type  total matched error\n",
      "0   jstor_trivial   3563    3555     8\n",
      "1   jstor_article   5211    4620   591\n",
      "2  other_articles   8599       0     0\n",
      "3      other_refs  36107       0     0\n",
      "53480\n",
      "8175\n",
      "599\n"
     ]
    }
   ],
   "source": [
    "summary={\n",
    "    0: {'type': \"jstor_trivial\",'total': fullset_jstor.shape[0], \"matched\":fullset_jstor_match.shape[0],\"error\" : fullset_jstor[fullset_jstor['match_url']==\"CHECKREQ\"].shape[0]},\n",
    "    1: {'type':'jstor_article','total': fullset_article[fullset_article[\"journal_proc\"].isin(interest)].shape[0], 'matched': fullset_article_match.shape[0], \"error\": fullset_article[fullset_article[\"match_url\"]==\"CHECKREQ\"].shape[0]},\n",
    "    2: {'type':'other_articles','total': fullset_article.shape[0]-fullset_article[fullset_article[\"journal_proc\"].isin(interest)].shape[0], 'matched':0, 'error':0},\n",
    "    3: {'type': 'other_refs', 'total': fullset_others.shape[0], 'matched':0, 'error':0}\n",
    "}\n",
    "\n",
    "summary_df=pd.DataFrame(summary).transpose()\n",
    "print(summary_df)\n",
    "print(sum(summary_df['total']))\n",
    "print(sum(summary_df['matched']))\n",
    "print(sum(summary_df['error']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
