{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting .pkl to panel data\n",
    "\n",
    "Expect inputs in .pkl:\n",
    "- combined jstor + scopus metadata\n",
    "- author names and affiliations data\n",
    "- references data\n",
    "- tables, figures and equations data\n",
    "\n",
    "\n",
    "Output:\n",
    "- flattened versions\n",
    "\n",
    "REC:\n",
    "- 013, 023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from unidecode import unidecode\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import combinations\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/sijiawu/Work/Thesis/Data/Affiliations/\"\n",
    "data_base_path=\"/Users/sijiawu/Work/Thesis/Data/\"\n",
    "nets_path=\"/Users/sijiawu/Work/80YearsEconomicResearch/032_auth_graph_gen/networks/\"\n",
    "pdf_base_path=\"/Users/sijiawu/Dropbox/80YearsEconomicResearch/Data/0_PDF/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_auths_all = pd.read_pickle(base_path+\"proc_auth_aff_flat.pkl\")\n",
    "aff_sub=pd.read_pickle(base_path+\"affiliations_combined_sub.pkl\")\n",
    "j_data=pd.read_pickle(data_base_path+\"Combined/011_merged_proc_scopus_inception_2020_w_counts.pkl\")\n",
    "all_refs=pd.read_excel('../031_proc_refs_full_set/refs_1940_2020.xlsx')\n",
    "relevant=pd.read_excel('../031_proc_refs_full_set/refs_1940_2020_top5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_data[\"id\"]=j_data[\"URL\"].str.split(\"/\").str[-1]\n",
    "relevant[\"id_o\"]=relevant[\"id_o\"].astype(str)\n",
    "relevant[\"year_o\"]=relevant[\"year_o\"].astype(int)\n",
    "proc_auths_all[\"id_o\"]=proc_auths_all[\"url\"].str.split(\"/\").str[-1]\n",
    "proc_auths_all[\"a1_order_str\"]=proc_auths_all[\"a1_order\"].astype(str)\n",
    "relevant_sub=relevant[[\"ref_ord\", \"id_o\", \"year_o\",\"match_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in proc_auths_all['id_o'].unique():\n",
    "    if \".\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_data[\"page_start\"]=j_data[\"pages\"].str.split('-').str[0]\n",
    "j_data[\"page_end\"]=j_data[\"pages\"].str.split('-').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_content=['MISC', 'Errata','Discussion', 'Review', 'Review2']\n",
    "content=['Article', 'Comment', 'Reply', 'Rejoinder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Article', 'MISC', 'Comment', 'Reply', 'Errata', 'Rejoinder',\n",
       "       'Discussion', 'Review', 'Review2'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_data.content_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>year</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>abstract</th>\n",
       "      <th>URL</th>\n",
       "      <th>publisher</th>\n",
       "      <th>content_type</th>\n",
       "      <th>type</th>\n",
       "      <th>jid</th>\n",
       "      <th>author_split</th>\n",
       "      <th>urldate</th>\n",
       "      <th>reviewed-author</th>\n",
       "      <th>uploaded</th>\n",
       "      <th>title_10</th>\n",
       "      <th>URL_og</th>\n",
       "      <th>number_og</th>\n",
       "      <th>title_og</th>\n",
       "      <th>author_og</th>\n",
       "      <th>pages_og</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1363-1398</td>\n",
       "      <td>2020</td>\n",
       "      <td>0033-5533</td>\n",
       "      <td>News reports and communication are inherently constrained by space, time, and attention. As a re...</td>\n",
       "      <td>https://doi.org/10.1093/qje/qjaa012</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>Article</td>\n",
       "      <td>N</td>\n",
       "      <td>qje</td>\n",
       "      <td>['Enke, Benjamin']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1093/qje/qjaa012</td>\n",
       "      <td>3</td>\n",
       "      <td>What You See Is All There Is*</td>\n",
       "      <td>Enke, Benjamin</td>\n",
       "      <td>1363-1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan</td>\n",
       "      <td>2020</td>\n",
       "      <td>00028282, 19447981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.jstor.org/stable/26966477</td>\n",
       "      <td>American Economic Association</td>\n",
       "      <td>MISC</td>\n",
       "      <td>N</td>\n",
       "      <td>aer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.jstor.org/stable/26966477</td>\n",
       "      <td>12</td>\n",
       "      <td>Front Matter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3705-3747</td>\n",
       "      <td>2020</td>\n",
       "      <td>00028282, 19447981</td>\n",
       "      <td>African agricultural markets are characterized by low farmer revenues and high consumer food pri...</td>\n",
       "      <td>https://www.jstor.org/stable/26966478</td>\n",
       "      <td>American Economic Association</td>\n",
       "      <td>Article</td>\n",
       "      <td>N</td>\n",
       "      <td>aer</td>\n",
       "      <td>['Lauren Falcao Bergquist', 'Michael Dinerstein']</td>\n",
       "      <td>2023-09-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.jstor.org/stable/26966478</td>\n",
       "      <td>12</td>\n",
       "      <td>Competition and Entry in Agricultural Markets: Experimental Evidence from Kenya</td>\n",
       "      <td>Lauren Falcao Bergquist and Michael Dinerstein</td>\n",
       "      <td>3705-3747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3748-3785</td>\n",
       "      <td>2020</td>\n",
       "      <td>00028282, 19447981</td>\n",
       "      <td>We present a new equilibrium search model where consumers initially search among discount opport...</td>\n",
       "      <td>https://www.jstor.org/stable/26966479</td>\n",
       "      <td>American Economic Association</td>\n",
       "      <td>Article</td>\n",
       "      <td>N</td>\n",
       "      <td>aer</td>\n",
       "      <td>['Dominic Coey', 'Bradley J. Larsen', 'Brennan C. Platt']</td>\n",
       "      <td>2023-09-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.jstor.org/stable/26966479</td>\n",
       "      <td>12</td>\n",
       "      <td>Discounts and Deadlines in Consumer Search</td>\n",
       "      <td>Dominic Coey and Bradley J. Larsen and Brennan C. Platt</td>\n",
       "      <td>3748-3785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3786-3816</td>\n",
       "      <td>2020</td>\n",
       "      <td>00028282, 19447981</td>\n",
       "      <td>We formalize the argument that political disagreements can be traced to a “clash of narratives.”...</td>\n",
       "      <td>https://www.jstor.org/stable/26966480</td>\n",
       "      <td>American Economic Association</td>\n",
       "      <td>Article</td>\n",
       "      <td>N</td>\n",
       "      <td>aer</td>\n",
       "      <td>['Kfir Eliaz', 'Ran Spiegler']</td>\n",
       "      <td>2023-09-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.jstor.org/stable/26966480</td>\n",
       "      <td>12</td>\n",
       "      <td>A Model of Competing Narratives</td>\n",
       "      <td>Kfir Eliaz and Ran Spiegler</td>\n",
       "      <td>3786-3816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pages  year                ISSN  \\\n",
       "0  1363-1398  2020           0033-5533   \n",
       "1        nan  2020  00028282, 19447981   \n",
       "2  3705-3747  2020  00028282, 19447981   \n",
       "3  3748-3785  2020  00028282, 19447981   \n",
       "4  3786-3816  2020  00028282, 19447981   \n",
       "\n",
       "                                                                                              abstract  \\\n",
       "0  News reports and communication are inherently constrained by space, time, and attention. As a re...   \n",
       "1                                                                                                  NaN   \n",
       "2  African agricultural markets are characterized by low farmer revenues and high consumer food pri...   \n",
       "3  We present a new equilibrium search model where consumers initially search among discount opport...   \n",
       "4  We formalize the argument that political disagreements can be traced to a “clash of narratives.”...   \n",
       "\n",
       "                                     URL                      publisher  \\\n",
       "0    https://doi.org/10.1093/qje/qjaa012        Oxford University Press   \n",
       "1  https://www.jstor.org/stable/26966477  American Economic Association   \n",
       "2  https://www.jstor.org/stable/26966478  American Economic Association   \n",
       "3  https://www.jstor.org/stable/26966479  American Economic Association   \n",
       "4  https://www.jstor.org/stable/26966480  American Economic Association   \n",
       "\n",
       "  content_type type  jid  \\\n",
       "0      Article    N  qje   \n",
       "1         MISC    N  aer   \n",
       "2      Article    N  aer   \n",
       "3      Article    N  aer   \n",
       "4      Article    N  aer   \n",
       "\n",
       "                                                author_split  \\\n",
       "0                                         ['Enke, Benjamin']   \n",
       "1                                                        NaN   \n",
       "2          ['Lauren Falcao Bergquist', 'Michael Dinerstein']   \n",
       "3  ['Dominic Coey', 'Bradley J. Larsen', 'Brennan C. Platt']   \n",
       "4                             ['Kfir Eliaz', 'Ran Spiegler']   \n",
       "\n",
       "               urldate reviewed-author  uploaded title_10  \\\n",
       "0                  NaN             NaN       NaN      NaN   \n",
       "1  2023-09-04 00:00:00             NaN       1.0      NaN   \n",
       "2  2023-09-04 00:00:00             NaN       1.0      NaN   \n",
       "3  2023-09-04 00:00:00             NaN       1.0      NaN   \n",
       "4  2023-09-04 00:00:00             NaN       1.0      NaN   \n",
       "\n",
       "                                  URL_og number_og  \\\n",
       "0    https://doi.org/10.1093/qje/qjaa012         3   \n",
       "1  https://www.jstor.org/stable/26966477        12   \n",
       "2  https://www.jstor.org/stable/26966478        12   \n",
       "3  https://www.jstor.org/stable/26966479        12   \n",
       "4  https://www.jstor.org/stable/26966480        12   \n",
       "\n",
       "                                                                          title_og  \\\n",
       "0                                                    What You See Is All There Is*   \n",
       "1                                                                     Front Matter   \n",
       "2  Competition and Entry in Agricultural Markets: Experimental Evidence from Kenya   \n",
       "3                                       Discounts and Deadlines in Consumer Search   \n",
       "4                                                  A Model of Competing Narratives   \n",
       "\n",
       "                                                 author_og   pages_og  \n",
       "0                                           Enke, Benjamin  1363-1398  \n",
       "1                                                      NaN        NaN  \n",
       "2           Lauren Falcao Bergquist and Michael Dinerstein  3705-3747  \n",
       "3  Dominic Coey and Bradley J. Larsen and Brennan C. Platt  3748-3785  \n",
       "4                              Kfir Eliaz and Ran Spiegler  3786-3816  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_data[['pages',\n",
    "       'year', 'ISSN', 'abstract', 'URL', 'publisher', 'content_type', 'type',\n",
    "       'jid', 'author_split', 'urldate', 'reviewed-author', 'uploaded',\n",
    "       'title_10', 'URL_og', 'number_og', 'title_og', 'author_og', 'pages_og',]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46436, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_auths_all.shape #46436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_counts=proc_auths_all[\"id_o\"].value_counts().reset_index()\n",
    "auth_page_count=auth_counts.merge(j_data[[\"id\",\"page_count\"]], left_on=\"id_o\", right_on=\"id\", how=\"left\").drop_duplicates().drop(columns=[\"id\"])\n",
    "auth_page_count[\"points\"]=auth_page_count[\"page_count\"]/(auth_page_count[\"count\"]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_auths_all=proc_auths_all.merge(auth_page_count, on=\"id_o\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_point_years=proc_auths_all[[\"a1_order_str\", \"year\", \"points\"]].groupby(['year', 'a1_order_str'])['points'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_auths_all[\"c_count\"]=proc_auths_all[\"count\"]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'harvard university',\n",
       " 'national bureau of economic research - nber',\n",
       " 'university of michigan'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_auths_all.loc[0,\"affs\"].union(proc_auths_all.loc[1,\"affs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_count(lag):\n",
    "    auth_lags=[]\n",
    "    auth_counts=[]\n",
    "    paper_counts=[]\n",
    "    auth_affs=[]\n",
    "    for i in range(1940,2021,1):\n",
    "        authpoint=auth_point_years[(auth_point_years[\"year\"]<=i)&(auth_point_years[\"year\"]>i-lag)]\n",
    "        tem=authpoint.groupby(['a1_order_str'])['points'].sum().reset_index()\n",
    "        tem=tem.rename(columns={\"points\":\"points\"+str(lag)})\n",
    "        tem[\"year\"+str(lag)]=i\n",
    "        auth_lags.append(tem)\n",
    "\n",
    "        authcount=proc_auths_all[(proc_auths_all[\"year\"]<=i)&(proc_auths_all[\"year\"]>i-lag)]\n",
    "        tem=authcount[[\"a1_order_str\", \"year\", \"c_count\"]].groupby(['a1_order_str'])['c_count'].sum().reset_index()\n",
    "        tem=tem.rename(columns={\"c_count\":\"c_counts\"+str(lag)})\n",
    "        tem[\"year\"+str(lag)]=i\n",
    "        auth_counts.append(tem)\n",
    "\n",
    "        tem=authcount[[\"a1_order_str\", \"year\", \"c_count\"]].groupby(['a1_order_str'])['c_count'].count().reset_index()\n",
    "        tem=tem.rename(columns={\"c_count\":\"p_counts\"+str(lag)})\n",
    "        tem[\"year\"+str(lag)]=i\n",
    "        paper_counts.append(tem)\n",
    "\n",
    "        redproccombo=proc_auths_all[(proc_auths_all[\"year\"]>i-lag)&(proc_auths_all[\"year\"]<=i)][[\"a1_order_str\",\"affs\",\"year\"]].groupby(\"a1_order_str\").agg({\n",
    "            'affs': lambda x: set().union(*x),\n",
    "            'year': list,  # Keeping the first year since they're all the same in this sample\n",
    "            'a1_order_str': 'first'  # Keep track of which a1_order_str values were grouped\n",
    "        }).reset_index(drop=True)\n",
    "        redproccombo=redproccombo.rename(columns={\"year\":\"all_years\"+str(lag), \"affs\":\"affs\"+str(lag)})\n",
    "        redproccombo[\"year\"+str(lag)]=i\n",
    "        auth_affs.append(redproccombo)\n",
    "\n",
    "\n",
    "    return (pd.concat(auth_lags) , pd.concat(auth_counts), pd.concat(paper_counts),pd.concat(auth_affs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_lag_10_df, auth_c_10_df, auth_p_10_df, auth_affs_10_df = lag_count(10)\n",
    "auth_lag_5_df, auth_c_5_df, auth_p_5_df, auth_affs_5_df = lag_count(5)\n",
    "auth_lag_20_df, auth_c_20_df, auth_p_20_df, auth_affs_20_df = lag_count(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affs10</th>\n",
       "      <th>all_years10</th>\n",
       "      <th>a1_order_str</th>\n",
       "      <th>year10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{columbia university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>10002</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{colgate university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>1003</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{harvard university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>10067</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{new york university, university of buffalo}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "      <td>10222</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{university of st. thomas}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>10251</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         affs10   all_years10 a1_order_str  \\\n",
       "0                         {columbia university}        [1940]        10002   \n",
       "1                          {colgate university}        [1940]         1003   \n",
       "2                          {harvard university}        [1940]        10067   \n",
       "3  {new york university, university of buffalo}  [1940, 1940]        10222   \n",
       "4                    {university of st. thomas}        [1940]        10251   \n",
       "\n",
       "   year10  \n",
       "0    1940  \n",
       "1    1940  \n",
       "2    1940  \n",
       "3    1940  \n",
       "4    1940  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_affs_10_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_comps_10=auth_lag_10_df.merge(auth_c_10_df, left_on=[\"a1_order_str\", \"year10\"], right_on=[\"a1_order_str\", \"year10\"]).merge(auth_p_10_df, left_on=[\"a1_order_str\", \"year10\"], right_on=[\"a1_order_str\", \"year10\"]).merge(auth_affs_10_df, left_on=[\"a1_order_str\", \"year10\"], right_on=[\"a1_order_str\", \"year10\"])\n",
    "auth_comps_20=auth_lag_20_df.merge(auth_c_20_df, left_on=[\"a1_order_str\", \"year20\"], right_on=[\"a1_order_str\", \"year20\"]).merge(auth_p_20_df, left_on=[\"a1_order_str\", \"year20\"], right_on=[\"a1_order_str\", \"year20\"]).merge(auth_affs_20_df, left_on=[\"a1_order_str\", \"year20\"], right_on=[\"a1_order_str\", \"year20\"])\n",
    "auth_comps_5=auth_lag_5_df.merge(auth_c_5_df, left_on=[\"a1_order_str\", \"year5\"], right_on=[\"a1_order_str\", \"year5\"]).merge(auth_p_5_df, left_on=[\"a1_order_str\", \"year5\"], right_on=[\"a1_order_str\", \"year5\"]).merge(auth_affs_5_df, left_on=[\"a1_order_str\", \"year5\"], right_on=[\"a1_order_str\", \"year5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_lags_points=auth_comps_20.merge(auth_comps_10, left_on=[\"a1_order_str\", \"year20\"], right_on=[\"a1_order_str\", \"year10\"], how =\"left\").merge(auth_comps_5, left_on=[\"a1_order_str\", \"year20\"], right_on=[\"a1_order_str\", \"year5\"], how =\"left\").drop(columns=[\"year10\", \"year5\"]).rename(columns={\"year20\":\"year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1_order_str</th>\n",
       "      <th>points20</th>\n",
       "      <th>year</th>\n",
       "      <th>c_counts20</th>\n",
       "      <th>p_counts20</th>\n",
       "      <th>affs20</th>\n",
       "      <th>all_years20</th>\n",
       "      <th>points10</th>\n",
       "      <th>c_counts10</th>\n",
       "      <th>p_counts10</th>\n",
       "      <th>affs10</th>\n",
       "      <th>all_years10</th>\n",
       "      <th>points5</th>\n",
       "      <th>c_counts5</th>\n",
       "      <th>p_counts5</th>\n",
       "      <th>affs5</th>\n",
       "      <th>all_years5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{columbia university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{columbia university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{columbia university}</td>\n",
       "      <td>[1940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{colgate university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{colgate university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{colgate university}</td>\n",
       "      <td>[1940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10067</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{harvard university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{harvard university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{harvard university}</td>\n",
       "      <td>[1940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10222</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>{new york university, university of buffalo}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{new york university, university of buffalo}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{new york university, university of buffalo}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{university of st. thomas}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{university of st. thomas}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{university of st. thomas}</td>\n",
       "      <td>[1940]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  a1_order_str  points20  year  c_counts20  p_counts20  \\\n",
       "0        10002       7.5  1940           0           1   \n",
       "1         1003       3.0  1940           0           1   \n",
       "2        10067       1.5  1940           0           1   \n",
       "3        10222      15.0  1940           0           2   \n",
       "4        10251       1.0  1940           0           1   \n",
       "\n",
       "                                         affs20   all_years20  points10  \\\n",
       "0                         {columbia university}        [1940]       7.5   \n",
       "1                          {colgate university}        [1940]       3.0   \n",
       "2                          {harvard university}        [1940]       1.5   \n",
       "3  {new york university, university of buffalo}  [1940, 1940]      15.0   \n",
       "4                    {university of st. thomas}        [1940]       1.0   \n",
       "\n",
       "   c_counts10  p_counts10                                        affs10  \\\n",
       "0         0.0         1.0                         {columbia university}   \n",
       "1         0.0         1.0                          {colgate university}   \n",
       "2         0.0         1.0                          {harvard university}   \n",
       "3         0.0         2.0  {new york university, university of buffalo}   \n",
       "4         0.0         1.0                    {university of st. thomas}   \n",
       "\n",
       "    all_years10  points5  c_counts5  p_counts5  \\\n",
       "0        [1940]      7.5        0.0        1.0   \n",
       "1        [1940]      3.0        0.0        1.0   \n",
       "2        [1940]      1.5        0.0        1.0   \n",
       "3  [1940, 1940]     15.0        0.0        2.0   \n",
       "4        [1940]      1.0        0.0        1.0   \n",
       "\n",
       "                                          affs5    all_years5  \n",
       "0                         {columbia university}        [1940]  \n",
       "1                          {colgate university}        [1940]  \n",
       "2                          {harvard university}        [1940]  \n",
       "3  {new york university, university of buffalo}  [1940, 1940]  \n",
       "4                    {university of st. thomas}        [1940]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1_lags_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_coauthorship_network(collabs):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(list(collabs.index))\n",
    "    unique_pairs = list(combinations(collabs.index, 2))\n",
    "\n",
    "    for i in unique_pairs:\n",
    "        if collabs.loc[i[0],i[1]]!=0:\n",
    "            G.add_edge(i[0], i[1], weight=collabs.loc[i[0],i[1]])\n",
    "    return G\n",
    "\n",
    "def get_network_features(G, author1, author2):\n",
    "    try:\n",
    "        distance = nx.shortest_path_length(G, source=author1, target=author2)\n",
    "    except nx.NetworkXNoPath:\n",
    "        distance = np.inf  # No path exists\n",
    "\n",
    "    num_paths = len(list(nx.all_shortest_paths(G, source=author1, target=author2))) if distance != np.inf else 0\n",
    "    return distance, num_paths\n",
    "\n",
    "def compute_cosine_similarity(matrix):\n",
    "    m_array = matrix.values\n",
    "    cosine_sim = cosine_similarity(m_array)\n",
    "    authors = matrix.index\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim, index=authors, columns=authors)\n",
    "    return cosine_sim_df\n",
    "\n",
    "def cit_matrix(aff_auths, order, cit_data):\n",
    "    # Merge to get citations at author level\n",
    "    print(cit_data.shape)\n",
    "    df_citations = cit_data.merge(aff_auths[[order, \"id_o\"]], on=\"id_o\")\n",
    "    print(df_citations.shape)\n",
    "    matrix = df_citations.pivot_table(\n",
    "        index=order, columns=\"match_id\", aggfunc=\"size\", fill_value=0\n",
    "    )\n",
    "    co_simm=compute_cosine_similarity(matrix)\n",
    "    return {\"matrix\":matrix,\"sim_matrix\":co_simm}\n",
    "\n",
    "def collab_matrix(aff_auths, order):\n",
    "    authors = aff_auths[order].unique()\n",
    "    author_index = {author: idx for idx, author in enumerate(authors)}\n",
    "    matrix_size = len(authors)\n",
    "    collab_matrix = np.zeros((matrix_size, matrix_size), dtype=int)\n",
    "    grouped_papers = aff_auths.groupby(\"url\")[order].apply(list)\n",
    "\n",
    "    for authors_list in grouped_papers:\n",
    "        for author1, author2 in combinations(authors_list, 2):\n",
    "            idx1, idx2 = author_index[author1], author_index[author2]\n",
    "            collab_matrix[idx1, idx2] += 1\n",
    "            collab_matrix[idx2, idx1] += 1  \n",
    "\n",
    "    collaboration_matrix = pd.DataFrame(collab_matrix, index=authors, columns=authors)\n",
    "    \n",
    "    return collaboration_matrix\n",
    "    \n",
    "def reduce_affs_jacc_sim(aff_auths, order, cits):\n",
    "    collabs=collab_matrix(aff_auths, order)\n",
    "    # o={}\n",
    "    # for i in aff_auths.index:\n",
    "    #     if aff_auths.loc[i,order] in o.keys():\n",
    "    #         o[aff_auths.loc[i,order]].update(aff_auths.loc[i,\"affs\"])  # Merge sets\n",
    "    #     else:\n",
    "    #         o[aff_auths.loc[i,order]] = aff_auths.loc[i,\"affs\"]\n",
    "\n",
    "    # Group by the \"order\" column and merge sets efficiently\n",
    "    o = aff_auths.groupby(order)[\"affs\"].agg(set.union).to_dict()\n",
    "\n",
    "    cit_mat=cit_matrix(aff_auths, order, cits)\n",
    "    \n",
    "    o_proc=[]\n",
    "    pairs = list(combinations(list(o.keys()), 2))\n",
    "    # print(cit_mat['sim_matrix'].head())\n",
    "    \n",
    "    G_t = build_coauthorship_network(collabs)\n",
    "    all_shortest_paths = dict(nx.all_pairs_shortest_path_length(G_t))  # Dictionary of shortest paths\n",
    "    \n",
    "    # Convert to DataFrame for fast lookups\n",
    "    shortest_paths_df = pd.DataFrame(\n",
    "        [(src, tgt, dist) for src, targets in all_shortest_paths.items() for tgt, dist in targets.items()],\n",
    "        columns=[\"pair_1\", \"pair_2\", \"distance\"]\n",
    "    )\n",
    "\n",
    "    print(shortest_paths_df.columns)\n",
    "    # Compute number of shortest paths\n",
    "    num_paths_dict = {\n",
    "        (a, b): len(list(nx.all_shortest_paths(G_t, a, b))) if b in all_shortest_paths[a] else 0\n",
    "        for a, targets in all_shortest_paths.items()\n",
    "        for b in targets\n",
    "    }\n",
    "\n",
    "    # Add num_paths to DataFrame\n",
    "    shortest_paths_df[\"num_paths\"] = shortest_paths_df.apply(lambda row: num_paths_dict.get((row[\"pair_1\"], row[\"pair_2\"]), 0), axis=1)\n",
    "\n",
    "    # Convert pairs list to DataFrame and merge precomputed network data\n",
    "    # pairs_df = pd.DataFrame(pairs, columns=[\"pair_1\", \"pair_2\"])\n",
    "    # pairs_df = pairs_df.merge(shortest_paths_df, on=[\"pair_1\", \"pair_2\"], how=\"left\").fillna({\"distance\": np.inf, \"num_paths\": 0})\n",
    "\n",
    "\n",
    "\n",
    "    for i in pairs:\n",
    "        # distance, num_paths = get_network_features(G_t, i[0], i[1])\n",
    "        # network_proximity = 1 / distance if distance != np.inf else 0\n",
    "        # log_num_paths = np.log(num_paths + 1)  # Avoid log(0)\n",
    "        temp={ \n",
    "                       \"pair_1\":i[0], \n",
    "                       \"pair_2\":i[1],\n",
    "                       \"aff_jacc_sim\":compute_jaccard_similarity(o[i[0]],o[i[1]]),\n",
    "                       \"collabs\": collabs.loc[i[0],i[1]],\n",
    "                    #    \"distance\": distance,\n",
    "                    #    \"network_proximity\": network_proximity,\n",
    "                    #    \"log_num_paths\":log_num_paths\n",
    "        }\n",
    "        \n",
    "        \n",
    "        if (i[0] in cit_mat[\"sim_matrix\"].index) & (i[1] in cit_mat[\"sim_matrix\"].index):\n",
    "            temp[\"cit_cos_sim\"]=cit_mat[\"sim_matrix\"].loc[i[0],i[1]]\n",
    "        else:\n",
    "            temp[\"cit_cos_sim\"]=0\n",
    "        o_proc.append(temp)\n",
    "\n",
    "    combo=pd.DataFrame(o_proc).merge(shortest_paths_df, on=[\"pair_1\", \"pair_2\"], how=\"left\").fillna({\"distance\": np.inf, \"num_paths\": 0})\n",
    "    \n",
    "    o_flat=[]\n",
    "    for i in o.keys():\n",
    "        o_flat.append({\"order\": i,\"affs\": o[i]})\n",
    "\n",
    "    \n",
    "    return {\"sims_pairs\":combo, \"aff_sets\":o, \"aff_flat_sets\": pd.DataFrame(o_flat),  \"collabs\": collabs, \"cit\":cit_mat, \"auth_net\": G_t}\n",
    "\n",
    "\n",
    "\n",
    "def data_prep(t, duration, order):\n",
    "    print(t)\n",
    "    aff_t=proc_auths_all[(proc_auths_all['year']<t+duration)&(proc_auths_all['year']>=t)].reset_index(drop=True)\n",
    "    cit_t=relevant_sub[(relevant_sub[\"year_o\"]>=t)&(relevant_sub[\"year_o\"]<t+duration)].reset_index(drop=True)\n",
    "    j_t=j_data[(j_data[\"year\"]>=t)&(j_data[\"year\"]<t+duration)][['id', \"title\", \"jid\", \"year\", \"content_type\"]].reset_index(drop=True)\n",
    "    a=time.time()\n",
    "    jaccs=reduce_affs_jacc_sim(aff_t, order, cit_t)\n",
    "    jaccs[\"j_data_t\"]=j_t\n",
    "    b=time.time()\n",
    "    print(b-a)\n",
    "    # print()\n",
    "    return jaccs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jacc_sims_10={}\n",
    "\n",
    "# for i in range(1940,2020,10):\n",
    "#     jacc_sims_10[i]=data_prep(i,10, 'a1_order')\n",
    "\n",
    "# jacc_sims_20={}\n",
    "\n",
    "# for i in range(1940,2020,20):\n",
    "#     jacc_sims_20[i]=data_prep(i,20, 'a1_order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_it(filepath, data):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def get_pickle(filepath):\n",
    "    data=None\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset (Assuming it has 'Paper_ID', 'Author', and 'Year')\n",
    "df = proc_auths_all[[\"id_o\",\"a1\",\"last\", \"a1_order_str\", \"year\"]].rename(columns={'id_o': 'Paper_ID', 'a1_order_str': 'Author', \"year\":\"Year\"})\n",
    "# Step 1: Expand multi-author papers into pairwise relationships\n",
    "df_expanded = df.groupby([\"Paper_ID\", \"Year\"])['Author'].apply(\n",
    "    lambda x: list(combinations(x, 2)) if len(x) > 1 else [(x.iloc[0], None)]\n",
    ").explode()\n",
    "\n",
    "# Convert tuples to separate columns\n",
    "df_expanded = pd.DataFrame(df_expanded.tolist(), index=df_expanded.index, columns=[\"Author\", \"Coauthor\"]).reset_index()\n",
    "\n",
    "# Keep necessary columns\n",
    "df_expanded = df_expanded[[\"Author\", \"Coauthor\", \"Year\"]]\n",
    "df_expanded_alt=df_expanded[[\"Author\", \"Coauthor\", \"Year\"]].fillna(-1)\n",
    "\n",
    "# Step 2: Count occurrences of coauthorship per year\n",
    "df_expanded[\"Coauthorship_Count\"] = df_expanded.groupby([\"Author\", \"Coauthor\", \"Year\"])['Year'].transform('count')\n",
    "df_expanded_alt[\"Coauthorship_Count\"] = df_expanded_alt.groupby([\"Author\", \"Coauthor\", \"Year\"])['Year'].transform('count')\n",
    "\n",
    "\n",
    "# Determine first and last publication year for each author\n",
    "author_first_pub = df.groupby(\"Author\")[\"Year\"].min()\n",
    "author_last_pub = df.groupby(\"Author\")[\"Year\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define year range\n",
    "start_year = 1949\n",
    "end_year = 2020\n",
    "window_10=10\n",
    "window_5=5\n",
    "window_20=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cent_measures(G):\n",
    "    max_eig=max(nx.adjacency_spectrum(G))\n",
    "    complex_num=max_eig\n",
    "    float_value = float(complex_num.real)\n",
    "    # Check if imaginary part is effectively zero\n",
    "    # has_imaginary_part = not np.isclose(complex_num.imag, 0)\n",
    "    # components = list(nx.connected_components(G))\n",
    "    # print(f\"Network has {len(components)} disconnected components\")\n",
    "    # Convert to float (only if it's safe to do so)\n",
    "    # if has_imaginary_part:\n",
    "        # print(f\"Warning: Number has imaginary component: {complex_num.imag}\")\n",
    "        # Handle appropriately - either use abs() or raise error\n",
    "    # else:\n",
    "        # float_value = float(complex_num.real)\n",
    "        # print(f\"Converted to float: {float_value}\")\n",
    "    centrality_measures = {\n",
    "        \"degree\": nx.degree_centrality(G),\n",
    "        \"betweenness\": nx.betweenness_centrality(G),\n",
    "        \"closeness\": nx.closeness_centrality(G),\n",
    "        \"eigenvector\": nx.eigenvector_centrality(G),\n",
    "        \"pagerank\": nx.pagerank(G),\n",
    "        # \"katz\": nx.katz_centrality(G, alpha=1/(max_eig+1), max_iter=100000),\n",
    "        'katz':nx.katz_centrality_numpy(G, alpha=1/(float_value+1)),\n",
    "        \"harmonic\": nx.harmonic_centrality(G),\n",
    "    }\n",
    "    return centrality_measures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>Year</th>\n",
       "      <th>Coauthorship_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2479</td>\n",
       "      <td>-1</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2943</td>\n",
       "      <td>3681</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3600</td>\n",
       "      <td>-1</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12923</td>\n",
       "      <td>-1</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356</td>\n",
       "      <td>12149</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Author Coauthor  Year  Coauthorship_Count\n",
       "0   2479       -1  1998                   1\n",
       "1   2943     3681  1998                   1\n",
       "2   3600       -1  1998                   1\n",
       "3  12923       -1  1998                   1\n",
       "4    356    12149  1998                   1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expanded_alt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>Year</th>\n",
       "      <th>Coauthorship_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2479</td>\n",
       "      <td>None</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2943</td>\n",
       "      <td>3681</td>\n",
       "      <td>1998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3600</td>\n",
       "      <td>None</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12923</td>\n",
       "      <td>None</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356</td>\n",
       "      <td>12149</td>\n",
       "      <td>1998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Author Coauthor  Year  Coauthorship_Count\n",
       "0   2479     None  1998                 NaN\n",
       "1   2943     3681  1998                 1.0\n",
       "2   3600     None  1998                 NaN\n",
       "3  12923     None  1998                 NaN\n",
       "4    356    12149  1998                 1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 to 1936\n",
      "0.018382787704467773\n",
      "1941 to 1937\n",
      "0.014557838439941406\n",
      "1942 to 1938\n",
      "0.021886110305786133\n",
      "1943 to 1939\n",
      "0.02733898162841797\n",
      "1944 to 1940\n",
      "0.03339195251464844\n",
      "1945 to 1941\n",
      "0.03278923034667969\n",
      "1946 to 1942\n",
      "0.03696107864379883\n",
      "1947 to 1943\n",
      "0.03502798080444336\n",
      "1948 to 1944\n",
      "0.03610110282897949\n",
      "1949 to 1945\n",
      "0.03364109992980957\n",
      "1950 to 1946\n",
      "0.03672003746032715\n",
      "1951 to 1947\n",
      "0.03069305419921875\n",
      "1952 to 1948\n",
      "0.03229403495788574\n",
      "1953 to 1949\n",
      "0.03426694869995117\n",
      "1954 to 1950\n",
      "0.03651285171508789\n",
      "1955 to 1951\n",
      "0.037810325622558594\n",
      "1956 to 1952\n",
      "0.0336909294128418\n",
      "1957 to 1953\n",
      "0.03226590156555176\n",
      "1958 to 1954\n",
      "0.0317378044128418\n",
      "1959 to 1955\n",
      "0.032956838607788086\n",
      "1960 to 1956\n",
      "0.034303903579711914\n",
      "1961 to 1957\n",
      "0.03418326377868652\n",
      "1962 to 1958\n",
      "0.03529477119445801\n",
      "1963 to 1959\n",
      "0.035317182540893555\n",
      "1964 to 1960\n",
      "0.037719011306762695\n",
      "1965 to 1961\n",
      "0.05210304260253906\n",
      "1966 to 1962\n",
      "0.04176521301269531\n",
      "1967 to 1963\n",
      "0.04269099235534668\n",
      "1968 to 1964\n",
      "0.04473590850830078\n",
      "1969 to 1965\n",
      "0.050653934478759766\n",
      "1970 to 1966\n",
      "0.05664992332458496\n",
      "1971 to 1967\n",
      "0.06085801124572754\n",
      "1972 to 1968\n",
      "0.06600785255432129\n",
      "1973 to 1969\n",
      "0.07016110420227051\n",
      "1974 to 1970\n",
      "0.07141685485839844\n",
      "1975 to 1971\n",
      "0.07067084312438965\n",
      "1976 to 1972\n",
      "0.07135224342346191\n",
      "1977 to 1973\n",
      "0.07181787490844727\n",
      "1978 to 1974\n",
      "0.07067680358886719\n",
      "1979 to 1975\n",
      "0.07229900360107422\n",
      "1980 to 1976\n",
      "0.07959604263305664\n",
      "1981 to 1977\n",
      "0.07845115661621094\n",
      "1982 to 1978\n",
      "0.0759119987487793\n",
      "1983 to 1979\n",
      "0.08243107795715332\n",
      "1984 to 1980\n",
      "0.07821011543273926\n",
      "1985 to 1981\n",
      "0.08101820945739746\n",
      "1986 to 1982\n",
      "0.07742476463317871\n",
      "1987 to 1983\n",
      "0.0722050666809082\n",
      "1988 to 1984\n",
      "0.07090926170349121\n",
      "1989 to 1985\n",
      "0.07383608818054199\n",
      "1990 to 1986\n",
      "0.06879687309265137\n",
      "1991 to 1987\n",
      "0.06939196586608887\n",
      "1992 to 1988\n",
      "0.07363104820251465\n",
      "1993 to 1989\n",
      "0.07279205322265625\n",
      "1994 to 1990\n",
      "0.07420110702514648\n",
      "1995 to 1991\n",
      "0.07017278671264648\n",
      "1996 to 1992\n",
      "0.06758904457092285\n",
      "1997 to 1993\n",
      "0.06615996360778809\n",
      "1998 to 1994\n",
      "0.06619501113891602\n",
      "1999 to 1995\n",
      "0.06999778747558594\n",
      "2000 to 1996\n",
      "0.0685279369354248\n",
      "2001 to 1997\n",
      "0.07189702987670898\n",
      "2002 to 1998\n",
      "0.07420110702514648\n",
      "2003 to 1999\n",
      "0.0772407054901123\n",
      "2004 to 2000\n",
      "0.07770109176635742\n",
      "2005 to 2001\n",
      "0.08468890190124512\n",
      "2006 to 2002\n",
      "0.08643078804016113\n",
      "2007 to 2003\n",
      "0.08594012260437012\n",
      "2008 to 2004\n",
      "0.09163212776184082\n",
      "2009 to 2005\n",
      "0.09192085266113281\n",
      "2010 to 2006\n",
      "0.09661722183227539\n",
      "2011 to 2007\n",
      "0.10721468925476074\n",
      "2012 to 2008\n",
      "0.11437726020812988\n",
      "2013 to 2009\n",
      "0.1239931583404541\n",
      "2014 to 2010\n",
      "0.130540132522583\n",
      "2015 to 2011\n",
      "0.13431310653686523\n",
      "2016 to 2012\n",
      "0.13725900650024414\n",
      "2017 to 2013\n",
      "0.1566629409790039\n",
      "2018 to 2014\n",
      "0.14549612998962402\n",
      "2019 to 2015\n",
      "0.14649605751037598\n",
      "2020 to 2016\n",
      "0.1508948802947998\n"
     ]
    }
   ],
   "source": [
    "window=5\n",
    "start_year=1940\n",
    "# Step 4: Iterate over each year t\n",
    "for t in range(start_year, end_year + 1):\n",
    "    w=window-1\n",
    "    net_dist=[]\n",
    "    a=time.time()\n",
    "    print(str(t) + \" to \"+str(t-w))\n",
    "    min_year = t - w  # Define 10-year rolling window\n",
    "    max_year = t\n",
    "    \n",
    "    # Filter data for the current 10-year period\n",
    "    df_window = df_expanded_alt[(df_expanded_alt[\"Year\"] >= min_year) & (df_expanded_alt[\"Year\"] <= max_year)]\n",
    "    \n",
    "    # Build coauthorship network\n",
    "    G = nx.Graph()\n",
    "    for _, row in df_window.iterrows():\n",
    "        if row[\"Coauthor\"]==-1:\n",
    "            G.add_node(row[\"Author\"], weight=row[\"Coauthorship_Count\"])\n",
    "        else:\n",
    "            G.add_edge(row[\"Author\"], row[\"Coauthor\"], weight=row[\"Coauthorship_Count\"])\n",
    "    \n",
    "    nx.write_gexf(G, nets_path+str(t)+\"-\"+str(min_year)+\"_\"+str(window)+\"Y.gexf\", encoding='utf-8')\n",
    "    b=time.time()\n",
    "    print(b-a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sijiawu/Work/80YearsEconomicResearch/032_auth_graph_gen/networks/'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nets_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx simple paths usage takes way too long\n",
    "\n",
    "def count_paths_with_exact_length(G, source, target, length):\n",
    "    return sum(1 for path in nx.all_simple_paths(G, source, target, cutoff=length) \n",
    "               if len(path) - 1 == length)\n",
    "\n",
    "\n",
    "def find_kth_shortest_path(G,source, target, k=2):\n",
    "    results = defaultdict(dict)\n",
    "\n",
    "    all_paths = [(len(path)-1, path) for path in nx.all_simple_paths(G, source, target)] #add cutoff\n",
    "    all_paths.sort()\n",
    "\n",
    "\n",
    "    # Group paths by length\n",
    "    path_groups = {}\n",
    "    for length, path in all_paths:\n",
    "        if length not in path_groups:\n",
    "            path_groups[length] = []\n",
    "        path_groups[length].append(path)\n",
    "    \n",
    "    # Get distinct lengths and sort them\n",
    "    lengths = sorted(path_groups.keys())\n",
    "    \n",
    "    # If we have at least k different lengths, return one path from the kth group\n",
    "    if len(lengths) >= k:\n",
    "        kth_shortest_length = lengths[k-1]\n",
    "        kth_shortest_path = path_groups[kth_shortest_length][0]  # Get one path of this length\n",
    "        results[source][target] = (kth_shortest_path, \"Success\")\n",
    "    else:\n",
    "        results[source][target] = ([], f\"Only {len(lengths)} path lengths found\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def find_kth_shortest_paths_all_pairs(G, k=2, limit=5):\n",
    "    \"\"\"\n",
    "    Find the kth shortest path for each pair of nodes in graph G.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : networkx.Graph\n",
    "        The input graph\n",
    "    k : int\n",
    "        Which shortest path to find (1 for shortest, 2 for second shortest, etc.)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict of dict\n",
    "        A nested dictionary where result[source][target] contains a tuple of\n",
    "        (path, status) where path is the kth shortest path and status explains\n",
    "        any issues if the path doesn't exist.\n",
    "    \"\"\"\n",
    "    results = defaultdict(dict)\n",
    "    \n",
    "    for source in G.nodes():\n",
    "        for target in G.nodes():\n",
    "            if source == target:\n",
    "                # Skip self-loops\n",
    "                results[source][target] = ([], \"Same node\")\n",
    "                continue\n",
    "\n",
    "            # Check if there's a path between source and target\n",
    "            if not nx.has_path(G, source, target):\n",
    "                results[source][target] = ([], \"No path exists\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Get all simple paths and their lengths\n",
    "                all_paths = [(len(path)-1, path) for path in nx.all_simple_paths(G, source, target, cutoff=limit)]\n",
    "                \n",
    "                # Sort paths by length\n",
    "                all_paths.sort()\n",
    "                \n",
    "                # Group paths by length\n",
    "                path_groups = {}\n",
    "                for length, path in all_paths:\n",
    "                    if length not in path_groups:\n",
    "                        path_groups[length] = []\n",
    "                    path_groups[length].append(path)\n",
    "                \n",
    "                # Get distinct lengths and sort them\n",
    "                lengths = sorted(path_groups.keys())\n",
    "                \n",
    "                # If we have at least k different lengths, return one path from the kth group\n",
    "                if len(lengths) >= k:\n",
    "                    kth_shortest_length = lengths[k-1]\n",
    "                    kth_shortest_path = path_groups[kth_shortest_length][0]  # Get one path of this length\n",
    "                    results[source][target] = (kth_shortest_path, \"Success\")\n",
    "                else:\n",
    "                    results[source][target] = ([], f\"Only {len(lengths)} path lengths found\")\n",
    "            except Exception as e:\n",
    "                results[source][target] = ([], f\"Error: {e}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt count simple paths up to a point, \n",
    "\n",
    "def count_simple_paths_of_length(G, source, target, length):\n",
    "    \"\"\"\n",
    "    Counts the number of simple paths of exact length between source and target.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : NetworkX graph\n",
    "    source : node\n",
    "        Starting node\n",
    "    target : node\n",
    "        Ending node\n",
    "    length : int\n",
    "        Desired path length (number of edges)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        Number of simple paths with exactly the specified length\n",
    "    \"\"\"\n",
    "    # Counter to keep track of the number of paths\n",
    "    path_count = [0]  # Using list for mutable reference in nested function\n",
    "    \n",
    "    # Keep track of visited nodes to ensure simple paths\n",
    "    visited = {source: True}\n",
    "    \n",
    "    def dfs(current, steps_remaining):\n",
    "        # If we've reached the target with the exact length\n",
    "        if current == target and steps_remaining == 0:\n",
    "            path_count[0] += 1\n",
    "            return\n",
    "        \n",
    "        # If we've used all steps but haven't reached target, or reached target too early\n",
    "        if steps_remaining == 0 or current == target:\n",
    "            return\n",
    "            \n",
    "        # Continue DFS\n",
    "        for neighbor in G.neighbors(current):\n",
    "            if neighbor not in visited:\n",
    "                visited[neighbor] = True\n",
    "                dfs(neighbor, steps_remaining - 1)\n",
    "                del visited[neighbor]  # Backtrack\n",
    "    \n",
    "    # Start DFS from source\n",
    "    dfs(source, length)\n",
    "    return path_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>First_Year</th>\n",
       "      <th>Last_Year</th>\n",
       "      <th>a1</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>paul segerstrom</td>\n",
       "      <td>segerstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1972</td>\n",
       "      <td>2016</td>\n",
       "      <td>benjamin m. friedman</td>\n",
       "      <td>friedman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>dana foarta</td>\n",
       "      <td>foarta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>charles r. blitzer</td>\n",
       "      <td>blitzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>1941</td>\n",
       "      <td>1941</td>\n",
       "      <td>h. g. white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Author First_Year Last_Year                    a1        last\n",
       "0      0       1999      1999       paul segerstrom  segerstrom\n",
       "1      1       1972      2016  benjamin m. friedman    friedman\n",
       "2     10       2018      2018           dana foarta      foarta\n",
       "3    100       1970      1970    charles r. blitzer     blitzer\n",
       "4   1000       1941      1941           h. g. white       white"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo=author_first_pub.reset_index().rename(columns={\"Year\": \"First_Year\"}).merge(author_last_pub.reset_index().rename(columns={\"Year\": \"Last_Year\"}), on=\"Author\").merge(df[[\"Author\",\"a1\",\"last\"]].groupby(\"Author\").first().reset_index(), on=\"Author\")\n",
    "combo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23582, 6)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ex_na=df_expanded[df_expanded[\"Coauthor\"].isna()==False].reset_index(drop=True)\n",
    "df_ex_na[\"Ai\"]=df_ex_na[\"Author\"].astype(int)\n",
    "df_ex_na[\"Ci\"]=df_ex_na[\"Coauthor\"].astype(int)\n",
    "df_ex_na['Author'] = df_ex_na[['Ai', 'Ci']].min(axis=1).astype(str)\n",
    "df_ex_na['Coauthor'] = df_ex_na[['Ai', 'Ci']].max(axis=1).astype(str)\n",
    "df_ex_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18834, 10)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collabs=df_ex_na[[\"Author\",\"Coauthor\"]].groupby([\"Author\",\"Coauthor\"]).first().reset_index()\n",
    "collabs_merge=collabs.merge(combo, on=\"Author\").merge(combo.rename(columns={\"Author\":\"Coauthor\",\"First_Year\":\"First_Year_C\", \"Last_Year\":\"Last_Year_C\", \"a1\":\"a1_C\", \"last\":\"last_C\"}), on=\"Coauthor\")\n",
    "collabs_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>First_Year</th>\n",
       "      <th>Last_Year</th>\n",
       "      <th>a1</th>\n",
       "      <th>last</th>\n",
       "      <th>First_Year_C</th>\n",
       "      <th>Last_Year_C</th>\n",
       "      <th>a1_C</th>\n",
       "      <th>last_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13607</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>paul segerstrom</td>\n",
       "      <td>segerstrom</td>\n",
       "      <td>1990</td>\n",
       "      <td>1999</td>\n",
       "      <td>elias dinopoulos</td>\n",
       "      <td>dinopoulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11603</td>\n",
       "      <td>1972</td>\n",
       "      <td>2016</td>\n",
       "      <td>benjamin m. friedman</td>\n",
       "      <td>friedman</td>\n",
       "      <td>1978</td>\n",
       "      <td>2008</td>\n",
       "      <td>zvi bodie</td>\n",
       "      <td>bodie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13039</td>\n",
       "      <td>1972</td>\n",
       "      <td>2016</td>\n",
       "      <td>benjamin m. friedman</td>\n",
       "      <td>friedman</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>kenneth n. kuttner</td>\n",
       "      <td>kuttner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16885</td>\n",
       "      <td>1972</td>\n",
       "      <td>2016</td>\n",
       "      <td>benjamin m. friedman</td>\n",
       "      <td>friedman</td>\n",
       "      <td>1979</td>\n",
       "      <td>1985</td>\n",
       "      <td>v. v. roley</td>\n",
       "      <td>roley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9433</td>\n",
       "      <td>1972</td>\n",
       "      <td>2016</td>\n",
       "      <td>benjamin m. friedman</td>\n",
       "      <td>friedman</td>\n",
       "      <td>1990</td>\n",
       "      <td>1999</td>\n",
       "      <td>mark j. warshawsky</td>\n",
       "      <td>warshawsky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Author Coauthor First_Year Last_Year                    a1        last  \\\n",
       "0      0    13607       1999      1999       paul segerstrom  segerstrom   \n",
       "1      1    11603       1972      2016  benjamin m. friedman    friedman   \n",
       "2      1    13039       1972      2016  benjamin m. friedman    friedman   \n",
       "3      1    16885       1972      2016  benjamin m. friedman    friedman   \n",
       "4      1     9433       1972      2016  benjamin m. friedman    friedman   \n",
       "\n",
       "  First_Year_C Last_Year_C                a1_C      last_C  \n",
       "0         1990        1999    elias dinopoulos  dinopoulos  \n",
       "1         1978        2008           zvi bodie       bodie  \n",
       "2         1992        1992  kenneth n. kuttner     kuttner  \n",
       "3         1979        1985         v. v. roley       roley  \n",
       "4         1990        1999  mark j. warshawsky  warshawsky  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collabs_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yijt = {}\n",
    "a=0\n",
    "for x in collabs_merge.index:\n",
    "    i=collabs_merge.loc[x,'Author']\n",
    "    j=collabs_merge.loc[x,'Coauthor']\n",
    "    ti_0=collabs_merge.loc[x,'First_Year']\n",
    "    tj_0=collabs_merge.loc[x,'First_Year_C']\n",
    "    tij_0=max(ti_0,tj_0)\n",
    "    ti_2=collabs_merge.loc[x,'Last_Year']\n",
    "    tj_2=collabs_merge.loc[x,'Last_Year_C']\n",
    "    tij_2=min(ti_2,tj_2)\n",
    "    collab_ij=df_ex_na[(df_ex_na[\"Author\"]==i)&(df_ex_na[\"Coauthor\"]==j)]\n",
    "    collab_years=collab_ij[\"Year\"].to_list()\n",
    "    # if len(collab_ij[\"Year\"].unique())!=collab_ij.shape[0]:\n",
    "    #     # print(x)\n",
    "    #     a+=1\n",
    "    tij_1=min(collab_ij[\"Year\"])\n",
    "\n",
    "    for y in range(tij_0, tij_2+1):\n",
    "        if y not in collab_years:\n",
    "            df_yijt[a]={\"Author\":i, \"Coauthor\":j, \"tij\":y, \"ytij\":0, \"tij_1\":tij_1, \"tij_2\":tij_2, \"tij_0\":tij_0, \n",
    "                        # \"Paper_ID\":\"\"\n",
    "                        }\n",
    "            a+=1\n",
    "            # print(y)\n",
    "    for y in collab_ij.index:\n",
    "        # print(\" \"+str(collab_ij.loc[y,\"Year\"]))\n",
    "        df_yijt[a]={\"Author\":i, \"Coauthor\":j, \"tij\":collab_ij.loc[y,\"Year\"], \"ytij\":1, \"tij_1\":tij_1, \"tij_2\":tij_2, \"tij_0\":tij_0, \n",
    "                    # \"Paper_ID\":collab_ij.loc[y,\"Paper_ID\"]\n",
    "                    }\n",
    "        a+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y=pd.DataFrame(df_yijt).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>tij</th>\n",
       "      <th>ytij</th>\n",
       "      <th>tij_1</th>\n",
       "      <th>tij_2</th>\n",
       "      <th>tij_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13607</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11603</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>1978</td>\n",
       "      <td>2008</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11603</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>1978</td>\n",
       "      <td>2008</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11603</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>1978</td>\n",
       "      <td>2008</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11603</td>\n",
       "      <td>1982</td>\n",
       "      <td>0</td>\n",
       "      <td>1978</td>\n",
       "      <td>2008</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Author Coauthor   tij ytij tij_1 tij_2 tij_0\n",
       "0      0    13607  1999    1  1999  1999  1999\n",
       "1      1    11603  1979    0  1978  2008  1978\n",
       "2      1    11603  1980    0  1978  2008  1978\n",
       "3      1    11603  1981    0  1978  2008  1978\n",
       "4      1    11603  1982    0  1978  2008  1978"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108470, 7)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42395, 7)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y[df_y[\"tij_0\"]==df_y[\"tij_1\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54145, 7)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y[df_y[\"tij\"]<=df_y[\"tij_1\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms=[\"i\",\"j\",\"distance\", \"total_paths\", \"avg_path_length\", \"pij_t\", \"shortest_path_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_second_shortest_paths(G, source, target):\n",
    "    \"\"\"\n",
    "    Find the count of second shortest simple paths between source and target.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : NetworkX graph\n",
    "    source : node\n",
    "        Starting node\n",
    "    target : node\n",
    "        Ending node\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (second_shortest_length, count) - Length of second shortest path and count of paths with that length\n",
    "    \"\"\"\n",
    "    # Use Dijkstra's algorithm to find distances to all nodes\n",
    "    import heapq\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # Track distances and path counts\n",
    "    # For each node, we'll store (distance, count of paths with that distance)\n",
    "    distances = {node: float('infinity') for node in G.nodes()}\n",
    "    distances[source] = 0\n",
    "    \n",
    "    # For each node, we'll maintain a sorted list of (distance, count) pairs\n",
    "    path_info = defaultdict(list)\n",
    "    path_info[source].append((0, 1))  # (distance, count)\n",
    "    \n",
    "    # Priority queue for Dijkstra's algorithm\n",
    "    pq = [(0, source)]\n",
    "    \n",
    "    while pq:\n",
    "        dist, node = heapq.heappop(pq)\n",
    "        \n",
    "        # Skip outdated entries\n",
    "        if dist > distances[node]:\n",
    "            continue\n",
    "            \n",
    "        # Process neighbors\n",
    "        for neighbor in G.neighbors(node):\n",
    "            # Get edge weight (1 for unweighted graphs)\n",
    "            weight = G[node][neighbor].get('weight', 1)\n",
    "            \n",
    "            # Calculate new distance\n",
    "            new_dist = dist + weight\n",
    "            \n",
    "            # If we found a new distance to this neighbor\n",
    "            if new_dist <= distances[neighbor]:\n",
    "                # If it's a shorter path, update distance\n",
    "                if new_dist < distances[neighbor]:\n",
    "                    distances[neighbor] = new_dist\n",
    "                    heapq.heappush(pq, (new_dist, neighbor))\n",
    "                    path_info[neighbor] = [(new_dist, 0)]  # Reset path count\n",
    "                \n",
    "                # Count paths with this distance\n",
    "                # Find paths to 'node' with distance = dist\n",
    "                for d, count in path_info[node]:\n",
    "                    if d == dist:\n",
    "                        # Update count for the distance at neighbor\n",
    "                        for i, (nd, nc) in enumerate(path_info[neighbor]):\n",
    "                            if nd == new_dist:\n",
    "                                path_info[neighbor][i] = (nd, nc + count)\n",
    "                                break\n",
    "                        else:\n",
    "                            path_info[neighbor].append((new_dist, count))\n",
    "    \n",
    "    # Sort path_info for the target to get shortest and second shortest\n",
    "    target_info = sorted(path_info[target])\n",
    "    \n",
    "    # If there's only one distance or no paths\n",
    "    if len(target_info) <= 1:\n",
    "        return None, 0\n",
    "    \n",
    "    # Return second shortest distance and its count\n",
    "    return target_info[1][0], target_info[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_excluding_direct(G, source, target):\n",
    "    \"\"\"\n",
    "    Find the shortest path between source and target,\n",
    "    ignoring any direct edge between them.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : NetworkX graph\n",
    "    source : node\n",
    "        Starting node\n",
    "    target : node\n",
    "        Ending node\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        The shortest path excluding direct connection, or None if no such path exists\n",
    "    \"\"\"\n",
    "    # Check if a direct edge exists\n",
    "    has_direct_edge = G.has_edge(source, target)\n",
    "    \n",
    "    if has_direct_edge:\n",
    "        # Temporarily remove the direct edge\n",
    "        edge_data = None\n",
    "        \n",
    "        # For simple graphs\n",
    "        edge_data = G.get_edge_data(source, target)\n",
    "        G.remove_edge(source, target)\n",
    "        \n",
    "        try:\n",
    "            # Find the shortest path without the direct edge\n",
    "            path = list(nx.all_shortest_paths(G, source, target))\n",
    "            return path\n",
    "        except nx.NetworkXNoPath:\n",
    "            # No alternate path exists\n",
    "            return None\n",
    "        finally:\n",
    "            G.add_edge(source, target, **edge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "updates = []\n",
    "c=0\n",
    "for t in range(1950,2021):\n",
    "    \n",
    "    G=nx.read_gexf(nets_path+str(t-1)+\"-\"+str(t-9-1)+\"_10Y.gexf\")\n",
    "    nodes=G.nodes\n",
    "    # print(len(nodes))\n",
    "    print(\"\\r\"+str(t))\n",
    "    for i in df_y[df_y[\"tij\"]==t].index:\n",
    "        # c+=1\n",
    "        # if c>50:\n",
    "        #     break\n",
    "        source=df_y.loc[i,\"Author\"]\n",
    "        target=df_y.loc[i,\"Coauthor\"]\n",
    "        source_conf=source in nodes\n",
    "        target_conf=target in nodes\n",
    "        if source_conf & target_conf:\n",
    "            if nx.has_path(G, source, target):\n",
    "                paths = list(nx.all_shortest_paths(G, source, target))\n",
    "                distance=len(paths[0])-1                \n",
    "                pij=1/distance\n",
    "                \n",
    "                if distance==1:\n",
    "                    excl=shortest_path_excluding_direct(G, source, target)\n",
    "                    \n",
    "                    if excl==None:\n",
    "                        distance=float('inf')\n",
    "                        count=0\n",
    "                        pij=0\n",
    "                    else:\n",
    "                        distance=len(excl[0])-1\n",
    "                        count=len(excl)\n",
    "                        pij=1/distance\n",
    "                        \n",
    "                updates.append(df_y.iloc[i].to_dict()|\n",
    "                                {   \n",
    "                                    \"tij\":t,\n",
    "                                    \"tij-1\":t-1,\n",
    "                                    \"Author\":source,\n",
    "                                    \"Coauthor\":target, \n",
    "                                    \"distance\": distance, \n",
    "                                    \"pij_t\":pij,\n",
    "                                    \"cij_t\":len(paths),\n",
    "                                    \"A\":source_conf, \n",
    "                                    \"C\":target_conf,\n",
    "                                    \"E\":0\n",
    "                                }\n",
    "                            )\n",
    "            else:\n",
    "                updates.append(df_y.iloc[i].to_dict()|\n",
    "                                {   \n",
    "                                    \"tij\":t,\n",
    "                                    \"tij-1\":t-1,\n",
    "                                    \"Author\":source,\n",
    "                                    \"Coauthor\":target, \n",
    "                                    \"distance\": float('inf'),\n",
    "                                    \"pij_t\": 0,\n",
    "                                    \"cij_t\":0,\n",
    "                                    \"A\":source_conf, \n",
    "                                    \"C\":target_conf,\n",
    "                                    \"E\":0\n",
    "                                }\n",
    "                            )\n",
    "        else:\n",
    "            if source_conf |target_conf:\n",
    "                updates.append(df_y.iloc[i].to_dict()|\n",
    "                                    {   \n",
    "                                        \"tij\":t,\n",
    "                                        \"tij-1\":t-1,\n",
    "                                        \"Author\":source,\n",
    "                                        \"Coauthor\":target, \n",
    "                                        \"distance\": float('inf'),\n",
    "                                        \"pij_t\":0, \n",
    "                                        \"cij_t\":0,\n",
    "                                        \"A\":source_conf, \n",
    "                                        \"C\":target_conf,\n",
    "                                        \"E\":1\n",
    "                                    }\n",
    "                                )\n",
    "            else:\n",
    "                updates.append(df_y.iloc[i].to_dict()|\n",
    "                                    {   \n",
    "                                        \"tij\":t,\n",
    "                                        \"tij-1\":t-1,\n",
    "                                        \"Author\":source,\n",
    "                                        \"Coauthor\":target, \n",
    "                                        \"distance\": float('inf'),\n",
    "                                        \"pij_t\":0, \n",
    "                                        \"cij_t\":0,\n",
    "                                        \"A\":source_conf, \n",
    "                                        \"C\":target_conf,\n",
    "                                        \"E\":2\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "updates_5 = []\n",
    "c=0\n",
    "for t in range(1945,2021):\n",
    "    G=nx.read_gexf(nets_path+str(t-1)+\"-\"+str(t-4-1)+\"_5Y.gexf\")\n",
    "    nodes=G.nodes\n",
    "    # print(len(nodes))\n",
    "    print(t)\n",
    "    for i in df_y[df_y[\"tij\"]==t].index:\n",
    "        # c+=1\n",
    "        # if c>50:\n",
    "        #     break\n",
    "        source=df_y.loc[i,\"Author\"]\n",
    "        target=df_y.loc[i,\"Coauthor\"]\n",
    "        source_conf=source in nodes\n",
    "        target_conf=target in nodes\n",
    "        if source_conf & target_conf:\n",
    "            if nx.has_path(G, source, target):\n",
    "                paths = list(nx.all_shortest_paths(G, source, target))\n",
    "                distance=len(paths[0])-1                \n",
    "                pij=1/distance\n",
    "                \n",
    "                if distance==1:\n",
    "                    excl=shortest_path_excluding_direct(G, source, target)\n",
    "                    \n",
    "                    if excl==None:\n",
    "                        distance=float('inf')\n",
    "                        count=0\n",
    "                        pij=0\n",
    "                    else:\n",
    "                        distance=len(excl[0])-1\n",
    "                        count=len(excl)\n",
    "                        pij=1/distance\n",
    "                        \n",
    "                updates_5.append(df_y.iloc[i].to_dict()|\n",
    "                                {   \n",
    "                                    \"tij\":t,\n",
    "                                    \"tij-1\":t-1,\n",
    "                                    \"Author\":source,\n",
    "                                    \"Coauthor\":target, \n",
    "                                    \"distance\": distance, \n",
    "                                    \"pij_t\":pij,\n",
    "                                    \"cij_t\":len(paths),\n",
    "                                    \"A\":source_conf, \n",
    "                                    \"C\":target_conf,\n",
    "                                    \"E\":0\n",
    "                                }\n",
    "                            )\n",
    "            else:\n",
    "                updates_5.append(df_y.iloc[i].to_dict()|\n",
    "                                {   \n",
    "                                    \"tij\":t,\n",
    "                                    \"tij-1\":t-1,\n",
    "                                    \"Author\":source,\n",
    "                                    \"Coauthor\":target, \n",
    "                                    \"distance\": float('inf'),\n",
    "                                    \"pij_t\": 0,\n",
    "                                    \"cij_t\":0,\n",
    "                                    \"A\":source_conf, \n",
    "                                    \"C\":target_conf,\n",
    "                                    \"E\":0\n",
    "                                }\n",
    "                            )\n",
    "        else:\n",
    "            if source_conf |target_conf:\n",
    "                updates_5.append(df_y.iloc[i].to_dict()|\n",
    "                                    {   \n",
    "                                        \"tij\":t,\n",
    "                                        \"tij-1\":t-1,\n",
    "                                        \"Author\":source,\n",
    "                                        \"Coauthor\":target, \n",
    "                                        \"distance\": float('inf'),\n",
    "                                        \"pij_t\":0, \n",
    "                                        \"cij_t\":0,\n",
    "                                        \"A\":source_conf, \n",
    "                                        \"C\":target_conf,\n",
    "                                        \"E\":1\n",
    "                                    }\n",
    "                                )\n",
    "            else:\n",
    "                updates_5.append(df_y.iloc[i].to_dict()|\n",
    "                                    {   \n",
    "                                        \"tij\":t,\n",
    "                                        \"tij-1\":t-1,\n",
    "                                        \"Author\":source,\n",
    "                                        \"Coauthor\":target, \n",
    "                                        \"distance\": float('inf'),\n",
    "                                        \"pij_t\":0, \n",
    "                                        \"cij_t\":0,\n",
    "                                        \"A\":source_conf, \n",
    "                                        \"C\":target_conf,\n",
    "                                        \"E\":2\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "updates_20 = []\n",
    "c=0\n",
    "for t in range(1960,2021):\n",
    "    G=nx.read_gexf(nets_path+str(t-1)+\"-\"+str(t-19-1)+\"_20Y.gexf\")\n",
    "    nodes=G.nodes\n",
    "    # print(len(nodes))\n",
    "    print(t)\n",
    "    for i in df_y[df_y[\"tij\"]==t].index:\n",
    "        # c+=1\n",
    "        # if c>50:\n",
    "        #     break\n",
    "        source=df_y.loc[i,\"Author\"]\n",
    "        target=df_y.loc[i,\"Coauthor\"]\n",
    "        source_conf=source in nodes\n",
    "        target_conf=target in nodes\n",
    "        if source_conf & target_conf:\n",
    "            if nx.has_path(G, source, target):\n",
    "                paths = list(nx.all_shortest_paths(G, source, target))\n",
    "                distance=len(paths[0])-1                \n",
    "                pij=1/distance\n",
    "                \n",
    "                if distance==1:\n",
    "                    excl=shortest_path_excluding_direct(G, source, target)\n",
    "                    \n",
    "                    if excl==None:\n",
    "                        distance=float('inf')\n",
    "                        count=0\n",
    "                        pij=0\n",
    "                    else:\n",
    "                        distance=len(excl[0])-1\n",
    "                        count=len(excl)\n",
    "                        pij=1/distance\n",
    "                        \n",
    "                updates_20.append(df_y.iloc[i].to_dict()|\n",
    "                                {   \n",
    "                                    \"tij\":t,\n",
    "                                    \"tij-1\":t-1,\n",
    "                                    \"Author\":source,\n",
    "                                    \"Coauthor\":target, \n",
    "                                    \"distance\": distance, \n",
    "                                    \"pij_t\":pij,\n",
    "                                    \"cij_t\":len(paths),\n",
    "                                    \"A\":source_conf, \n",
    "                                    \"C\":target_conf,\n",
    "                                    \"E\":0\n",
    "                                }\n",
    "                            )\n",
    "            else:\n",
    "                updates_20.append(df_y.iloc[i].to_dict()|\n",
    "                                {   \n",
    "                                    \"tij\":t,\n",
    "                                    \"tij-1\":t-1,\n",
    "                                    \"Author\":source,\n",
    "                                    \"Coauthor\":target, \n",
    "                                    \"distance\": float('inf'),\n",
    "                                    \"pij_t\": 0,\n",
    "                                    \"cij_t\":0,\n",
    "                                    \"A\":source_conf, \n",
    "                                    \"C\":target_conf,\n",
    "                                    \"E\":0\n",
    "                                }\n",
    "                            )\n",
    "        else:\n",
    "            if source_conf |target_conf:\n",
    "                updates_20.append(df_y.iloc[i].to_dict()|\n",
    "                                    {   \n",
    "                                        \"tij\":t,\n",
    "                                        \"tij-1\":t-1,\n",
    "                                        \"Author\":source,\n",
    "                                        \"Coauthor\":target, \n",
    "                                        \"distance\": float('inf'),\n",
    "                                        \"pij_t\":0, \n",
    "                                        \"cij_t\":0,\n",
    "                                        \"A\":source_conf, \n",
    "                                        \"C\":target_conf,\n",
    "                                        \"E\":1\n",
    "                                    }\n",
    "                                )\n",
    "            else:\n",
    "                updates_20.append(df_y.iloc[i].to_dict()|\n",
    "                                    {   \n",
    "                                        \"tij\":t,\n",
    "                                        \"tij-1\":t-1,\n",
    "                                        \"Author\":source,\n",
    "                                        \"Coauthor\":target, \n",
    "                                        \"distance\": float('inf'),\n",
    "                                        \"pij_t\":0, \n",
    "                                        \"cij_t\":0,\n",
    "                                        \"A\":source_conf, \n",
    "                                        \"C\":target_conf,\n",
    "                                        \"E\":2\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd=pd.DataFrame(updates)\n",
    "upd_5=pd.DataFrame(updates_5)\n",
    "upd_20=pd.DataFrame(updates_20)\n",
    "\n",
    "# upd.to_pickle(\"upd.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>tij</th>\n",
       "      <th>ytij</th>\n",
       "      <th>tij_1</th>\n",
       "      <th>tij_2</th>\n",
       "      <th>tij_0</th>\n",
       "      <th>tij-1</th>\n",
       "      <th>distance</th>\n",
       "      <th>pij_t</th>\n",
       "      <th>cij_t</th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023</td>\n",
       "      <td>15700</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1940</td>\n",
       "      <td>1949</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10177</td>\n",
       "      <td>12194</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>1972</td>\n",
       "      <td>1950</td>\n",
       "      <td>1949</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10333</td>\n",
       "      <td>10980</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1946</td>\n",
       "      <td>1957</td>\n",
       "      <td>1940</td>\n",
       "      <td>1949</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10333</td>\n",
       "      <td>11857</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1946</td>\n",
       "      <td>1957</td>\n",
       "      <td>1946</td>\n",
       "      <td>1949</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10333</td>\n",
       "      <td>12583</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1946</td>\n",
       "      <td>1952</td>\n",
       "      <td>1941</td>\n",
       "      <td>1949</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Author Coauthor   tij  ytij  tij_1  tij_2  tij_0  tij-1  distance  pij_t  \\\n",
       "0  10023    15700  1950     0   1952   1952   1940   1949       inf    0.0   \n",
       "1  10177    12194  1950     0   1956   1972   1950   1949       inf    0.0   \n",
       "2  10333    10980  1950     0   1946   1957   1940   1949       2.0    0.5   \n",
       "3  10333    11857  1950     0   1946   1957   1946   1949       2.0    0.5   \n",
       "4  10333    12583  1950     0   1946   1952   1941   1949       2.0    0.5   \n",
       "\n",
       "   cij_t     A      C  E  \n",
       "0      0  True   True  0  \n",
       "1      0  True  False  1  \n",
       "2      1  True   True  0  \n",
       "3      1  True   True  0  \n",
       "4      1  True   True  0  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1_order_str</th>\n",
       "      <th>points20</th>\n",
       "      <th>year</th>\n",
       "      <th>c_counts20</th>\n",
       "      <th>p_counts20</th>\n",
       "      <th>affs20</th>\n",
       "      <th>all_years20</th>\n",
       "      <th>points10</th>\n",
       "      <th>c_counts10</th>\n",
       "      <th>p_counts10</th>\n",
       "      <th>affs10</th>\n",
       "      <th>all_years10</th>\n",
       "      <th>points5</th>\n",
       "      <th>c_counts5</th>\n",
       "      <th>p_counts5</th>\n",
       "      <th>affs5</th>\n",
       "      <th>all_years5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>{london united kingdom (city)}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{london united kingdom (city)}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{london united kingdom (city)}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10055</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{london united kingdom (city)}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{london united kingdom (city)}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{london united kingdom (city)}</td>\n",
       "      <td>[1940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10125</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{harvard university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{harvard university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{harvard university}</td>\n",
       "      <td>[1940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10263</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1940</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{university of california - berkeley, university of california}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{university of california - berkeley, university of california}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{university of california - berkeley, university of california}</td>\n",
       "      <td>[1940, 1940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10273</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{colgate university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{colgate university}</td>\n",
       "      <td>[1940]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{colgate university}</td>\n",
       "      <td>[1940]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  a1_order_str   points20  year  c_counts20  p_counts20  \\\n",
       "0        10023   4.500000  1940           0           2   \n",
       "1        10055   5.500000  1940           0           1   \n",
       "2        10125   5.500000  1940           0           1   \n",
       "3        10263  11.333333  1940           1           2   \n",
       "4        10273   3.000000  1940           0           1   \n",
       "\n",
       "                                                            affs20  \\\n",
       "0                                   {london united kingdom (city)}   \n",
       "1                                   {london united kingdom (city)}   \n",
       "2                                             {harvard university}   \n",
       "3  {university of california - berkeley, university of california}   \n",
       "4                                             {colgate university}   \n",
       "\n",
       "    all_years20   points10  c_counts10  p_counts10  \\\n",
       "0  [1940, 1940]   4.500000         0.0         2.0   \n",
       "1        [1940]   5.500000         0.0         1.0   \n",
       "2        [1940]   5.500000         0.0         1.0   \n",
       "3  [1940, 1940]  11.333333         1.0         2.0   \n",
       "4        [1940]   3.000000         0.0         1.0   \n",
       "\n",
       "                                                            affs10  \\\n",
       "0                                   {london united kingdom (city)}   \n",
       "1                                   {london united kingdom (city)}   \n",
       "2                                             {harvard university}   \n",
       "3  {university of california - berkeley, university of california}   \n",
       "4                                             {colgate university}   \n",
       "\n",
       "    all_years10    points5  c_counts5  p_counts5  \\\n",
       "0  [1940, 1940]   4.500000        0.0        2.0   \n",
       "1        [1940]   5.500000        0.0        1.0   \n",
       "2        [1940]   5.500000        0.0        1.0   \n",
       "3  [1940, 1940]  11.333333        1.0        2.0   \n",
       "4        [1940]   3.000000        0.0        1.0   \n",
       "\n",
       "                                                             affs5  \\\n",
       "0                                   {london united kingdom (city)}   \n",
       "1                                   {london united kingdom (city)}   \n",
       "2                                             {harvard university}   \n",
       "3  {university of california - berkeley, university of california}   \n",
       "4                                             {colgate university}   \n",
       "\n",
       "     all_years5  \n",
       "0  [1940, 1940]  \n",
       "1        [1940]  \n",
       "2        [1940]  \n",
       "3  [1940, 1940]  \n",
       "4        [1940]  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1_lags_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_w_lags_10=upd.merge(a1_lags_points[[\"a1_order_str\",\"year\", \"points10\",\"c_counts10\",\"p_counts10\"]], left_on=[\"Author\", \"tij-1\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"points10\":\"p-a\", \"c_counts10\":\"co-a\",\"p_counts10\":\"pa-a\"}).merge(a1_lags_points[[\"a1_order_str\",\"year\", \"points10\",\"c_counts10\",\"p_counts10\"]], left_on=[\"Coauthor\", \"tij-1\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"points10\":\"p-c\",\"c_counts10\":\"co-c\",\"p_counts10\":\"pa-c\"}).drop(columns=[\"a1_order_str_x\", \"year_x\",\"a1_order_str_y\", \"year_y\"]).fillna(0)\n",
    "upd_w_lags_5=upd.merge(a1_lags_points[[\"a1_order_str\",\"year\", \"points5\",\"c_counts5\",\"p_counts5\"]], left_on=[\"Author\", \"tij-1\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"points5\":\"p-a\",\"c_counts5\":\"co-a\",\"p_counts5\":\"pa-a\"}).merge(a1_lags_points[[\"a1_order_str\",\"year\", \"points5\", \"c_counts5\",\"p_counts5\"]], left_on=[\"Coauthor\", \"tij-1\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"points5\":\"p-c\", \"c_counts5\":\"co-c\",\"p_counts5\":\"pa-c\"}).drop(columns=[\"a1_order_str_x\", \"year_x\",\"a1_order_str_y\", \"year_y\"]).fillna(0)\n",
    "upd_w_lags_20=upd.merge(a1_lags_points[[\"a1_order_str\",\"year\", \"points20\",\"c_counts20\",\"p_counts20\"]], left_on=[\"Author\", \"tij-1\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"points20\":\"p-a\", \"c_counts20\":\"co-a\",\"p_counts20\":\"pa-a\"}).merge(a1_lags_points[[\"a1_order_str\",\"year\", \"points20\", \"c_counts20\",\"p_counts20\"]], left_on=[\"Coauthor\", \"tij-1\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"points20\":\"p-c\", \"c_counts20\":\"co-c\",\"p_counts20\":\"pa-c\"}).drop(columns=[\"a1_order_str_x\", \"year_x\",\"a1_order_str_y\", \"year_y\"]).fillna(0)\n",
    "\n",
    "upd_w_lags_10=upd_w_lags_10.merge(a1_lags_points[[\"a1_order_str\",\"year\",\"affs10\"]], left_on=[\"Author\", \"tij\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"affs10\":\"affs-a\"}).merge(a1_lags_points[[\"a1_order_str\",\"year\",\"affs10\"]], left_on=[\"Coauthor\", \"tij\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"affs10\":\"affs-c\"}).drop(columns=[\"a1_order_str_x\", \"year_x\",\"a1_order_str_y\", \"year_y\"]).fillna({})\n",
    "upd_w_lags_5=upd_w_lags_5.merge(a1_lags_points[[\"a1_order_str\",\"year\",\"affs5\"]], left_on=[\"Author\", \"tij\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"affs5\":\"affs-a\"}).merge(a1_lags_points[[\"a1_order_str\",\"year\",\"affs5\"]], left_on=[\"Coauthor\", \"tij\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"affs5\":\"affs-c\"}).drop(columns=[\"a1_order_str_x\", \"year_x\",\"a1_order_str_y\", \"year_y\"]).fillna({})\n",
    "upd_w_lags_20=upd_w_lags_20.merge(a1_lags_points[[\"a1_order_str\",\"year\",\"affs20\"]], left_on=[\"Author\", \"tij\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"affs20\":\"affs-a\"}).merge(a1_lags_points[[\"a1_order_str\",\"year\",\"affs20\"]], left_on=[\"Coauthor\", \"tij\"], right_on=[\"a1_order_str\", \"year\"], how=\"left\").rename(columns={\"affs20\":\"affs-c\"}).drop(columns=[\"a1_order_str_x\", \"year_x\",\"a1_order_str_y\", \"year_y\"]).fillna({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auth_ord</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>last</th>\n",
       "      <th>affs</th>\n",
       "      <th>year</th>\n",
       "      <th>content_type</th>\n",
       "      <th>jid</th>\n",
       "      <th>url</th>\n",
       "      <th>...</th>\n",
       "      <th>a2_order</th>\n",
       "      <th>a3_order</th>\n",
       "      <th>fl</th>\n",
       "      <th>a1_tk_count</th>\n",
       "      <th>id_o</th>\n",
       "      <th>a1_order_str</th>\n",
       "      <th>count</th>\n",
       "      <th>page_count</th>\n",
       "      <th>points</th>\n",
       "      <th>c_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10240</th>\n",
       "      <td>0</td>\n",
       "      <td>george p. shultz</td>\n",
       "      <td>g. p. shultz</td>\n",
       "      <td>g. shultz</td>\n",
       "      <td>shultz</td>\n",
       "      <td>{stanford university}</td>\n",
       "      <td>1995</td>\n",
       "      <td>Article</td>\n",
       "      <td>aer</td>\n",
       "      <td>https://www.jstor.org/stable/2117882</td>\n",
       "      <td>...</td>\n",
       "      <td>11538</td>\n",
       "      <td>8765</td>\n",
       "      <td>george shultz</td>\n",
       "      <td>3</td>\n",
       "      <td>2117882</td>\n",
       "      <td>960</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19469</th>\n",
       "      <td>0</td>\n",
       "      <td>george p. shultz</td>\n",
       "      <td>g. p. shultz</td>\n",
       "      <td>g. shultz</td>\n",
       "      <td>shultz</td>\n",
       "      <td>{massachusetts institute of technology - mit}</td>\n",
       "      <td>1950</td>\n",
       "      <td>Article</td>\n",
       "      <td>aer</td>\n",
       "      <td>https://www.jstor.org/stable/1802208</td>\n",
       "      <td>...</td>\n",
       "      <td>11538</td>\n",
       "      <td>8765</td>\n",
       "      <td>george shultz</td>\n",
       "      <td>3</td>\n",
       "      <td>1802208</td>\n",
       "      <td>960</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      auth_ord                a1            a2         a3    last  \\\n",
       "10240        0  george p. shultz  g. p. shultz  g. shultz  shultz   \n",
       "19469        0  george p. shultz  g. p. shultz  g. shultz  shultz   \n",
       "\n",
       "                                                affs  year content_type  jid  \\\n",
       "10240                          {stanford university}  1995      Article  aer   \n",
       "19469  {massachusetts institute of technology - mit}  1950      Article  aer   \n",
       "\n",
       "                                        url  ... a2_order a3_order  \\\n",
       "10240  https://www.jstor.org/stable/2117882  ...    11538     8765   \n",
       "19469  https://www.jstor.org/stable/1802208  ...    11538     8765   \n",
       "\n",
       "                  fl a1_tk_count     id_o a1_order_str count  page_count  \\\n",
       "10240  george shultz           3  2117882          960     1         8.0   \n",
       "19469  george shultz           3  1802208          960     2        19.0   \n",
       "\n",
       "         points  c_count  \n",
       "10240  4.000000        0  \n",
       "19469  6.333333        1  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_auths_all[proc_auths_all[\"a1_order_str\"]==\"960\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "otw=0\n",
    "difs=[]\n",
    "for i in proc_auths_all[\"a1_order_str\"].unique():\n",
    "    temp=proc_auths_all[proc_auths_all[\"a1_order_str\"]==i].sort_values('year')\n",
    "    tempi=temp.index\n",
    "    if len(tempi)>1:\n",
    "        dif=0\n",
    "        for j in range(len(tempi)-1):\n",
    "            dif+=(proc_auths_all.loc[tempi[j+1],\"year\"]-proc_auths_all.loc[tempi[j],\"year\"])\n",
    "        avg_dif=dif/(len(tempi)-1)\n",
    "        # print(avg_dif)\n",
    "        difs.append({\"a1_order_str\":i,\"avg-d\":avg_dif,\"dif\":dif,\"pubs\":len(tempi)})\n",
    "    else:\n",
    "        otw+=1\n",
    "        difs.append({\"a1_order_str\":i,\"avg-d\":0,\"dif\":0,\"pubs\":len(tempi)}) \n",
    "\n",
    "authstat=pd.DataFrame(difs)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1_order_str</th>\n",
       "      <th>avg-d</th>\n",
       "      <th>dif</th>\n",
       "      <th>pubs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2982</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14901</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  a1_order_str  avg-d  dif  pubs\n",
       "0         2982    0.5    2     5\n",
       "1        13024    1.0    1     2\n",
       "2        14901    2.0    2     2\n",
       "3        15321    0.0    0     1\n",
       "4         7031    0.0    0     1"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authstat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.249980344104996"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(authstat[authstat[\"pubs\"]>1][\"avg-d\"])/authstat[authstat[\"pubs\"]>1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.249980344104996"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sum(authstat[authstat[\"pubs\"]>1][\"avg-d\"])/authstat[authstat[\"pubs\"]>1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3528.5"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authstat[authstat[\"avg-d\"]>0].shape[0]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(authstat[authstat[\"avg-d\"]>0][\"avg-d\"].sort_values())[3529]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 4)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authstat[authstat[\"avg-d\"]>20].sort_values(\"avg-d\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "collabs20=list(authstat[authstat[\"avg-d\"]>20][\"a1_order_str\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 4)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authstat[authstat[\"avg-d\"]>10].sort_values(\"avg-d\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "collabs10=list(authstat[authstat[\"avg-d\"]>10][\"a1_order_str\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "collaborators=list(set(upd_w_lags_10[\"Author\"].unique()).union(set(upd_w_lags_10[\"Coauthor\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(collaborators).intersection(set(collabs10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(collaborators).intersection(set(collabs20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plothist(authstat,\"avg-d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17304"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proc_auths_all[\"a1_order_str\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>tij</th>\n",
       "      <th>ytij</th>\n",
       "      <th>tij_1</th>\n",
       "      <th>tij_2</th>\n",
       "      <th>tij_0</th>\n",
       "      <th>tij-1</th>\n",
       "      <th>distance</th>\n",
       "      <th>pij_t</th>\n",
       "      <th>...</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>p-a</th>\n",
       "      <th>co-a</th>\n",
       "      <th>pa-a</th>\n",
       "      <th>p-c</th>\n",
       "      <th>co-c</th>\n",
       "      <th>pa-c</th>\n",
       "      <th>affs-a</th>\n",
       "      <th>affs-c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Author, Coauthor, tij, ytij, tij_1, tij_2, tij_0, tij-1, distance, pij_t, cij_t, A, C, E, p-a, co-a, pa-a, p-c, co-c, pa-c, affs-a, affs-c]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10[upd_w_lags_10[\"affs-a\"]==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>tij</th>\n",
       "      <th>ytij</th>\n",
       "      <th>tij_1</th>\n",
       "      <th>tij_2</th>\n",
       "      <th>tij_0</th>\n",
       "      <th>tij-1</th>\n",
       "      <th>distance</th>\n",
       "      <th>pij_t</th>\n",
       "      <th>...</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>p-a</th>\n",
       "      <th>co-a</th>\n",
       "      <th>pa-a</th>\n",
       "      <th>p-c</th>\n",
       "      <th>co-c</th>\n",
       "      <th>pa-c</th>\n",
       "      <th>affs-a</th>\n",
       "      <th>affs-c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>6040</td>\n",
       "      <td>13164</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1951</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.166667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{cambridge massachusetts united states (city), rand corporation, massachusetts institute of tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>6040</td>\n",
       "      <td>13275</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1951</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{institute for advanced study, princeton, new jersey, board of governors of the federal reserve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>6040</td>\n",
       "      <td>15421</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1951</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{columbia university, conservatoire national des arts et metiers, stanford university, universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>6040</td>\n",
       "      <td>7352</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1951</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{committee for economic development, takoma park, md. (city), american enterprise institute for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>6040</td>\n",
       "      <td>8721</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1951</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>6040</td>\n",
       "      <td>9240</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1951</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{university of chicago, princeton university}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Author Coauthor   tij  ytij  tij_1  tij_2  tij_0  tij-1  distance  pij_t  \\\n",
       "682   6040    13164  1952     1   1952   1952   1952   1951       inf    0.0   \n",
       "683   6040    13275  1952     1   1952   1952   1952   1951       inf    0.0   \n",
       "684   6040    15421  1952     1   1952   1952   1952   1951       inf    0.0   \n",
       "685   6040     7352  1952     1   1952   1952   1952   1951       inf    0.0   \n",
       "686   6040     8721  1952     1   1952   1952   1952   1951       inf    0.0   \n",
       "687   6040     9240  1952     1   1952   1952   1952   1951       inf    0.0   \n",
       "\n",
       "     ...      C  E  p-a  co-a  pa-a         p-c  co-c  pa-c  affs-a  \\\n",
       "682  ...   True  1  0.0   0.0   0.0   63.166667   4.0  13.0      {}   \n",
       "683  ...   True  1  0.0   0.0   0.0   20.750000  18.0   5.0      {}   \n",
       "684  ...   True  1  0.0   0.0   0.0  102.333333   5.0  12.0      {}   \n",
       "685  ...   True  1  0.0   0.0   0.0    2.500000   0.0   2.0      {}   \n",
       "686  ...  False  2  0.0   0.0   0.0    0.000000   0.0   0.0      {}   \n",
       "687  ...   True  1  0.0   0.0   0.0   36.000000   0.0   4.0      {}   \n",
       "\n",
       "                                                                                                  affs-c  \n",
       "682  {cambridge massachusetts united states (city), rand corporation, massachusetts institute of tech...  \n",
       "683  {institute for advanced study, princeton, new jersey, board of governors of the federal reserve ...  \n",
       "684  {columbia university, conservatoire national des arts et metiers, stanford university, universit...  \n",
       "685  {committee for economic development, takoma park, md. (city), american enterprise institute for ...  \n",
       "686                                                                                                   {}  \n",
       "687                                                        {university of chicago, princeton university}  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10[upd_w_lags_10[\"Author\"]==\"6040\"] #8721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_w_lags_10[\"avg_p\"]=(upd_w_lags_10[\"p-a\"]+upd_w_lags_10[\"p-c\"])/2\n",
    "upd_w_lags_10[\"abs_p\"]=abs(upd_w_lags_10[\"p-a\"]-upd_w_lags_10[\"p-c\"])\n",
    "upd_w_lags_10[\"c-a\"]=upd_w_lags_10[\"co-a\"]/upd_w_lags_10[\"pa-a\"]\n",
    "upd_w_lags_10[\"c-c\"]=upd_w_lags_10[\"co-c\"]/upd_w_lags_10[\"pa-c\"]\n",
    "upd_w_lags_10=upd_w_lags_10.fillna(0)\n",
    "upd_w_lags_10[\"avg_c\"]=(upd_w_lags_10[\"c-a\"]+upd_w_lags_10[\"c-c\"])/2\n",
    "upd_w_lags_10[\"abs_c\"]=abs(upd_w_lags_10[\"c-a\"]-upd_w_lags_10[\"c-c\"])\n",
    "for i in upd_w_lags_10.index:\n",
    "    if (upd_w_lags_10.loc[i,'affs-a']==0)|(upd_w_lags_10.loc[i,'affs-c']==0):\n",
    "        upd_w_lags_10.loc[i,'aff_js']=0\n",
    "    else:\n",
    "        if (len(upd_w_lags_10.loc[i,'affs-a'])==0)|(len(upd_w_lags_10.loc[i,'affs-c'])==0):\n",
    "            upd_w_lags_10.loc[i,'aff_js']=0\n",
    "        else:\n",
    "            upd_w_lags_10.loc[i,'aff_js']=len(upd_w_lags_10.loc[i,'affs-a'].intersection(upd_w_lags_10.loc[i,'affs-c']))/len(upd_w_lags_10.loc[i,'affs-a'].union(upd_w_lags_10.loc[i,'affs-c']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "upd_w_lags_20[\"avg_p\"]=(upd_w_lags_20[\"p-a\"]+upd_w_lags_20[\"p-c\"])/2\n",
    "upd_w_lags_20[\"abs_p\"]=abs(upd_w_lags_20[\"p-a\"]-upd_w_lags_20[\"p-c\"])\n",
    "upd_w_lags_20[\"c-a\"]=upd_w_lags_20[\"co-a\"]/upd_w_lags_20[\"pa-a\"]\n",
    "upd_w_lags_20[\"c-c\"]=upd_w_lags_20[\"co-c\"]/upd_w_lags_20[\"pa-c\"]\n",
    "upd_w_lags_20=upd_w_lags_20.fillna(0)\n",
    "upd_w_lags_20[\"avg_c\"]=(upd_w_lags_20[\"c-a\"]+upd_w_lags_20[\"c-c\"])/2\n",
    "upd_w_lags_20[\"abs_c\"]=abs(upd_w_lags_20[\"c-a\"]-upd_w_lags_20[\"c-c\"])\n",
    "for i in upd_w_lags_20.index:\n",
    "    if (upd_w_lags_20.loc[i,'affs-a']==0)|(upd_w_lags_20.loc[i,'affs-c']==0):\n",
    "        upd_w_lags_20.loc[i,'aff_js']=0\n",
    "    else:\n",
    "        if (len(upd_w_lags_20.loc[i,'affs-a'])==0)|(len(upd_w_lags_20.loc[i,'affs-c'])==0):\n",
    "            upd_w_lags_20.loc[i,'aff_js']=0\n",
    "        else:\n",
    "            upd_w_lags_20.loc[i,'aff_js']=len(upd_w_lags_20.loc[i,'affs-a'].intersection(upd_w_lags_20.loc[i,'affs-c']))/len(upd_w_lags_20.loc[i,'affs-a'].union(upd_w_lags_20.loc[i,'affs-c']))\n",
    "\n",
    "\n",
    "\n",
    "upd_w_lags_5[\"avg_p\"]=(upd_w_lags_5[\"p-a\"]+upd_w_lags_5[\"p-c\"])/2\n",
    "upd_w_lags_5[\"abs_p\"]=abs(upd_w_lags_5[\"p-a\"]-upd_w_lags_5[\"p-c\"])\n",
    "upd_w_lags_5[\"c-a\"]=upd_w_lags_5[\"co-a\"]/upd_w_lags_5[\"pa-a\"]\n",
    "upd_w_lags_5[\"c-c\"]=upd_w_lags_5[\"co-c\"]/upd_w_lags_5[\"pa-c\"]\n",
    "upd_w_lags_5=upd_w_lags_5.fillna(0)\n",
    "upd_w_lags_5[\"avg_c\"]=(upd_w_lags_5[\"c-a\"]+upd_w_lags_5[\"c-c\"])/2\n",
    "upd_w_lags_5[\"abs_c\"]=abs(upd_w_lags_5[\"c-a\"]-upd_w_lags_5[\"c-c\"])\n",
    "for i in upd_w_lags_5.index:\n",
    "    if (upd_w_lags_5.loc[i,'affs-a']==0)|(upd_w_lags_5.loc[i,'affs-c']==0):\n",
    "        upd_w_lags_5.loc[i,'aff_js']=0\n",
    "    else:\n",
    "        if (len(upd_w_lags_5.loc[i,'affs-a'])==0)|(len(upd_w_lags_5.loc[i,'affs-c'])==0):\n",
    "            upd_w_lags_5.loc[i,'aff_js']=0\n",
    "        else:\n",
    "            upd_w_lags_5.loc[i,'aff_js']=len(upd_w_lags_5.loc[i,'affs-a'].intersection(upd_w_lags_5.loc[i,'affs-c']))/len(upd_w_lags_5.loc[i,'affs-a'].union(upd_w_lags_5.loc[i,'affs-c']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_w_lags_10.to_pickle(\"flattened_co-author_10.pkl\")\n",
    "upd_w_lags_20.to_pickle(\"flattened_co-author_20.pkl\")\n",
    "upd_w_lags_5.to_pickle(\"flattened_co-author_5.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upd_w_lags_10.dropna().to_csv(\"flattened_co-author_10.csv\")\n",
    "upd_w_lags_20.dropna().to_csv(\"flattened_co-author_20.csv\")\n",
    "upd_w_lags_5.dropna().to_csv(\"flattened_co-author_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>tij</th>\n",
       "      <th>ytij</th>\n",
       "      <th>tij_1</th>\n",
       "      <th>tij_2</th>\n",
       "      <th>tij_0</th>\n",
       "      <th>tij-1</th>\n",
       "      <th>distance</th>\n",
       "      <th>pij_t</th>\n",
       "      <th>...</th>\n",
       "      <th>pa-c</th>\n",
       "      <th>affs-a</th>\n",
       "      <th>affs-c</th>\n",
       "      <th>avg_p</th>\n",
       "      <th>abs_p</th>\n",
       "      <th>c-a</th>\n",
       "      <th>c-c</th>\n",
       "      <th>avg_c</th>\n",
       "      <th>abs_c</th>\n",
       "      <th>aff_js</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023</td>\n",
       "      <td>15700</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1940</td>\n",
       "      <td>1949</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>{university of liverpool}</td>\n",
       "      <td>{university of chicago}</td>\n",
       "      <td>10.916667</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10177</td>\n",
       "      <td>12194</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>1972</td>\n",
       "      <td>1950</td>\n",
       "      <td>1949</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{iowa state university, university of minnesota, carnegie mellon university, university of chicago}</td>\n",
       "      <td>{university of minnesota}</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10333</td>\n",
       "      <td>10980</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1946</td>\n",
       "      <td>1957</td>\n",
       "      <td>1940</td>\n",
       "      <td>1949</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>{council of economic advisors, washington dc, cornell university}</td>\n",
       "      <td>{university of chicago}</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10333</td>\n",
       "      <td>11857</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1946</td>\n",
       "      <td>1957</td>\n",
       "      <td>1946</td>\n",
       "      <td>1949</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{council of economic advisors, washington dc, cornell university}</td>\n",
       "      <td>{harvard university}</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10333</td>\n",
       "      <td>12583</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1946</td>\n",
       "      <td>1952</td>\n",
       "      <td>1941</td>\n",
       "      <td>1949</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>{council of economic advisors, washington dc, cornell university}</td>\n",
       "      <td>{columbia university, national bureau of economic research - nber, new york city united states (...</td>\n",
       "      <td>17.281250</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Author Coauthor   tij  ytij  tij_1  tij_2  tij_0  tij-1  distance  pij_t  \\\n",
       "0  10023    15700  1950     0   1952   1952   1940   1949       inf    0.0   \n",
       "1  10177    12194  1950     0   1956   1972   1950   1949       inf    0.0   \n",
       "2  10333    10980  1950     0   1946   1957   1940   1949       2.0    0.5   \n",
       "3  10333    11857  1950     0   1946   1957   1946   1949       2.0    0.5   \n",
       "4  10333    12583  1950     0   1946   1952   1941   1949       2.0    0.5   \n",
       "\n",
       "   ...  pa-c  \\\n",
       "0  ...   3.0   \n",
       "1  ...   0.0   \n",
       "2  ...  16.0   \n",
       "3  ...   1.0   \n",
       "4  ...   6.0   \n",
       "\n",
       "                                                                                                affs-a  \\\n",
       "0                                                                            {university of liverpool}   \n",
       "1  {iowa state university, university of minnesota, carnegie mellon university, university of chicago}   \n",
       "2                                    {council of economic advisors, washington dc, cornell university}   \n",
       "3                                    {council of economic advisors, washington dc, cornell university}   \n",
       "4                                    {council of economic advisors, washington dc, cornell university}   \n",
       "\n",
       "                                                                                                affs-c  \\\n",
       "0                                                                              {university of chicago}   \n",
       "1                                                                            {university of minnesota}   \n",
       "2                                                                              {university of chicago}   \n",
       "3                                                                                 {harvard university}   \n",
       "4  {columbia university, national bureau of economic research - nber, new york city united states (...   \n",
       "\n",
       "       avg_p      abs_p       c-a        c-c      avg_c      abs_c  aff_js  \n",
       "0  10.916667   7.833333  0.000000   0.666667   0.333333   0.666667    0.00  \n",
       "1   3.916667   7.833333  0.333333   0.000000   0.166667   0.333333    0.25  \n",
       "2  61.250000  87.000000  4.500000   1.125000   2.812500   3.375000    0.00  \n",
       "3   9.000000  17.500000  4.500000  18.000000  11.250000  13.500000    0.00  \n",
       "4  17.281250   0.937500  4.500000   5.333333   4.916667   0.833333    0.00  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106190, 29)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>tij</th>\n",
       "      <th>ytij</th>\n",
       "      <th>tij_1</th>\n",
       "      <th>tij_2</th>\n",
       "      <th>tij_0</th>\n",
       "      <th>tij-1</th>\n",
       "      <th>distance</th>\n",
       "      <th>pij_t</th>\n",
       "      <th>...</th>\n",
       "      <th>pa-c</th>\n",
       "      <th>affs-a</th>\n",
       "      <th>affs-c</th>\n",
       "      <th>avg_p</th>\n",
       "      <th>abs_p</th>\n",
       "      <th>c-a</th>\n",
       "      <th>c-c</th>\n",
       "      <th>avg_c</th>\n",
       "      <th>abs_c</th>\n",
       "      <th>aff_js</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10177</td>\n",
       "      <td>12194</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>1972</td>\n",
       "      <td>1950</td>\n",
       "      <td>1949</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{iowa state university, university of minnesota, carnegie mellon university, university of chicago}</td>\n",
       "      <td>{university of minnesota}</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12553</td>\n",
       "      <td>14396</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1949</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{dun and bradstreet}</td>\n",
       "      <td>{dun and bradstreet}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1273</td>\n",
       "      <td>15278</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1949</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{cambridge massachusetts united states (city)}</td>\n",
       "      <td>{cambridge massachusetts united states (city)}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>13861</td>\n",
       "      <td>15423</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1949</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{northwestern university}</td>\n",
       "      <td>{northwestern university}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>5881</td>\n",
       "      <td>8596</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>1950</td>\n",
       "      <td>1975</td>\n",
       "      <td>1950</td>\n",
       "      <td>1949</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{university of washington, university of georgia}</td>\n",
       "      <td>{university of washington}</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Author Coauthor   tij  ytij  tij_1  tij_2  tij_0  tij-1  distance  pij_t  \\\n",
       "1    10177    12194  1950     0   1956   1972   1950   1949       inf    0.0   \n",
       "32   12553    14396  1950     1   1950   1950   1950   1949       inf    0.0   \n",
       "39    1273    15278  1950     1   1950   1950   1950   1949       inf    0.0   \n",
       "49   13861    15423  1950     1   1950   1950   1950   1949       inf    0.0   \n",
       "180   5881     8596  1950     1   1950   1975   1950   1949       inf    0.0   \n",
       "\n",
       "     ...  pa-c  \\\n",
       "1    ...   0.0   \n",
       "32   ...   0.0   \n",
       "39   ...   0.0   \n",
       "49   ...   0.0   \n",
       "180  ...   0.0   \n",
       "\n",
       "                                                                                                  affs-a  \\\n",
       "1    {iowa state university, university of minnesota, carnegie mellon university, university of chicago}   \n",
       "32                                                                                  {dun and bradstreet}   \n",
       "39                                                        {cambridge massachusetts united states (city)}   \n",
       "49                                                                             {northwestern university}   \n",
       "180                                                    {university of washington, university of georgia}   \n",
       "\n",
       "                                             affs-c     avg_p      abs_p  \\\n",
       "1                         {university of minnesota}  3.916667   7.833333   \n",
       "32                             {dun and bradstreet}  0.000000   0.000000   \n",
       "39   {cambridge massachusetts united states (city)}  0.000000   0.000000   \n",
       "49                        {northwestern university}  0.000000   0.000000   \n",
       "180                      {university of washington}  5.000000  10.000000   \n",
       "\n",
       "          c-a  c-c     avg_c     abs_c  aff_js  \n",
       "1    0.333333  0.0  0.166667  0.333333    0.25  \n",
       "32   0.000000  0.0  0.000000  0.000000    1.00  \n",
       "39   0.000000  0.0  0.000000  0.000000    1.00  \n",
       "49   0.000000  0.0  0.000000  0.000000    1.00  \n",
       "180  0.000000  0.0  0.000000  0.000000    0.50  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10[upd_w_lags_10[\"pa-c\"]==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upd=pd.read_pickle(\"upd.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18385, 2)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10[[\"Author\",\"Coauthor\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Author', 'Coauthor', 'tij', 'ytij', 'tij_1', 'tij_2', 'tij_0', 'tij-1',\n",
       "       'distance', 'pij_t', 'cij_t', 'A', 'C', 'E', 'p-a', 'co-a', 'pa-a',\n",
       "       'p-c', 'co-c', 'pa-c', 'affs-a', 'affs-c', 'avg_p', 'abs_p', 'c-a',\n",
       "       'c-c', 'avg_c', 'abs_c', 'aff_js'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_a=upd_w_lags_10[['Author', 'Coauthor', 'tij', 'ytij', 'tij_1', 'tij_2', 'tij_0', 'tij-1',\n",
    "       'distance', 'pij_t', 'cij_t', 'A', 'C', 'E', 'avg_p', 'abs_p', 'avg_c', 'abs_c', 'aff_js']]\n",
    "df_y_b=df_y_a.reset_index(drop=True).fillna(0).drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "df_f=df_y_b[df_y_b[\"tij\"]<=df_y_b[\"tij_1\"]].reset_index(drop=True)\n",
    "df_c=df_y_b[df_y_b[\"tij\"]>df_y_b[\"tij_1\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_b_5=upd_w_lags_5[['Author', 'Coauthor', 'tij', 'ytij', 'tij_1', 'tij_2', 'tij_0', 'tij-1',\n",
    "       'distance', 'pij_t', 'cij_t', 'A', 'C', 'E', 'avg_p', 'abs_p', 'avg_c', 'abs_c', 'aff_js']].reset_index(drop=True).fillna(0).drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "df_f_5=df_y_b_5[df_y_b_5[\"tij\"]<=df_y_b_5[\"tij_1\"]].reset_index(drop=True)\n",
    "df_c_5=df_y_b_5[df_y_b_5[\"tij\"]>df_y_b_5[\"tij_1\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_b_20=upd_w_lags_20[['Author', 'Coauthor', 'tij', 'ytij', 'tij_1', 'tij_2', 'tij_0', 'tij-1',\n",
    "       'distance', 'pij_t', 'cij_t', 'A', 'C', 'E', 'avg_p', 'abs_p', 'avg_c', 'abs_c', 'aff_js']].reset_index(drop=True).fillna(0).drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "df_f_20=df_y_b_20[df_y_b_20[\"tij\"]<=df_y_b_20[\"tij_1\"]].reset_index(drop=True)\n",
    "df_c_20=df_y_b_20[df_y_b_20[\"tij\"]>df_y_b_20[\"tij_1\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a numerical column for histogram (replace 'column_name' with actual column)\n",
    "def plothist(df,column_name):\n",
    "    # Plot histogram\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(df[column_name], bins=30, color='blue', alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Histogram of {column_name}\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def conf_stat(conf):\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(str(tn)+\"true neg\")\n",
    "    print(str(fp)+\"false pos\")\n",
    "    print(str(fn)+\"false neg\")\n",
    "    print(str(tp)+\"true pos\")\n",
    "    # Multi-class:\n",
    "    precisions = np.zeros(conf.shape[0])\n",
    "    recalls = np.zeros(conf.shape[0])\n",
    "    \n",
    "    for i in range(conf.shape[0]):\n",
    "        # Calculate precision and recall for class i\n",
    "        true_pos = conf[i, i]\n",
    "        false_pos = sum(conf[:, i]) - true_pos\n",
    "        false_neg = sum(conf[i, :]) - true_pos\n",
    "        \n",
    "        # Handle division by zero\n",
    "        precisions[i] = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "        recalls[i] = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
    "\n",
    "    # Calculate averages if needed\n",
    "    macro_precision = np.mean(precisions)\n",
    "    macro_recall = np.mean(recalls)\n",
    "\n",
    "\n",
    "# Function to calculate statistics for logistic regression\n",
    "def get_logistic_regression_stats(model, X, feature_names=None):\n",
    "    \"\"\"\n",
    "    Calculate p-values and significance levels for logistic regression coefficients.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : fitted sklearn.linear_model.LogisticRegression\n",
    "        The fitted logistic regression model\n",
    "    X : array-like\n",
    "        The input features used to train the model\n",
    "    feature_names : list, optional\n",
    "        Names of the features (columns)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with coefficients, standard errors, z-values, p-values, and significance indicators\n",
    "    \"\"\"\n",
    "    # Get coefficients and intercept\n",
    "    coef = model.coef_[0]\n",
    "    intercept = model.intercept_[0]\n",
    "    \n",
    "    # Combine coefficients with intercept\n",
    "    params = np.append(intercept, coef)\n",
    "    \n",
    "    # Calculate predictions and probabilities\n",
    "    y_pred = model.predict(X)\n",
    "    probs = model.predict_proba(X)\n",
    "    \n",
    "    # Design matrix with intercept\n",
    "    X_design = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "    \n",
    "    # Calculate variance-covariance matrix\n",
    "    # For logistic regression, V is a diagonal matrix of p_i * (1 - p_i)\n",
    "    p = probs[:, 1]\n",
    "    V = np.diagflat(p * (1 - p))\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    covb = np.linalg.inv(X_design.T @ V @ X_design)\n",
    "    se = np.sqrt(np.diag(covb))\n",
    "    \n",
    "    # Calculate z-scores (for logistic regression, we use z instead of t)\n",
    "    z_scores = params / se\n",
    "    \n",
    "    # Calculate p-values (two-tailed test)\n",
    "    p_values = 2 * (1 - stats.norm.cdf(abs(z_scores)))\n",
    "\n",
    "    degrees_of_freedom = X.shape[0] - X.shape[1]\n",
    "    t_scores = params / se\n",
    "    p_values_t = 2 * (1 - stats.t.cdf(abs(t_scores), df=degrees_of_freedom))\n",
    "    \n",
    "    # Create significance indicators\n",
    "    significance = [''] * len(p_values)\n",
    "    for i, p in enumerate(p_values):\n",
    "        if p < 0.001:\n",
    "            significance[i] = '***'\n",
    "        elif p < 0.01:\n",
    "            significance[i] = '**'\n",
    "        elif p < 0.05:\n",
    "            significance[i] = '*'\n",
    "        elif p < 0.1:\n",
    "            significance[i] = '.'\n",
    "\n",
    "    significance_t = [''] * len(p_values_t)\n",
    "    for i, p in enumerate(p_values_t):\n",
    "        if p < 0.001:\n",
    "            significance_t[i] = '***'\n",
    "        elif p < 0.01:\n",
    "            significance_t[i] = '**'\n",
    "        elif p < 0.05:\n",
    "            significance_t[i] = '*'\n",
    "        elif p < 0.1:\n",
    "            significance_t[i] = '.'\n",
    "    \n",
    "    # Create feature names if not provided\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'X{i}' for i in range(X.shape[1])]\n",
    "    \n",
    "    # Combine results into a DataFrame\n",
    "    result = pd.DataFrame({\n",
    "        'Variable': ['Intercept'] + list(feature_names),\n",
    "        'Coefficient': params,\n",
    "        'Std. Error': se,\n",
    "        'z-value': z_scores,\n",
    "        'p-value': p_values,\n",
    "        'Significance': significance,\n",
    "        't-value':t_scores,\n",
    "        'p_values_t':p_values_t,\n",
    "        \"Significance_t\":significance_t\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def calculate_pseudo_r_squared(model, X, y):\n",
    "    # Make predictions (probabilities)\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Calculate log-likelihood of the model\n",
    "    ll_model = -log_loss(y, y_pred_proba, normalize=False)\n",
    "    \n",
    "    # Calculate log-likelihood of null model (intercept only)\n",
    "    null_proba = np.ones(len(y)) * y.mean()\n",
    "    ll_null = -log_loss(y, null_proba, normalize=False)\n",
    "    \n",
    "    # McFadden's R²\n",
    "    r_squared_mcfadden = 1 - (ll_model / ll_null)\n",
    "    \n",
    "    # Cox & Snell R²\n",
    "    r_squared_cox_snell = 1 - np.exp(2 * (ll_null - ll_model) / len(y))\n",
    "    \n",
    "    # Nagelkerke R² (adjusted Cox & Snell)\n",
    "    r_squared_nagelkerke = r_squared_cox_snell / (1 - np.exp(2 * ll_null / len(y)))\n",
    "    \n",
    "    return {\n",
    "        'McFadden': r_squared_mcfadden,\n",
    "        'Cox & Snell': r_squared_cox_snell,\n",
    "        'Nagelkerke': r_squared_nagelkerke\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logi_mod(df, y, e, C=1):\n",
    "    \n",
    "    # Original logistic regression code\n",
    "    cat_var = df[['E']]\n",
    "    cat_var_2=df[['pij_t']]\n",
    "    # Create and apply encoder\n",
    "    encoder = OneHotEncoder(drop='first', sparse_output=False)  # Drop first category to avoid multicollinearity\n",
    "    encoded = encoder.fit_transform(cat_var)\n",
    "    \n",
    "    # Create DataFrame with encoded variables\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded,\n",
    "        columns=encoder.get_feature_names_out(['E'])\n",
    "    )\n",
    "    encoder_2 = OneHotEncoder(drop='first', sparse_output=False)  # Drop first category to avoid multicollinearity\n",
    "\n",
    "    encoded_2 = encoder_2.fit_transform(cat_var_2)\n",
    "    \n",
    "    # Create DataFrame with encoded variables\n",
    "    encoded_df_2 = pd.DataFrame(\n",
    "        encoded_2,\n",
    "        columns=encoder_2.get_feature_names_out(['pij_t'])\n",
    "    )\n",
    "    X=df\n",
    "    if e:\n",
    "        # X = pd.concat([df.drop(['E'], axis=1), encoded_df, encoded_df_2], axis=1)\n",
    "        con=pd.concat([encoded_df, encoded_df_2],axis=1)\n",
    "    else:\n",
    "        X=df.drop('E', axis=1)\n",
    "        \n",
    "    # Combine with other features\n",
    "\n",
    "    # std_scaler=StandardScaler().fit(X)\n",
    "    # X_std=std_scaler.transform(X)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    if e:\n",
    "        X_scaled=X_scaled.drop(\"pij_t\", axis=1)\n",
    "        X_scaled=pd.concat([X_scaled, con], axis=1)\n",
    "\n",
    "    model = LogisticRegression(fit_intercept=True, max_iter=100000, solver=\"newton-cg\", C=C)\n",
    "    model.fit(X_scaled, y)\n",
    "    print(X.shape)\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    stats_df = get_logistic_regression_stats(model, X_scaled, feature_names=X_scaled.columns)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"\\nLogistic Regression Results:\")\n",
    "    print(stats_df)\n",
    "    \n",
    "    y_pred = model.predict(X_scaled)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, y_pred, zero_division=1))\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    conf=confusion_matrix(y, y_pred)\n",
    "    print(conf)\n",
    "\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # newX = pd.DataFrame({\"Constant\":np.ones(len(X))}).join(pd.DataFrame(X))\n",
    "    newX = pd.DataFrame({\"Constant\":np.ones(len(X_scaled))}).join(pd.DataFrame(X_scaled.reset_index(drop=True)))\n",
    "    MSE = (sum((y-predictions)**2))/(len(newX)-len(newX.columns))\n",
    "    print(MSE)\n",
    "    # Note if you don't want to use a DataFrame replace the two lines above with\n",
    "    # newX = np.append(np.ones((len(X),1)), X, axis=1)\n",
    "    # MSE = (sum((y-predictions)**2))/(len(newX)-len(newX[0]))\n",
    "    print(calculate_pseudo_r_squared(model, X_scaled, y))\n",
    "    \n",
    "    return (classification_report(y, y_pred, zero_division=1),conf, stats_df)\n",
    "\n",
    "def print_latex_format(mod):\n",
    "    reshaped={}\n",
    "    for i in range(len(mod)):\n",
    "        res=mod[i][2]\n",
    "        # print(res)\n",
    "        # print(type(res))\n",
    "        # print(res.index)\n",
    "        dec=6\n",
    "        just=\"c\"\n",
    "        for j in res.index:\n",
    "            if res.loc[j,\"Variable\"] not in reshaped.keys():\n",
    "                reshaped[res.loc[j,\"Variable\"]]=\"&\\\\makecell[\"+just+\"]{\"+str(round(res.loc[j, \"Coefficient\"],dec)) + str(res.loc[j, \"Significance\"]) +'\\\\\\\\(' +str(round(res.loc[j,'Std. Error'],dec)) +')\\\\\\\\' + str(round(res.loc[j, \"p-value\"],dec))+\"} \"\n",
    "            else:\n",
    "                reshaped[res.loc[j,\"Variable\"]]+=\"& \\\\makecell[\"+just+\"]{\"+str(round(res.loc[j, \"Coefficient\"],dec)) + str(res.loc[j, \"Significance\"]) +'\\\\\\\\(' +str(round(res.loc[j,'Std. Error'],dec)) +')\\\\\\\\' + str(round(res.loc[j, \"p-value\"],dec))+\"}\"\n",
    "\n",
    "    for i in reshaped.keys():\n",
    "        print(\"\\makecell[l]{\"+i.replace(\"_\",\" \")+\"}\"+reshaped[i]+\"\\\\\\\\\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Author', 'Coauthor', 'tij', 'ytij', 'tij_1', 'tij_2', 'tij_0', 'tij-1',\n",
       "       'distance', 'pij_t', 'cij_t', 'A', 'C', 'E', 'avg_p', 'abs_p', 'avg_c',\n",
       "       'abs_c', 'aff_js'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "1950 to 1959 inclusive\n",
      "#########################################\n",
      "\n",
      "(767, 2)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error   z-value       p-value Significance  \\\n",
      "0  Intercept    -0.474871    0.074795 -6.348948  2.167926e-10          ***   \n",
      "1      pij_t     0.505930    0.479045  1.056122  2.909123e-01                \n",
      "2   log(cij)    -0.590342    0.546589 -1.080047  2.801214e-01                \n",
      "\n",
      "    t-value    p_values_t Significance_t  \n",
      "0 -6.348948  3.714400e-10            ***  \n",
      "1  1.056122  2.912457e-01                 \n",
      "2 -1.080047  2.804618e-01                 \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       472\n",
      "           1       1.00      0.00      0.00       295\n",
      "\n",
      "    accuracy                           0.62       767\n",
      "   macro avg       0.81      0.50      0.38       767\n",
      "weighted avg       0.76      0.62      0.47       767\n",
      "\n",
      "Confusion Matrix:\n",
      "[[472   0]\n",
      " [295   0]]\n",
      "0.612565445026178\n",
      "{'McFadden': 0.0034285803140136073, 'Cox & Snell': np.float64(0.004558357311479799), 'Nagelkerke': np.float64(0.006191753594868204)}\n",
      "#########################################\n",
      "1960 to 1969 inclusive\n",
      "#########################################\n",
      "\n",
      "(1439, 2)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error   z-value       p-value Significance  \\\n",
      "0  Intercept    -0.431000    0.053995 -7.982218  1.332268e-15          ***   \n",
      "1      pij_t     0.261651    0.491382  0.532479  5.943945e-01                \n",
      "2   log(cij)    -0.280827    0.515214 -0.545068  5.857068e-01                \n",
      "\n",
      "    t-value    p_values_t Significance_t  \n",
      "0 -7.982218  2.886580e-15            ***  \n",
      "1  0.532479  5.944768e-01                 \n",
      "2 -0.545068  5.857914e-01                 \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.75       872\n",
      "           1       1.00      0.00      0.00       567\n",
      "\n",
      "    accuracy                           0.61      1439\n",
      "   macro avg       0.80      0.50      0.38      1439\n",
      "weighted avg       0.76      0.61      0.46      1439\n",
      "\n",
      "Confusion Matrix:\n",
      "[[872   0]\n",
      " [567   0]]\n",
      "0.6058495821727019\n",
      "{'McFadden': 0.00044564442323380415, 'Cox & Snell': np.float64(0.0005974430383801632), 'Nagelkerke': np.float64(0.0008090793114174971)}\n",
      "#########################################\n",
      "1970 to 1979 inclusive\n",
      "#########################################\n",
      "\n",
      "(4019, 2)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -0.655192    0.033331 -19.657023  0.000000          ***   \n",
      "1      pij_t    -0.070816    0.100209  -0.706685  0.479762                \n",
      "2   log(cij)    -0.045212    0.094097  -0.480482  0.630885                \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -19.657023    0.000000            ***  \n",
      "1  -0.706685    0.479803                 \n",
      "2  -0.480482    0.630911                 \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79      2643\n",
      "           1       1.00      0.00      0.00      1376\n",
      "\n",
      "    accuracy                           0.66      4019\n",
      "   macro avg       0.83      0.50      0.40      4019\n",
      "weighted avg       0.77      0.66      0.52      4019\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2643    0]\n",
      " [1376    0]]\n",
      "0.3426294820717131\n",
      "{'McFadden': 0.00169147323596619, 'Cox & Snell': np.float64(0.002171511508591628), 'Nagelkerke': np.float64(0.0030017992390223703)}\n",
      "#########################################\n",
      "1980 to 1989 inclusive\n",
      "#########################################\n",
      "\n",
      "(7307, 2)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -0.956667    0.026402 -36.235182  0.000000          ***   \n",
      "1      pij_t     0.138403    0.062866   2.201551  0.027697            *   \n",
      "2   log(cij)    -0.336378    0.068971  -4.877127  0.000001          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -36.235182    0.000000            ***  \n",
      "1   2.201551    0.027728              *  \n",
      "2  -4.877127    0.000001            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      5261\n",
      "           1       1.00      0.00      0.00      2046\n",
      "\n",
      "    accuracy                           0.72      7307\n",
      "   macro avg       0.86      0.50      0.42      7307\n",
      "weighted avg       0.80      0.72      0.60      7307\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5261    0]\n",
      " [2046    0]]\n",
      "0.6762048192771084\n",
      "{'McFadden': 0.006273961563385, 'Cox & Snell': np.float64(0.007412786283452877), 'Nagelkerke': np.float64(0.010673035029321896)}\n",
      "#########################################\n",
      "1990 to 1999 inclusive\n",
      "#########################################\n",
      "\n",
      "(9314, 2)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -1.038116    0.024480 -42.406902  0.000000          ***   \n",
      "1      pij_t     0.030915    0.050278   0.614878  0.538635                \n",
      "2   log(cij)    -0.470314    0.051048  -9.213238  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -42.406902     0.00000            ***  \n",
      "1   0.614878     0.53865                 \n",
      "2  -9.213238     0.00000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84      6792\n",
      "           1       1.00      0.00      0.00      2522\n",
      "\n",
      "    accuracy                           0.73      9314\n",
      "   macro avg       0.86      0.50      0.42      9314\n",
      "weighted avg       0.80      0.73      0.62      9314\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6792    0]\n",
      " [2522    0]]\n",
      "0.5943507679089249\n",
      "{'McFadden': 0.024501398337607005, 'Cox & Snell': np.float64(0.02821337602680485), 'Nagelkerke': np.float64(0.04094655360752841)}\n",
      "#########################################\n",
      "2000 to 2009 inclusive\n",
      "#########################################\n",
      "\n",
      "(13594, 2)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value  p-value Significance  \\\n",
      "0  Intercept    -1.034904    0.020654 -50.107733  0.00000          ***   \n",
      "1      pij_t     0.068399    0.039434   1.734497  0.08283            .   \n",
      "2   log(cij)    -0.607629    0.040981 -14.827207  0.00000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -50.107733    0.000000            ***  \n",
      "1   1.734497    0.082853              .  \n",
      "2 -14.827207    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      9836\n",
      "           1       1.00      0.00      0.00      3758\n",
      "\n",
      "    accuracy                           0.72     13594\n",
      "   macro avg       0.86      0.50      0.42     13594\n",
      "weighted avg       0.80      0.72      0.61     13594\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9836    0]\n",
      " [3758    0]]\n",
      "0.5468324626591127\n",
      "{'McFadden': 0.037916946329403234, 'Cox & Snell': np.float64(0.04372427663117251), 'Nagelkerke': np.float64(0.06314397221596223)}\n",
      "#########################################\n",
      "2010 to 2019 inclusive\n",
      "#########################################\n",
      "\n",
      "(15021, 2)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -0.231298    0.017458 -13.248971  0.000000          ***   \n",
      "1      pij_t     0.032197    0.033896   0.949871  0.342178                \n",
      "2   log(cij)    -0.696472    0.034250 -20.334873  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -13.248971    0.000000            ***  \n",
      "1   0.949871    0.342193                 \n",
      "2 -20.334873    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.40      0.53      8211\n",
      "           1       0.55      0.87      0.67      6810\n",
      "\n",
      "    accuracy                           0.61     15021\n",
      "   macro avg       0.67      0.63      0.60     15021\n",
      "weighted avg       0.68      0.61      0.59     15021\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3255 4956]\n",
      " [ 868 5942]]\n",
      "0.387801305100546\n",
      "{'McFadden': 0.06882746327606348, 'Cox & Snell': np.float64(0.09045928006692516), 'Nagelkerke': np.float64(0.1209651845319703)}\n"
     ]
    }
   ],
   "source": [
    "mods_d=[]\n",
    "E_sum=[]\n",
    "for i in range(1960,2021,10):\n",
    "    print(\"#########################################\")\n",
    "    print(str(i-10)+' to '+str(i-1) + \" inclusive\")\n",
    "    print(\"#########################################\")\n",
    "    # test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)].reset_index(drop=True)\n",
    "    test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)][[\"pij_t\",'cij_t',\"ytij\",\"tij\",\"tij_0\",\"tij_1\",\"Author\", \"Coauthor\",\"E\",\"avg_p\",\"abs_p\",'avg_c',\"abs_c\"]].drop_duplicates().reset_index(drop=True)\n",
    "    # plothist(test_df, \"pij_t\")\n",
    "    test_df[\"log(cij)\"]=np.log(test_df['cij_t'].clip(lower=0.0001))\n",
    "    # plothist(test_df, \"E\")\n",
    "    X=test_df[[\"pij_t\",'log(cij)','E']].fillna(0)\n",
    "    y=test_df[\"ytij\"]\n",
    "    print()\n",
    "    temp_e=test_df[[\"Author\",\"Coauthor\",\"E\"]].drop_duplicates()['E'].value_counts().reset_index()\n",
    "    temp_e[\"start\"]=i-10\n",
    "    temp_e[\"end\"]=i\n",
    "    E_sum.append(temp_e)\n",
    "    mods_d.append(logi_mod(X,y, False,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Pivoting data for better visualization\n",
    "df_pivot = pd.concat(E_sum).pivot(index=\"start\", columns=\"E\", values=\"count\")\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "df_pivot.plot(kind=\"bar\", stacked=False, figsize=(12, 6), ax=ax)\n",
    "\n",
    "for i, bar_group in enumerate(ax.containers):\n",
    "    for bar in bar_group:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,  # X-coordinate\n",
    "                bar.get_height() + 1,  # Y-coordinate (a little above the bar)\n",
    "                f\" {height}\",  # Formatting percentage\n",
    "                ha='center', va='bottom', fontsize=10, rotation=90\n",
    "            )\n",
    "\n",
    "ax.set_xlabel(\"Start Year\")\n",
    "ax.set_ylabel(\"Count of type\")\n",
    "ax.set_title(\"Count of types of collaboration between two coauthors at their filst collaboration starting from 1950 to 2019. \\n0: both authors have published in the top 5 before their collaboration. \\n1: one of the authors have published in the top 5. \\n2: neither authors have published in the top 5.\")\n",
    "ax.set_xticklabels(df_pivot.index,rotation=45)\n",
    "ax.legend(title=\"Type\")\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "ax.set_ylim(0,5000)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pivot_percentage = df_pivot.div(df_pivot.sum(axis=1), axis=0) * 100\n",
    "# Plotting the bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "df_pivot_percentage.plot(kind=\"bar\", stacked=False, ax=ax)\n",
    "\n",
    "# Adding percentage labels above the bars\n",
    "for i, bar_group in enumerate(ax.containers):\n",
    "    for bar in bar_group:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,  # X-coordinate\n",
    "                bar.get_height() + 1,  # Y-coordinate (a little above the bar)\n",
    "                f\"{height:.1f}%\",  # Formatting percentage\n",
    "                ha='center', va='bottom', fontsize=10, rotation=90\n",
    "            )\n",
    "\n",
    "# Formatting the plot\n",
    "ax.set_xlabel(\"Start Year\")\n",
    "ax.set_ylabel(\"Percentage Share (%)\")\n",
    "ax.set_title(\"Percentage Share of Coauthor Pair Types Every 10 Year Decade Since 1950 to 2020 at their first collaboration. \\n0: both authors have published in the top 5 before their collaboration. \\n1: one of the authors have published in the top 5. \\n2: neither authors have published in the top 5.\")\n",
    "ax.set_xticklabels(df_pivot.index, rotation=45)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.legend(title=\"Type\")\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\makecell[l]{Intercept}&\\makecell[c]{-0.474871***\\\\(0.074795)\\\\0.0} & \\makecell[c]{-0.431***\\\\(0.053995)\\\\0.0}& \\makecell[c]{-0.655192***\\\\(0.033331)\\\\0.0}& \\makecell[c]{-0.956667***\\\\(0.026402)\\\\0.0}& \\makecell[c]{-1.038116***\\\\(0.02448)\\\\0.0}& \\makecell[c]{-1.034904***\\\\(0.020654)\\\\0.0}& \\makecell[c]{-0.231298***\\\\(0.017458)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{pij t}&\\makecell[c]{0.50593\\\\(0.479045)\\\\0.290912} & \\makecell[c]{0.261651\\\\(0.491382)\\\\0.594394}& \\makecell[c]{-0.070816\\\\(0.100209)\\\\0.479762}& \\makecell[c]{0.138403*\\\\(0.062866)\\\\0.027697}& \\makecell[c]{0.030915\\\\(0.050278)\\\\0.538635}& \\makecell[c]{0.068399.\\\\(0.039434)\\\\0.08283}& \\makecell[c]{0.032197\\\\(0.033896)\\\\0.342178}\\\\\\\\\n",
      "\\makecell[l]{log(cij)}&\\makecell[c]{-0.590342\\\\(0.546589)\\\\0.280121} & \\makecell[c]{-0.280827\\\\(0.515214)\\\\0.585707}& \\makecell[c]{-0.045212\\\\(0.094097)\\\\0.630885}& \\makecell[c]{-0.336378***\\\\(0.068971)\\\\1e-06}& \\makecell[c]{-0.470314***\\\\(0.051048)\\\\0.0}& \\makecell[c]{-0.607629***\\\\(0.040981)\\\\0.0}& \\makecell[c]{-0.696472***\\\\(0.03425)\\\\0.0}\\\\\\\\\n"
     ]
    }
   ],
   "source": [
    "print_latex_format(mods_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Author', 'Coauthor', 'tij', 'ytij', 'tij_1', 'tij_2', 'tij_0', 'tij-1',\n",
       "       'distance', 'pij_t', 'cij_t', 'A', 'C', 'E', 'avg_p', 'abs_p', 'avg_c',\n",
       "       'abs_c', 'aff_js'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "1950 to 1959 inclusive\n",
      "#########################################\n",
      "\n",
      "(767, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error   z-value       p-value Significance  \\\n",
      "0  Intercept    -0.563484    0.083945 -6.712549  1.912537e-11          ***   \n",
      "1      pij_t     0.618366    0.487783  1.267708  2.049024e-01                \n",
      "2   log(cij)    -0.534014    0.554187 -0.963598  3.352473e-01                \n",
      "3      abs_p     0.775736    0.184249  4.210258  2.550795e-05          ***   \n",
      "4      avg_p    -1.083874    0.204184 -5.308321  1.106399e-07          ***   \n",
      "5      abs_c     1.422351    0.623463  2.281373  2.252636e-02            *   \n",
      "6      avg_c    -1.428085    0.627815 -2.274693  2.292437e-02            *   \n",
      "7     aff_js     0.546486    0.083984  6.507037  7.664780e-11          ***   \n",
      "\n",
      "    t-value    p_values_t Significance_t  \n",
      "0 -6.712549  3.741629e-11            ***  \n",
      "1  1.267708  2.052907e-01                 \n",
      "2 -0.963598  3.355538e-01                 \n",
      "3  4.210258  2.856196e-05            ***  \n",
      "4 -5.308321  1.453486e-07            ***  \n",
      "5  2.281373  2.280215e-02              *  \n",
      "6 -2.274693  2.320220e-02              *  \n",
      "7  6.507037  1.390401e-10            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80       472\n",
      "           1       0.74      0.39      0.51       295\n",
      "\n",
      "    accuracy                           0.71       767\n",
      "   macro avg       0.72      0.65      0.65       767\n",
      "weighted avg       0.72      0.71      0.69       767\n",
      "\n",
      "Confusion Matrix:\n",
      "[[432  40]\n",
      " [180 115]]\n",
      "0.42160737812911725\n",
      "{'McFadden': 0.13122922573509765, 'Cox & Snell': np.float64(0.16043418547225863), 'Nagelkerke': np.float64(0.2179225709524574)}\n",
      "#########################################\n",
      "1960 to 1969 inclusive\n",
      "#########################################\n",
      "\n",
      "(1439, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -0.755430    0.078794  -9.587422  0.000000e+00          ***   \n",
      "1      pij_t     0.231614    0.552249   0.419400  6.749236e-01                \n",
      "2   log(cij)    -0.186552    0.581718  -0.320691  7.484445e-01                \n",
      "3      abs_p     1.143605    0.170943   6.689976  2.232081e-11          ***   \n",
      "4      avg_p    -2.227038    0.232998  -9.558164  0.000000e+00          ***   \n",
      "5      abs_c     0.136128    0.177712   0.766004  4.436738e-01                \n",
      "6      avg_c    -0.352335    0.178834  -1.970180  4.881773e-02            *   \n",
      "7     aff_js     0.665742    0.066137  10.066080  0.000000e+00          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0  -9.587422  0.000000e+00            ***  \n",
      "1   0.419400  6.749865e-01                 \n",
      "2  -0.320691  7.484913e-01                 \n",
      "3   6.689976  3.192335e-11            ***  \n",
      "4  -9.558164  0.000000e+00            ***  \n",
      "5   0.766004  4.438001e-01                 \n",
      "6  -1.970180  4.901015e-02              *  \n",
      "7  10.066080  0.000000e+00            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81       872\n",
      "           1       0.77      0.50      0.60       567\n",
      "\n",
      "    accuracy                           0.74      1439\n",
      "   macro avg       0.75      0.70      0.71      1439\n",
      "weighted avg       0.75      0.74      0.73      1439\n",
      "\n",
      "Confusion Matrix:\n",
      "[[787  85]\n",
      " [286 281]]\n",
      "0.22571628232005592\n",
      "{'McFadden': 0.22767580385009467, 'Cox & Snell': np.float64(0.2631121664107242), 'Nagelkerke': np.float64(0.3563161619596885)}\n",
      "#########################################\n",
      "1970 to 1979 inclusive\n",
      "#########################################\n",
      "\n",
      "(4019, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -0.929056    0.044586 -20.837424  0.000000          ***   \n",
      "1      pij_t    -0.261464    0.112043  -2.333609  0.019616            *   \n",
      "2   log(cij)     0.424183    0.108242   3.918829  0.000089          ***   \n",
      "3      abs_p     1.034570    0.116782   8.858969  0.000000          ***   \n",
      "4      avg_p    -1.943753    0.139430 -13.940689  0.000000          ***   \n",
      "5      abs_c    -0.031177    0.064751  -0.481493  0.630166                \n",
      "6      avg_c    -0.237294    0.068255  -3.476561  0.000508          ***   \n",
      "7     aff_js     0.589211    0.037336  15.781151  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -20.837424    0.000000            ***  \n",
      "1  -2.333609    0.019665              *  \n",
      "2   3.918829    0.000090            ***  \n",
      "3   8.858969    0.000000            ***  \n",
      "4 -13.940689    0.000000            ***  \n",
      "5  -0.481493    0.630192                 \n",
      "6  -3.476561    0.000513            ***  \n",
      "7  15.781151    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82      2643\n",
      "           1       0.72      0.39      0.50      1376\n",
      "\n",
      "    accuracy                           0.74      4019\n",
      "   macro avg       0.73      0.65      0.66      4019\n",
      "weighted avg       0.74      0.74      0.71      4019\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2439  204]\n",
      " [ 846  530]]\n",
      "0.34779356768885566\n",
      "{'McFadden': 0.18741724340529475, 'Cox & Snell': np.float64(0.21405437814667838), 'Nagelkerke': np.float64(0.2958990854470957)}\n",
      "#########################################\n",
      "1980 to 1989 inclusive\n",
      "#########################################\n",
      "\n",
      "(7307, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -1.193856    0.032718 -36.489115  0.000000          ***   \n",
      "1      pij_t     0.117137    0.064591   1.813534  0.069750            .   \n",
      "2   log(cij)     0.049611    0.072117   0.687926  0.491499                \n",
      "3      abs_p     0.756055    0.063501  11.906158  0.000000          ***   \n",
      "4      avg_p    -1.221451    0.077952 -15.669362  0.000000          ***   \n",
      "5      abs_c     0.073120    0.040564   1.802595  0.071452            .   \n",
      "6      avg_c    -0.633558    0.046818 -13.532368  0.000000          ***   \n",
      "7     aff_js     0.471428    0.027015  17.450532  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -36.489115    0.000000            ***  \n",
      "1   1.813534    0.069791              .  \n",
      "2   0.687926    0.491521                 \n",
      "3  11.906158    0.000000            ***  \n",
      "4 -15.669362    0.000000            ***  \n",
      "5   1.802595    0.071493              .  \n",
      "6 -13.532368    0.000000            ***  \n",
      "7  17.450532    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85      5261\n",
      "           1       0.67      0.27      0.38      2046\n",
      "\n",
      "    accuracy                           0.76      7307\n",
      "   macro avg       0.72      0.61      0.62      7307\n",
      "weighted avg       0.74      0.76      0.72      7307\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4986  275]\n",
      " [1495  551]]\n",
      "0.31387861350869983\n",
      "{'McFadden': 0.15353692869267488, 'Cox & Snell': np.float64(0.16646705380218596), 'Nagelkerke': np.float64(0.23968162962215503)}\n",
      "#########################################\n",
      "1990 to 1999 inclusive\n",
      "#########################################\n",
      "\n",
      "(9314, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -1.311699    0.030996 -42.318862  0.000000          ***   \n",
      "1      pij_t     0.176512    0.051177   3.449027  0.000563          ***   \n",
      "2   log(cij)     0.100406    0.055864   1.797308  0.072287            .   \n",
      "3      abs_p     0.709399    0.054657  12.979109  0.000000          ***   \n",
      "4      avg_p    -1.341546    0.072443 -18.518735  0.000000          ***   \n",
      "5      abs_c     0.135859    0.034823   3.901469  0.000096          ***   \n",
      "6      avg_c    -0.764050    0.042330 -18.049679  0.000000          ***   \n",
      "7     aff_js     0.366703    0.024271  15.108625  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -42.318862    0.000000            ***  \n",
      "1   3.449027    0.000565            ***  \n",
      "2   1.797308    0.072319              .  \n",
      "3  12.979109    0.000000            ***  \n",
      "4 -18.518735    0.000000            ***  \n",
      "5   3.901469    0.000096            ***  \n",
      "6 -18.049679    0.000000            ***  \n",
      "7  15.108625    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87      6792\n",
      "           1       0.68      0.43      0.52      2522\n",
      "\n",
      "    accuracy                           0.79      9314\n",
      "   macro avg       0.75      0.68      0.69      9314\n",
      "weighted avg       0.78      0.79      0.77      9314\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6289  503]\n",
      " [1448 1074]]\n",
      "0.26918117343649256\n",
      "{'McFadden': 0.17462611368886372, 'Cox & Snell': np.float64(0.1845157688228497), 'Nagelkerke': np.float64(0.26779088090560454)}\n",
      "#########################################\n",
      "2000 to 2009 inclusive\n",
      "#########################################\n",
      "\n",
      "(13594, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -1.238224    0.024602 -50.330869  0.000000e+00          ***   \n",
      "1      pij_t     0.198137    0.039453   5.022125  5.110298e-07          ***   \n",
      "2   log(cij)    -0.034549    0.045226  -0.763928  4.449103e-01                \n",
      "3      abs_p     0.765430    0.052329  14.627369  0.000000e+00          ***   \n",
      "4      avg_p    -1.170897    0.066844 -17.516766  0.000000e+00          ***   \n",
      "5      abs_c     0.134178    0.026086   5.143694  2.693886e-07          ***   \n",
      "6      avg_c    -0.780739    0.033696 -23.170313  0.000000e+00          ***   \n",
      "7     aff_js     0.243720    0.019889  12.253696  0.000000e+00          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -50.330869  0.000000e+00            ***  \n",
      "1   5.022125  5.175114e-07            ***  \n",
      "2  -0.763928  4.449235e-01                 \n",
      "3  14.627369  0.000000e+00            ***  \n",
      "4 -17.516766  0.000000e+00            ***  \n",
      "5   5.143694  2.731379e-07            ***  \n",
      "6 -23.170313  0.000000e+00            ***  \n",
      "7  12.253696  0.000000e+00            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86      9836\n",
      "           1       0.67      0.37      0.48      3758\n",
      "\n",
      "    accuracy                           0.77     13594\n",
      "   macro avg       0.73      0.65      0.67     13594\n",
      "weighted avg       0.76      0.77      0.75     13594\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9131  705]\n",
      " [2356 1402]]\n",
      "0.3452819078463124\n",
      "{'McFadden': 0.14800347345460685, 'Cox & Snell': np.float64(0.16013597663377144), 'Nagelkerke': np.float64(0.2312587523090073)}\n",
      "#########################################\n",
      "2010 to 2019 inclusive\n",
      "#########################################\n",
      "\n",
      "(15021, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -0.289095    0.018980 -15.231353  0.000000e+00          ***   \n",
      "1      pij_t     0.261111    0.034389   7.592922  3.130829e-14          ***   \n",
      "2   log(cij)    -0.161734    0.037286  -4.337636  1.440234e-05          ***   \n",
      "3      abs_p     0.635292    0.039622  16.033876  0.000000e+00          ***   \n",
      "4      avg_p    -1.007087    0.049601 -20.303863  0.000000e+00          ***   \n",
      "5      abs_c     0.267634    0.022034  12.146665  0.000000e+00          ***   \n",
      "6      avg_c    -0.794732    0.028013 -28.369959  0.000000e+00          ***   \n",
      "7     aff_js     0.208703    0.019244  10.845338  0.000000e+00          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -15.231353  0.000000e+00            ***  \n",
      "1   7.592922  3.308465e-14            ***  \n",
      "2  -4.337636  1.449632e-05            ***  \n",
      "3  16.033876  0.000000e+00            ***  \n",
      "4 -20.303863  0.000000e+00            ***  \n",
      "5  12.146665  0.000000e+00            ***  \n",
      "6 -28.369959  0.000000e+00            ***  \n",
      "7  10.845338  0.000000e+00            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75      8211\n",
      "           1       0.69      0.77      0.73      6810\n",
      "\n",
      "    accuracy                           0.74     15021\n",
      "   macro avg       0.74      0.74      0.74     15021\n",
      "weighted avg       0.74      0.74      0.74     15021\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5826 2385]\n",
      " [1572 5238]]\n",
      "0.2756943981882369\n",
      "{'McFadden': 0.15903896022268083, 'Cox & Snell': np.float64(0.1967500084194127), 'Nagelkerke': np.float64(0.26310071291207393)}\n"
     ]
    }
   ],
   "source": [
    "mods_e=[]\n",
    "\n",
    "for i in range(1960,2021,10):\n",
    "    print(\"#########################################\")\n",
    "    print(str(i-10)+' to '+str(i-1) + \" inclusive\")\n",
    "    print(\"#########################################\")\n",
    "    # test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)].reset_index(drop=True)\n",
    "    test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)][[\"pij_t\",'cij_t',\"ytij\",\"tij\",\"tij_0\",\"tij_1\",\"Author\", \"Coauthor\",\"E\",\"avg_p\",\"abs_p\",'avg_c',\"abs_c\",\"aff_js\"]].drop_duplicates().reset_index(drop=True)\n",
    "    # plothist(test_df, \"pij_t\")\n",
    "    # plothist(test_df, \"E\")\n",
    "    test_df[\"log(cij)\"]=np.log(test_df['cij_t'].clip(lower=0.0001))\n",
    "\n",
    "    X=test_df[[\"pij_t\",'log(cij)',\"E\",\"abs_p\", \"avg_p\",'abs_c',\"avg_c\",\"aff_js\"]].fillna(0)\n",
    "    y=test_df[\"ytij\"]\n",
    "    print()\n",
    "    mods_e.append(logi_mod(X,y, False, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "1950 to 1959 inclusive\n",
      "#########################################\n",
      "\n",
      "(1203, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -4.019966    0.275522 -14.590388  0.000000          ***   \n",
      "1      pij_t     0.082977    0.279139   0.297260  0.766268                \n",
      "2   log(cij)     0.527573    0.316367   1.667597  0.095396            .   \n",
      "3      abs_p     0.098462    0.301202   0.326897  0.743746                \n",
      "4      avg_p    -0.189516    0.292341  -0.648270  0.516810                \n",
      "5      abs_c    -0.406894    0.689330  -0.590274  0.555007                \n",
      "6      avg_c    -0.579904    0.664740  -0.872378  0.383002                \n",
      "7     aff_js     0.493902    0.150716   3.277042  0.001049           **   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -14.590388    0.000000            ***  \n",
      "1   0.297260    0.766320                 \n",
      "2   1.667597    0.095658              .  \n",
      "3   0.326897    0.743803                 \n",
      "4  -0.648270    0.516934                 \n",
      "5  -0.590274    0.555118                 \n",
      "6  -0.872378    0.383177                 \n",
      "7   3.277042    0.001079             **  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1165\n",
      "           1       1.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.97      1203\n",
      "   macro avg       0.98      0.50      0.49      1203\n",
      "weighted avg       0.97      0.97      0.95      1203\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1165    0]\n",
      " [  38    0]]\n",
      "0.031799163179916316\n",
      "{'McFadden': 0.20095809368160467, 'Cox & Snell': np.float64(0.054797523035917894), 'Nagelkerke': np.float64(0.2240780685379122)}\n",
      "#########################################\n",
      "1960 to 1969 inclusive\n",
      "#########################################\n",
      "\n",
      "(1218, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -3.029233    0.169752 -17.845044  0.000000          ***   \n",
      "1      pij_t    -0.221306    0.151700  -1.458842  0.144608                \n",
      "2   log(cij)     0.895796    0.246584   3.632817  0.000280          ***   \n",
      "3      abs_p     0.160749    0.188439   0.853056  0.393628                \n",
      "4      avg_p    -0.006821    0.185467  -0.036776  0.970664                \n",
      "5      abs_c    -0.432123    0.238623  -1.810902  0.070156            .   \n",
      "6      avg_c     0.373108    0.227241   1.641902  0.100610                \n",
      "7     aff_js    -0.097338    0.126019  -0.772409  0.439872                \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -17.845044    0.000000            ***  \n",
      "1  -1.458842    0.144868                 \n",
      "2   3.632817    0.000292            ***  \n",
      "3   0.853056    0.393797                 \n",
      "4  -0.036776    0.970670                 \n",
      "5  -1.810902    0.070404              .  \n",
      "6   1.641902    0.100870                 \n",
      "7  -0.772409    0.440023                 \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1143\n",
      "           1       1.00      0.00      0.00        75\n",
      "\n",
      "    accuracy                           0.94      1218\n",
      "   macro avg       0.97      0.50      0.48      1218\n",
      "weighted avg       0.94      0.94      0.91      1218\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1143    0]\n",
      " [  75    0]]\n",
      "0.3305785123966942\n",
      "{'McFadden': 0.10235127339715211, 'Cox & Snell': np.float64(0.04624097413244077), 'Nagelkerke': np.float64(0.12486281200844311)}\n",
      "#########################################\n",
      "1970 to 1979 inclusive\n",
      "#########################################\n",
      "\n",
      "(2957, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -2.573016    0.088274 -29.148049  0.000000          ***   \n",
      "1      pij_t    -0.242298    0.097542  -2.484048  0.012990            *   \n",
      "2   log(cij)     0.643794    0.168544   3.819742  0.000134          ***   \n",
      "3      abs_p    -0.072683    0.130234  -0.558098  0.576777                \n",
      "4      avg_p    -0.082939    0.129761  -0.639169  0.522713                \n",
      "5      abs_c    -0.015499    0.068971  -0.224721  0.822197                \n",
      "6      avg_c     0.336856    0.100960   3.336532  0.000848          ***   \n",
      "7     aff_js     0.132239    0.062850   2.104024  0.035376            *   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -29.148049    0.000000            ***  \n",
      "1  -2.484048    0.013045              *  \n",
      "2   3.819742    0.000136            ***  \n",
      "3  -0.558098    0.576820                 \n",
      "4  -0.639169    0.522763                 \n",
      "5  -0.224721    0.822212                 \n",
      "6   3.336532    0.000859            ***  \n",
      "7   2.104024    0.035461              *  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       1.00      0.00      0.00       255\n",
      "\n",
      "    accuracy                           0.91      2957\n",
      "   macro avg       0.96      0.50      0.48      2957\n",
      "weighted avg       0.92      0.91      0.87      2957\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2702    0]\n",
      " [ 255    0]]\n",
      "0.08646998982706001\n",
      "{'McFadden': 0.05188006932868083, 'Cox & Snell': np.float64(0.03001889930653434), 'Nagelkerke': np.float64(0.06756812162388035)}\n",
      "#########################################\n",
      "1980 to 1989 inclusive\n",
      "#########################################\n",
      "\n",
      "(5706, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -2.707737    0.062248 -43.499214  0.000000e+00          ***   \n",
      "1      pij_t    -0.083494    0.073646  -1.133722  2.569113e-01                \n",
      "2   log(cij)     0.532749    0.105903   5.030535  4.891126e-07          ***   \n",
      "3      abs_p     0.110443    0.087521   1.261906  2.069828e-01                \n",
      "4      avg_p    -0.115207    0.096047  -1.199484  2.303398e-01                \n",
      "5      abs_c    -0.240127    0.061204  -3.923409  8.730485e-05          ***   \n",
      "6      avg_c     0.192659    0.075064   2.566594  1.027029e-02            *   \n",
      "7     aff_js     0.091270    0.049500   1.843846  6.520560e-02            .   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -43.499214  0.000000e+00            ***  \n",
      "1  -1.133722  2.569590e-01                 \n",
      "2   5.030535  5.041052e-07            ***  \n",
      "3   1.261906  2.070344e-01                 \n",
      "4  -1.199484  2.303897e-01                 \n",
      "5  -3.923409  8.833194e-05            ***  \n",
      "6   2.566594  1.029560e-02              *  \n",
      "7   1.843846  6.525748e-02              .  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      5294\n",
      "           1       1.00      0.00      0.00       412\n",
      "\n",
      "    accuracy                           0.93      5706\n",
      "   macro avg       0.96      0.50      0.48      5706\n",
      "weighted avg       0.93      0.93      0.89      5706\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5294    0]\n",
      " [ 412    0]]\n",
      "0.10687960687960688\n",
      "{'McFadden': 0.03609454570403958, 'Cox & Snell': np.float64(0.01854486855583659), 'Nagelkerke': np.float64(0.04582914409755388)}\n",
      "#########################################\n",
      "1990 to 1999 inclusive\n",
      "#########################################\n",
      "\n",
      "(9435, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -2.890129    0.050362 -57.387540  0.000000e+00          ***   \n",
      "1      pij_t    -0.138771    0.062105  -2.234470  2.545220e-02            *   \n",
      "2   log(cij)     0.401720    0.079185   5.073184  3.912144e-07          ***   \n",
      "3      abs_p    -0.105262    0.060329  -1.744812  8.101761e-02            .   \n",
      "4      avg_p     0.127205    0.060536   2.101289  3.561563e-02            *   \n",
      "5      abs_c    -0.137482    0.050831  -2.704701  6.836593e-03           **   \n",
      "6      avg_c     0.213403    0.064369   3.315309  9.154184e-04          ***   \n",
      "7     aff_js     0.182417    0.039819   4.581185  4.623488e-06          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -57.387540  0.000000e+00            ***  \n",
      "1  -2.234470  2.547554e-02              *  \n",
      "2   5.073184  3.986690e-07            ***  \n",
      "3  -1.744812  8.105019e-02              .  \n",
      "4   2.101289  3.564210e-02              *  \n",
      "5  -2.704701  6.848871e-03             **  \n",
      "6   3.315309  9.188747e-04            ***  \n",
      "7   4.581185  4.682839e-06            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      8877\n",
      "           1       1.00      0.00      0.00       558\n",
      "\n",
      "    accuracy                           0.94      9435\n",
      "   macro avg       0.97      0.50      0.48      9435\n",
      "weighted avg       0.94      0.94      0.91      9435\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8877    0]\n",
      " [ 558    0]]\n",
      "0.22785615784448923\n",
      "{'McFadden': 0.028565895251103424, 'Cox & Snell': np.float64(0.012749753148526666), 'Nagelkerke': np.float64(0.03523394407246214)}\n",
      "#########################################\n",
      "2000 to 2009 inclusive\n",
      "#########################################\n",
      "\n",
      "(14584, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -2.865824    0.040236 -71.225597  0.000000e+00          ***   \n",
      "1      pij_t     0.019906    0.048731   0.408496  6.829094e-01                \n",
      "2   log(cij)     0.408420    0.063871   6.394492  1.610820e-10          ***   \n",
      "3      abs_p     0.053113    0.051939   1.022614  3.064905e-01                \n",
      "4      avg_p    -0.009276    0.053720  -0.172680  8.629027e-01                \n",
      "5      abs_c    -0.189010    0.044253  -4.271172  1.944482e-05          ***   \n",
      "6      avg_c     0.090488    0.050633   1.787119  7.391824e-02            .   \n",
      "7     aff_js     0.161085    0.031163   5.169068  2.352637e-07          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -71.225597  0.000000e+00            ***  \n",
      "1   0.408496  6.829154e-01                 \n",
      "2   6.394492  1.659890e-10            ***  \n",
      "3   1.022614  3.065075e-01                 \n",
      "4  -0.172680  8.629051e-01                 \n",
      "5  -4.271172  1.956803e-05            ***  \n",
      "6   1.787119  7.393901e-02              .  \n",
      "7   5.169068  2.383734e-07            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     13701\n",
      "           1       1.00      0.00      0.00       883\n",
      "\n",
      "    accuracy                           0.94     14584\n",
      "   macro avg       0.97      0.50      0.48     14584\n",
      "weighted avg       0.94      0.94      0.91     14584\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13701     0]\n",
      " [  883     0]]\n",
      "0.13796652030735457\n",
      "{'McFadden': 0.02705949732364965, 'Cox & Snell': np.float64(0.012288262438145847), 'Nagelkerke': np.float64(0.03350331841690589)}\n",
      "#########################################\n",
      "2010 to 2019 inclusive\n",
      "#########################################\n",
      "\n",
      "(17602, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -2.350871    0.028349 -82.926960  0.000000e+00          ***   \n",
      "1      pij_t    -0.008798    0.036695  -0.239749  8.105251e-01                \n",
      "2   log(cij)     0.310734    0.045902   6.769532  1.291989e-11          ***   \n",
      "3      abs_p     0.111191    0.042057   2.643822  8.197575e-03           **   \n",
      "4      avg_p    -0.170429    0.043909  -3.881418  1.038491e-04          ***   \n",
      "5      abs_c    -0.149504    0.030446  -4.910513  9.083866e-07          ***   \n",
      "6      avg_c     0.169735    0.034173   4.966943  6.801647e-07          ***   \n",
      "7     aff_js     0.186698    0.023170   8.057723  8.881784e-16          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -82.926960  0.000000e+00            ***  \n",
      "1  -0.239749  8.105279e-01                 \n",
      "2   6.769532  1.332778e-11            ***  \n",
      "3   2.643822  8.204844e-03             **  \n",
      "4  -3.881418  1.042280e-04            ***  \n",
      "5  -4.910513  9.165330e-07            ***  \n",
      "6   4.966943  6.865401e-07            ***  \n",
      "7   8.057723  8.881784e-16            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     15948\n",
      "           1       1.00      0.00      0.00      1654\n",
      "\n",
      "    accuracy                           0.91     17602\n",
      "   macro avg       0.95      0.50      0.48     17602\n",
      "weighted avg       0.91      0.91      0.86     17602\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15948     0]\n",
      " [ 1654     0]]\n",
      "0.10475161987041037\n",
      "{'McFadden': 0.02439700878001272, 'Cox & Snell': np.float64(0.015090189180396174), 'Nagelkerke': np.float64(0.032536266652080884)}\n"
     ]
    }
   ],
   "source": [
    "mods_m=[]\n",
    "\n",
    "for i in range(1960,2021,10):\n",
    "    print(\"#########################################\")\n",
    "    print(str(i-10)+' to '+str(i-1) + \" inclusive\")\n",
    "    print(\"#########################################\")\n",
    "    # test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)].reset_index(drop=True)\n",
    "    test_df=df_c[(df_c[\"tij\"]<i)&(df_c[\"tij\"]>=i-10)][[\"pij_t\",'cij_t',\"ytij\",\"tij\",\"tij_0\",\"tij_1\",\"Author\", \"Coauthor\",\"E\",\"avg_p\",\"abs_p\",'avg_c',\"abs_c\",\"aff_js\"]].drop_duplicates().reset_index(drop=True)\n",
    "    # plothist(test_df, \"pij_t\")\n",
    "    # plothist(test_df, \"E\")\n",
    "    test_df[\"log(cij)\"]=np.log(test_df['cij_t'].clip(lower=0.0001))\n",
    "\n",
    "    X=test_df[[\"pij_t\",'log(cij)',\"E\",\"abs_p\", \"avg_p\",'abs_c',\"avg_c\",\"aff_js\"]].fillna(0)\n",
    "    y=test_df[\"ytij\"]\n",
    "    print()\n",
    "    mods_m.append(logi_mod(X,y, False, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "1950 to 1959 inclusive\n",
      "#########################################\n",
      "\n",
      "(767, 8)\n",
      "\n",
      "Logistic Regression Results:\n",
      "                    Variable  Coefficient    Std. Error       z-value  \\\n",
      "0                  Intercept    -0.458498  2.259597e+06 -2.029116e-07   \n",
      "1                   log(cij)    -0.003132  1.466130e+06 -2.135913e-09   \n",
      "2                          E     1.690864  3.095701e+06  5.461976e-07   \n",
      "3                      abs_p    -0.275008  1.847648e-01 -1.488425e+00   \n",
      "4                      avg_p     0.527594  2.061911e-01  2.558762e+00   \n",
      "5                      abs_c     0.835116  6.886859e-01  1.212622e+00   \n",
      "6                      avg_c    -0.613898  6.970217e-01 -8.807449e-01   \n",
      "7                     aff_js     0.453309  1.054096e-01  4.300452e+00   \n",
      "8                        E_1    -0.136138  4.571657e+06 -2.977870e-08   \n",
      "9                        E_2     0.633825  9.143313e+06  6.932114e-08   \n",
      "10                pij_t_0.25    -0.288584  1.443118e+07 -1.999725e-08   \n",
      "11  pij_t_0.3333333333333333    -0.307981  1.443118e+07 -2.134136e-08   \n",
      "12                 pij_t_0.5     0.595961  1.443118e+07  4.129678e-08   \n",
      "\n",
      "     p-value Significance       t-value  p_values_t Significance_t  \n",
      "0   1.000000              -2.029116e-07    1.000000                 \n",
      "1   1.000000              -2.135913e-09    1.000000                 \n",
      "2   1.000000               5.461976e-07    1.000000                 \n",
      "3   0.136639              -1.488425e+00    0.137057                 \n",
      "4   0.010505            *  2.558762e+00    0.010698              *  \n",
      "5   0.225274               1.212622e+00    0.225654                 \n",
      "6   0.378456              -8.807449e-01    0.378736                 \n",
      "7   0.000017          ***  4.300452e+00    0.000019            ***  \n",
      "8   1.000000              -2.977870e-08    1.000000                 \n",
      "9   1.000000               6.932114e-08    1.000000                 \n",
      "10  1.000000              -1.999725e-08    1.000000                 \n",
      "11  1.000000              -2.134136e-08    1.000000                 \n",
      "12  1.000000               4.129678e-08    1.000000                 \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       472\n",
      "           1       0.72      0.73      0.73       295\n",
      "\n",
      "    accuracy                           0.79       767\n",
      "   macro avg       0.78      0.78      0.78       767\n",
      "weighted avg       0.79      0.79      0.79       767\n",
      "\n",
      "Confusion Matrix:\n",
      "[[388  84]\n",
      " [ 79 216]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- pij_t\nFeature names seen at fit time, yet now missing:\n- E_1\n- E_2\n- pij_t_0.25\n- pij_t_0.3333333333333333\n- pij_t_0.5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[518], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m y\u001b[38;5;241m=\u001b[39mtest_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mytij\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m---> 16\u001b[0m mods_n\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlogi_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[508], line 61\u001b[0m, in \u001b[0;36mlogi_mod\u001b[0;34m(df, y, e, C)\u001b[0m\n\u001b[1;32m     58\u001b[0m conf\u001b[38;5;241m=\u001b[39mconfusion_matrix(y, y_pred)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(conf)\n\u001b[0;32m---> 61\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# newX = pd.DataFrame({\"Constant\":np.ones(len(X))}).join(pd.DataFrame(X))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m newX \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstant\u001b[39m\u001b[38;5;124m\"\u001b[39m:np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(X_scaled))})\u001b[38;5;241m.\u001b[39mjoin(pd\u001b[38;5;241m.\u001b[39mDataFrame(X_scaled\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)))\n",
      "File \u001b[0;32m~/Work/80YearsEconomicResearch/venv/lib/python3.11/site-packages/sklearn/linear_model/_base.py:374\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 374\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    376\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[0;32m~/Work/80YearsEconomicResearch/venv/lib/python3.11/site-packages/sklearn/linear_model/_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    349\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 351\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m     xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (scores\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[1;32m    357\u001b[0m )\n",
      "File \u001b[0;32m~/Work/80YearsEconomicResearch/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[1;32m   2836\u001b[0m     _estimator,\n\u001b[1;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m   2844\u001b[0m ):\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \n\u001b[1;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2919\u001b[0m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[1;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[0;32m~/Work/80YearsEconomicResearch/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- pij_t\nFeature names seen at fit time, yet now missing:\n- E_1\n- E_2\n- pij_t_0.25\n- pij_t_0.3333333333333333\n- pij_t_0.5\n"
     ]
    }
   ],
   "source": [
    "mods_n=[]\n",
    "\n",
    "for i in range(1960,2021,10):\n",
    "    print(\"#########################################\")\n",
    "    print(str(i-10)+' to '+str(i-1) + \" inclusive\")\n",
    "    print(\"#########################################\")\n",
    "    # test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)].reset_index(drop=True)\n",
    "    test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)][[\"pij_t\",'cij_t',\"ytij\",\"tij\",\"tij_0\",\"tij_1\",\"Author\", \"Coauthor\",\"E\",\"avg_p\",\"abs_p\",'avg_c',\"abs_c\",\"aff_js\"]].drop_duplicates().reset_index(drop=True)\n",
    "    # plothist(test_df, \"pij_t\")\n",
    "    # plothist(test_df, \"E\")\n",
    "    test_df[\"log(cij)\"]=np.log(test_df['cij_t'].clip(lower=0.0001))\n",
    "\n",
    "    X=test_df[[\"pij_t\",'log(cij)',\"E\",\"abs_p\", \"avg_p\",'abs_c',\"avg_c\",\"aff_js\"]].fillna(0)\n",
    "    y=test_df[\"ytij\"]\n",
    "    print()\n",
    "    mods_n.append(logi_mod(X,y, True, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\makecell[l]{Intercept}&\\makecell[c]{-0.563484***\\\\(0.083945)\\\\0.0} & \\makecell[c]{-0.75543***\\\\(0.078794)\\\\0.0}& \\makecell[c]{-0.929056***\\\\(0.044586)\\\\0.0}& \\makecell[c]{-1.193856***\\\\(0.032718)\\\\0.0}& \\makecell[c]{-1.311699***\\\\(0.030996)\\\\0.0}& \\makecell[c]{-1.238224***\\\\(0.024602)\\\\0.0}& \\makecell[c]{-0.289095***\\\\(0.01898)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{pij t}&\\makecell[c]{0.618366\\\\(0.487783)\\\\0.204902} & \\makecell[c]{0.231614\\\\(0.552249)\\\\0.674924}& \\makecell[c]{-0.261464*\\\\(0.112043)\\\\0.019616}& \\makecell[c]{0.117137.\\\\(0.064591)\\\\0.06975}& \\makecell[c]{0.176512***\\\\(0.051177)\\\\0.000563}& \\makecell[c]{0.198137***\\\\(0.039453)\\\\1e-06}& \\makecell[c]{0.261111***\\\\(0.034389)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{log(cij)}&\\makecell[c]{-0.534014\\\\(0.554187)\\\\0.335247} & \\makecell[c]{-0.186552\\\\(0.581718)\\\\0.748444}& \\makecell[c]{0.424183***\\\\(0.108242)\\\\8.9e-05}& \\makecell[c]{0.049611\\\\(0.072117)\\\\0.491499}& \\makecell[c]{0.100406.\\\\(0.055864)\\\\0.072287}& \\makecell[c]{-0.034549\\\\(0.045226)\\\\0.44491}& \\makecell[c]{-0.161734***\\\\(0.037286)\\\\1.4e-05}\\\\\\\\\n",
      "\\makecell[l]{abs p}&\\makecell[c]{0.775736***\\\\(0.184249)\\\\2.6e-05} & \\makecell[c]{1.143605***\\\\(0.170943)\\\\0.0}& \\makecell[c]{1.03457***\\\\(0.116782)\\\\0.0}& \\makecell[c]{0.756055***\\\\(0.063501)\\\\0.0}& \\makecell[c]{0.709399***\\\\(0.054657)\\\\0.0}& \\makecell[c]{0.76543***\\\\(0.052329)\\\\0.0}& \\makecell[c]{0.635292***\\\\(0.039622)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{avg p}&\\makecell[c]{-1.083874***\\\\(0.204184)\\\\0.0} & \\makecell[c]{-2.227038***\\\\(0.232998)\\\\0.0}& \\makecell[c]{-1.943753***\\\\(0.13943)\\\\0.0}& \\makecell[c]{-1.221451***\\\\(0.077952)\\\\0.0}& \\makecell[c]{-1.341546***\\\\(0.072443)\\\\0.0}& \\makecell[c]{-1.170897***\\\\(0.066844)\\\\0.0}& \\makecell[c]{-1.007087***\\\\(0.049601)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{abs c}&\\makecell[c]{1.422351*\\\\(0.623463)\\\\0.022526} & \\makecell[c]{0.136128\\\\(0.177712)\\\\0.443674}& \\makecell[c]{-0.031177\\\\(0.064751)\\\\0.630166}& \\makecell[c]{0.07312.\\\\(0.040564)\\\\0.071452}& \\makecell[c]{0.135859***\\\\(0.034823)\\\\9.6e-05}& \\makecell[c]{0.134178***\\\\(0.026086)\\\\0.0}& \\makecell[c]{0.267634***\\\\(0.022034)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{avg c}&\\makecell[c]{-1.428085*\\\\(0.627815)\\\\0.022924} & \\makecell[c]{-0.352335*\\\\(0.178834)\\\\0.048818}& \\makecell[c]{-0.237294***\\\\(0.068255)\\\\0.000508}& \\makecell[c]{-0.633558***\\\\(0.046818)\\\\0.0}& \\makecell[c]{-0.76405***\\\\(0.04233)\\\\0.0}& \\makecell[c]{-0.780739***\\\\(0.033696)\\\\0.0}& \\makecell[c]{-0.794732***\\\\(0.028013)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{aff js}&\\makecell[c]{0.546486***\\\\(0.083984)\\\\0.0} & \\makecell[c]{0.665742***\\\\(0.066137)\\\\0.0}& \\makecell[c]{0.589211***\\\\(0.037336)\\\\0.0}& \\makecell[c]{0.471428***\\\\(0.027015)\\\\0.0}& \\makecell[c]{0.366703***\\\\(0.024271)\\\\0.0}& \\makecell[c]{0.24372***\\\\(0.019889)\\\\0.0}& \\makecell[c]{0.208703***\\\\(0.019244)\\\\0.0}\\\\\\\\\n"
     ]
    }
   ],
   "source": [
    "print_latex_format(mods_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18385, 2)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10[[\"Author\",\"Coauthor\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9755, 2)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10[(upd_w_lags_10[\"tij_0\"]==upd_w_lags_10[\"tij_1\"])&(upd_w_lags_10[\"tij_2\"]==upd_w_lags_10[\"tij_1\"])][[\"Author\",\"Coauthor\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "1950 to 1959 inclusive\n",
      "#########################################\n",
      "\n",
      "(767, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error   z-value       p-value Significance  \\\n",
      "0  Intercept    -0.612833    0.088027 -6.961894  3.357314e-12          ***   \n",
      "1      pij_t     0.808875    0.463251  1.746082  8.079674e-02            .   \n",
      "2   log(cij)    -0.674498    0.508699 -1.325927  1.848639e-01                \n",
      "3      abs_p     1.041724    0.203324  5.123471  2.999624e-07          ***   \n",
      "4      avg_p    -1.403936    0.231199 -6.072410  1.260050e-09          ***   \n",
      "5      abs_c     1.380156    0.745480  1.851365  6.411708e-02            .   \n",
      "6      avg_c    -1.409104    0.751326 -1.875489  6.072546e-02            .   \n",
      "7     aff_js     0.591982    0.083186  7.116335  1.108447e-12          ***   \n",
      "\n",
      "    t-value    p_values_t Significance_t  \n",
      "0 -6.961894  7.265522e-12            ***  \n",
      "1  1.746082  8.120079e-02              .  \n",
      "2 -1.325927  1.852623e-01                 \n",
      "3  5.123471  3.806806e-07            ***  \n",
      "4 -6.072410  1.989495e-09            ***  \n",
      "5  1.851365  6.450481e-02              .  \n",
      "6 -1.875489  6.110863e-02              .  \n",
      "7  7.116335  2.567058e-12            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80       472\n",
      "           1       0.75      0.42      0.54       295\n",
      "\n",
      "    accuracy                           0.72       767\n",
      "   macro avg       0.73      0.67      0.67       767\n",
      "weighted avg       0.73      0.72      0.70       767\n",
      "\n",
      "Confusion Matrix:\n",
      "[[431  41]\n",
      " [172 123]]\n",
      "0.461133069828722\n",
      "#########################################\n",
      "1960 to 1969 inclusive\n",
      "#########################################\n",
      "\n",
      "(1439, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -0.635815    0.070531  -9.014685  0.000000          ***   \n",
      "1      pij_t     0.183459    0.617979   0.296869  0.766566                \n",
      "2   log(cij)    -0.144731    0.652647  -0.221760  0.824501                \n",
      "3      abs_p     0.605225    0.141083   4.289834  0.000018          ***   \n",
      "4      avg_p    -1.529982    0.181461  -8.431469  0.000000          ***   \n",
      "5      abs_c     0.118813    0.140263   0.847074  0.396954                \n",
      "6      avg_c    -0.319781    0.149662  -2.136684  0.032624            *   \n",
      "7     aff_js     0.775442    0.064919  11.944838  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0  -9.014685    0.000000            ***  \n",
      "1   0.296869    0.766609                 \n",
      "2  -0.221760    0.824533                 \n",
      "3   4.289834    0.000019            ***  \n",
      "4  -8.431469    0.000000            ***  \n",
      "5   0.847074    0.397096                 \n",
      "6  -2.136684    0.032793              *  \n",
      "7  11.944838    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81       872\n",
      "           1       0.76      0.49      0.59       567\n",
      "\n",
      "    accuracy                           0.74      1439\n",
      "   macro avg       0.75      0.69      0.70      1439\n",
      "weighted avg       0.74      0.74      0.72      1439\n",
      "\n",
      "Confusion Matrix:\n",
      "[[787  85]\n",
      " [292 275]]\n",
      "0.2676450034940601\n",
      "#########################################\n",
      "1970 to 1979 inclusive\n",
      "#########################################\n",
      "\n",
      "(4019, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -0.885191    0.042320 -20.916428  0.000000          ***   \n",
      "1      pij_t    -0.223066    0.106751  -2.089597  0.036654            *   \n",
      "2   log(cij)     0.313105    0.100569   3.113335  0.001850           **   \n",
      "3      abs_p     0.410649    0.096214   4.268098  0.000020          ***   \n",
      "4      avg_p    -1.339101    0.109074 -12.276961  0.000000          ***   \n",
      "5      abs_c    -0.081076    0.066325  -1.222403  0.221555                \n",
      "6      avg_c    -0.222734    0.069946  -3.184353  0.001451           **   \n",
      "7     aff_js     0.711721    0.037623  18.917322  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -20.916428    0.000000            ***  \n",
      "1  -2.089597    0.036717              *  \n",
      "2   3.113335    0.001863             **  \n",
      "3   4.268098    0.000020            ***  \n",
      "4 -12.276961    0.000000            ***  \n",
      "5  -1.222403    0.221627                 \n",
      "6  -3.184353    0.001462             **  \n",
      "7  18.917322    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83      2643\n",
      "           1       0.74      0.41      0.53      1376\n",
      "\n",
      "    accuracy                           0.75      4019\n",
      "   macro avg       0.74      0.67      0.68      4019\n",
      "weighted avg       0.75      0.75      0.73      4019\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2440  203]\n",
      " [ 807  569]]\n",
      "0.3430565943654949\n",
      "#########################################\n",
      "1980 to 1989 inclusive\n",
      "#########################################\n",
      "\n",
      "(7307, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -1.179375    0.032192 -36.635227  0.000000          ***   \n",
      "1      pij_t     0.123560    0.065851   1.876362  0.060606            .   \n",
      "2   log(cij)    -0.044206    0.072577  -0.609093  0.542463                \n",
      "3      abs_p     0.498861    0.059452   8.390947  0.000000          ***   \n",
      "4      avg_p    -0.988295    0.071843 -13.756260  0.000000          ***   \n",
      "5      abs_c     0.015075    0.044549   0.338402  0.735060                \n",
      "6      avg_c    -0.551250    0.051039 -10.800640  0.000000          ***   \n",
      "7     aff_js     0.611262    0.027201  22.472402  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -36.635227    0.000000            ***  \n",
      "1   1.876362    0.060645              .  \n",
      "2  -0.609093    0.542482                 \n",
      "3   8.390947    0.000000            ***  \n",
      "4 -13.756260    0.000000            ***  \n",
      "5   0.338402    0.735070                 \n",
      "6 -10.800640    0.000000            ***  \n",
      "7  22.472402    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86      5261\n",
      "           1       0.72      0.30      0.43      2046\n",
      "\n",
      "    accuracy                           0.77      7307\n",
      "   macro avg       0.75      0.63      0.64      7307\n",
      "weighted avg       0.76      0.77      0.74      7307\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5013  248]\n",
      " [1423  623]]\n",
      "0.279901356350185\n",
      "#########################################\n",
      "1990 to 1999 inclusive\n",
      "#########################################\n",
      "\n",
      "(9314, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -1.266905    0.030028 -42.190777  0.000000          ***   \n",
      "1      pij_t     0.154178    0.052244   2.951120  0.003166           **   \n",
      "2   log(cij)    -0.142662    0.054202  -2.632063  0.008487           **   \n",
      "3      abs_p     0.480801    0.055611   8.645795  0.000000          ***   \n",
      "4      avg_p    -1.094929    0.071801 -15.249583  0.000000          ***   \n",
      "5      abs_c     0.029772    0.038186   0.779670  0.435585                \n",
      "6      avg_c    -0.508697    0.045881 -11.087380  0.000000          ***   \n",
      "7     aff_js     0.550139    0.024580  22.381409  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -42.190777    0.000000            ***  \n",
      "1   2.951120    0.003174             **  \n",
      "2  -2.632063    0.008501             **  \n",
      "3   8.645795    0.000000            ***  \n",
      "4 -15.249583    0.000000            ***  \n",
      "5   0.779670    0.435605                 \n",
      "6 -11.087380    0.000000            ***  \n",
      "7  22.381409    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86      6792\n",
      "           1       0.73      0.24      0.36      2522\n",
      "\n",
      "    accuracy                           0.77      9314\n",
      "   macro avg       0.75      0.60      0.61      9314\n",
      "weighted avg       0.76      0.77      0.72      9314\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6566  226]\n",
      " [1923  599]]\n",
      "0.22125510423382763\n",
      "#########################################\n",
      "2000 to 2009 inclusive\n",
      "#########################################\n",
      "\n",
      "(13594, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -1.193444    0.023788 -50.169553  0.000000e+00          ***   \n",
      "1      pij_t     0.141386    0.039978   3.536549  4.053914e-04          ***   \n",
      "2   log(cij)    -0.261114    0.043111  -6.056743  1.389055e-09          ***   \n",
      "3      abs_p     0.548021    0.049609  11.046829  0.000000e+00          ***   \n",
      "4      avg_p    -0.918676    0.062670 -14.659048  0.000000e+00          ***   \n",
      "5      abs_c     0.018334    0.027432   0.668344  5.039141e-01                \n",
      "6      avg_c    -0.551431    0.034890 -15.805035  0.000000e+00          ***   \n",
      "7     aff_js     0.354655    0.019789  17.921384  0.000000e+00          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -50.169553  0.000000e+00            ***  \n",
      "1   3.536549  4.067418e-04            ***  \n",
      "2  -6.056743  1.425715e-09            ***  \n",
      "3  11.046829  0.000000e+00            ***  \n",
      "4 -14.659048  0.000000e+00            ***  \n",
      "5   0.668344  5.039255e-01                 \n",
      "6 -15.805035  0.000000e+00            ***  \n",
      "7  17.921384  0.000000e+00            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85      9836\n",
      "           1       0.72      0.16      0.27      3758\n",
      "\n",
      "    accuracy                           0.75     13594\n",
      "   macro avg       0.74      0.57      0.56     13594\n",
      "weighted avg       0.74      0.75      0.69     13594\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9597  239]\n",
      " [3138  620]]\n",
      "0.36670101575150893\n",
      "#########################################\n",
      "2010 to 2019 inclusive\n",
      "#########################################\n",
      "\n",
      "(15021, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -0.278826    0.018769 -14.855799  0.000000e+00          ***   \n",
      "1      pij_t     0.212267    0.034957   6.072218  1.261554e-09          ***   \n",
      "2   log(cij)    -0.422242    0.035798 -11.795166  0.000000e+00          ***   \n",
      "3      abs_p     0.428131    0.036534  11.718812  0.000000e+00          ***   \n",
      "4      avg_p    -0.800340    0.044608 -17.941580  0.000000e+00          ***   \n",
      "5      abs_c     0.130396    0.022766   5.727672  1.018179e-08          ***   \n",
      "6      avg_c    -0.526857    0.028465 -18.508827  0.000000e+00          ***   \n",
      "7     aff_js     0.335043    0.019496  17.185174  0.000000e+00          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -14.855799  0.000000e+00            ***  \n",
      "1   6.072218  1.291957e-09            ***  \n",
      "2 -11.795166  0.000000e+00            ***  \n",
      "3  11.718812  0.000000e+00            ***  \n",
      "4 -17.941580  0.000000e+00            ***  \n",
      "5   5.727672  1.037681e-08            ***  \n",
      "6 -18.508827  0.000000e+00            ***  \n",
      "7  17.185174  0.000000e+00            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71      8211\n",
      "           1       0.65      0.72      0.68      6810\n",
      "\n",
      "    accuracy                           0.70     15021\n",
      "   macro avg       0.70      0.70      0.70     15021\n",
      "weighted avg       0.70      0.70      0.70     15021\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5527 2684]\n",
      " [1877 4933]]\n",
      "0.3143275827616066\n"
     ]
    }
   ],
   "source": [
    "mods_e=[]\n",
    "for i in range(1960,2021,10):\n",
    "    print(\"#########################################\")\n",
    "    print(str(i-10)+' to '+str(i-1) + \" inclusive\")\n",
    "    print(\"#########################################\")\n",
    "    # test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)].reset_index(drop=True)\n",
    "    test_df=df_f_5[(df_f_5[\"tij\"]<i)&(df_f_5[\"tij\"]>=i-10)][[\"pij_t\",'cij_t',\"ytij\",\"tij\",\"tij_0\",\"tij_1\",\"Author\", \"Coauthor\",\"E\",\"avg_p\",\"abs_p\",'avg_c',\"abs_c\",\"aff_js\"]].drop_duplicates().reset_index(drop=True)\n",
    "    # plothist(test_df, \"pij_t\")\n",
    "    # plothist(test_df, \"E\")\n",
    "    test_df[\"log(cij)\"]=np.log(test_df['cij_t'].clip(lower=0.0001))\n",
    "\n",
    "    X=test_df[[\"pij_t\",'log(cij)',\"E\",\"abs_p\", \"avg_p\",'abs_c',\"avg_c\",\"aff_js\"]].fillna(0)\n",
    "    y=test_df[\"ytij\"]\n",
    "    print()\n",
    "    mods_e.append(logi_mod(X,y, False, 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\makecell[l]{Intercept}&\\makecell[c]{-0.612833***\\\\(0.088027)\\\\0.0} & \\makecell[c]{-0.635815***\\\\(0.070531)\\\\0.0}& \\makecell[c]{-0.885191***\\\\(0.04232)\\\\0.0}& \\makecell[c]{-1.179375***\\\\(0.032192)\\\\0.0}& \\makecell[c]{-1.266905***\\\\(0.030028)\\\\0.0}& \\makecell[c]{-1.193444***\\\\(0.023788)\\\\0.0}& \\makecell[c]{-0.278826***\\\\(0.018769)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{pij t}&\\makecell[c]{0.808875.\\\\(0.463251)\\\\0.080797} & \\makecell[c]{0.183459\\\\(0.617979)\\\\0.766566}& \\makecell[c]{-0.223066*\\\\(0.106751)\\\\0.036654}& \\makecell[c]{0.12356.\\\\(0.065851)\\\\0.060606}& \\makecell[c]{0.154178**\\\\(0.052244)\\\\0.003166}& \\makecell[c]{0.141386***\\\\(0.039978)\\\\0.000405}& \\makecell[c]{0.212267***\\\\(0.034957)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{log(cij)}&\\makecell[c]{-0.674498\\\\(0.508699)\\\\0.184864} & \\makecell[c]{-0.144731\\\\(0.652647)\\\\0.824501}& \\makecell[c]{0.313105**\\\\(0.100569)\\\\0.00185}& \\makecell[c]{-0.044206\\\\(0.072577)\\\\0.542463}& \\makecell[c]{-0.142662**\\\\(0.054202)\\\\0.008487}& \\makecell[c]{-0.261114***\\\\(0.043111)\\\\0.0}& \\makecell[c]{-0.422242***\\\\(0.035798)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{abs p}&\\makecell[c]{1.041724***\\\\(0.203324)\\\\0.0} & \\makecell[c]{0.605225***\\\\(0.141083)\\\\1.8e-05}& \\makecell[c]{0.410649***\\\\(0.096214)\\\\2e-05}& \\makecell[c]{0.498861***\\\\(0.059452)\\\\0.0}& \\makecell[c]{0.480801***\\\\(0.055611)\\\\0.0}& \\makecell[c]{0.548021***\\\\(0.049609)\\\\0.0}& \\makecell[c]{0.428131***\\\\(0.036534)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{avg p}&\\makecell[c]{-1.403936***\\\\(0.231199)\\\\0.0} & \\makecell[c]{-1.529982***\\\\(0.181461)\\\\0.0}& \\makecell[c]{-1.339101***\\\\(0.109074)\\\\0.0}& \\makecell[c]{-0.988295***\\\\(0.071843)\\\\0.0}& \\makecell[c]{-1.094929***\\\\(0.071801)\\\\0.0}& \\makecell[c]{-0.918676***\\\\(0.06267)\\\\0.0}& \\makecell[c]{-0.80034***\\\\(0.044608)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{abs c}&\\makecell[c]{1.380156.\\\\(0.74548)\\\\0.064117} & \\makecell[c]{0.118813\\\\(0.140263)\\\\0.396954}& \\makecell[c]{-0.081076\\\\(0.066325)\\\\0.221555}& \\makecell[c]{0.015075\\\\(0.044549)\\\\0.73506}& \\makecell[c]{0.029772\\\\(0.038186)\\\\0.435585}& \\makecell[c]{0.018334\\\\(0.027432)\\\\0.503914}& \\makecell[c]{0.130396***\\\\(0.022766)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{avg c}&\\makecell[c]{-1.409104.\\\\(0.751326)\\\\0.060725} & \\makecell[c]{-0.319781*\\\\(0.149662)\\\\0.032624}& \\makecell[c]{-0.222734**\\\\(0.069946)\\\\0.001451}& \\makecell[c]{-0.55125***\\\\(0.051039)\\\\0.0}& \\makecell[c]{-0.508697***\\\\(0.045881)\\\\0.0}& \\makecell[c]{-0.551431***\\\\(0.03489)\\\\0.0}& \\makecell[c]{-0.526857***\\\\(0.028465)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{aff js}&\\makecell[c]{0.591982***\\\\(0.083186)\\\\0.0} & \\makecell[c]{0.775442***\\\\(0.064919)\\\\0.0}& \\makecell[c]{0.711721***\\\\(0.037623)\\\\0.0}& \\makecell[c]{0.611262***\\\\(0.027201)\\\\0.0}& \\makecell[c]{0.550139***\\\\(0.02458)\\\\0.0}& \\makecell[c]{0.354655***\\\\(0.019789)\\\\0.0}& \\makecell[c]{0.335043***\\\\(0.019496)\\\\0.0}\\\\\\\\\n"
     ]
    }
   ],
   "source": [
    "print_latex_format(mods_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "1960 to 1969 inclusive\n",
      "#########################################\n",
      "[0 1]\n",
      "\n",
      "(1439, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error   z-value       p-value Significance  \\\n",
      "0  Intercept    -0.763396    0.080386 -9.496674  0.000000e+00          ***   \n",
      "1      pij_t     0.241372    0.540990  0.446167  6.554765e-01                \n",
      "2   log(cij)    -0.197819    0.569755 -0.347199  7.284417e-01                \n",
      "3      abs_p     1.463265    0.222692  6.570790  5.004908e-11          ***   \n",
      "4      avg_p    -2.524037    0.280779 -8.989411  0.000000e+00          ***   \n",
      "5      abs_c     0.273811    0.177277  1.544539  1.224578e-01                \n",
      "6      avg_c    -0.421607    0.183271 -2.300451  2.142266e-02            *   \n",
      "7     aff_js     0.643839    0.067920  9.479414  0.000000e+00          ***   \n",
      "\n",
      "    t-value    p_values_t Significance_t  \n",
      "0 -9.496674  0.000000e+00            ***  \n",
      "1  0.446167  6.555439e-01                 \n",
      "2 -0.347199  7.284928e-01                 \n",
      "3  6.570790  6.987788e-11            ***  \n",
      "4 -8.989411  0.000000e+00            ***  \n",
      "5  1.544539  1.226788e-01                 \n",
      "6 -2.300451  2.156582e-02              *  \n",
      "7  9.479414  0.000000e+00            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81       872\n",
      "           1       0.76      0.48      0.59       567\n",
      "\n",
      "    accuracy                           0.74      1439\n",
      "   macro avg       0.74      0.69      0.70      1439\n",
      "weighted avg       0.74      0.74      0.72      1439\n",
      "\n",
      "Confusion Matrix:\n",
      "[[787  85]\n",
      " [295 272]]\n",
      "0.27393431167016075\n",
      "#########################################\n",
      "1970 to 1979 inclusive\n",
      "#########################################\n",
      "[0 1 2 4 3]\n",
      "\n",
      "(4019, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -0.973154    0.047148 -20.640221  0.000000          ***   \n",
      "1      pij_t    -0.359071    0.119796  -2.997346  0.002723           **   \n",
      "2   log(cij)     0.546784    0.122971   4.446446  0.000009          ***   \n",
      "3      abs_p     1.556855    0.144394  10.782012  0.000000          ***   \n",
      "4      avg_p    -2.518388    0.181209 -13.897674  0.000000          ***   \n",
      "5      abs_c    -0.016410    0.065000  -0.252470  0.800678                \n",
      "6      avg_c    -0.285519    0.068043  -4.196120  0.000027          ***   \n",
      "7     aff_js     0.534825    0.037571  14.235182  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -20.640221    0.000000            ***  \n",
      "1  -2.997346    0.002740             **  \n",
      "2   4.446446    0.000009            ***  \n",
      "3  10.782012    0.000000            ***  \n",
      "4 -13.897674    0.000000            ***  \n",
      "5  -0.252470    0.800691                 \n",
      "6  -4.196120    0.000028            ***  \n",
      "7  14.235182    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82      2643\n",
      "           1       0.72      0.38      0.50      1376\n",
      "\n",
      "    accuracy                           0.74      4019\n",
      "   macro avg       0.73      0.65      0.66      4019\n",
      "weighted avg       0.73      0.74      0.71      4019\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2439  204]\n",
      " [ 855  521]]\n",
      "0.37496883570182\n",
      "#########################################\n",
      "1980 to 1989 inclusive\n",
      "#########################################\n",
      "[0 1 2 3 4 6 5]\n",
      "\n",
      "(7307, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -1.234341    0.034200 -36.091393  0.000000          ***   \n",
      "1      pij_t     0.084285    0.063475   1.327848  0.184228                \n",
      "2   log(cij)     0.086051    0.071115   1.210030  0.226268                \n",
      "3      abs_p     1.137430    0.077869  14.606961  0.000000          ***   \n",
      "4      avg_p    -1.631405    0.096228 -16.953492  0.000000          ***   \n",
      "5      abs_c     0.075351    0.039167   1.923863  0.054372            .   \n",
      "6      avg_c    -0.619248    0.044951 -13.776013  0.000000          ***   \n",
      "7     aff_js     0.410252    0.027117  15.129084  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -36.091393    0.000000            ***  \n",
      "1   1.327848    0.184270                 \n",
      "2   1.210030    0.226307                 \n",
      "3  14.606961    0.000000            ***  \n",
      "4 -16.953492    0.000000            ***  \n",
      "5   1.923863    0.054411              .  \n",
      "6 -13.776013    0.000000            ***  \n",
      "7  15.129084    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85      5261\n",
      "           1       0.66      0.26      0.37      2046\n",
      "\n",
      "    accuracy                           0.76      7307\n",
      "   macro avg       0.72      0.60      0.61      7307\n",
      "weighted avg       0.74      0.76      0.72      7307\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4992  269]\n",
      " [1514  532]]\n",
      "0.34278668310727495\n",
      "#########################################\n",
      "1990 to 1999 inclusive\n",
      "#########################################\n",
      "[ 0  1  2  4  6  3  5 20 18 16  8 10  7]\n",
      "\n",
      "(9314, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -1.338890    0.031641 -42.314455  0.000000e+00          ***   \n",
      "1      pij_t     0.161192    0.050721   3.178028  1.482802e-03           **   \n",
      "2   log(cij)     0.083978    0.054758   1.533618  1.251236e-01                \n",
      "3      abs_p     0.851436    0.057726  14.749576  0.000000e+00          ***   \n",
      "4      avg_p    -1.440894    0.076126 -18.927645  0.000000e+00          ***   \n",
      "5      abs_c     0.182007    0.033113   5.496579  3.872300e-08          ***   \n",
      "6      avg_c    -0.861426    0.040309 -21.370627  0.000000e+00          ***   \n",
      "7     aff_js     0.265769    0.024412  10.886677  0.000000e+00          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -42.314455  0.000000e+00            ***  \n",
      "1   3.178028  1.487653e-03             **  \n",
      "2   1.533618  1.251576e-01                 \n",
      "3  14.749576  0.000000e+00            ***  \n",
      "4 -18.927645  0.000000e+00            ***  \n",
      "5   5.496579  3.974559e-08            ***  \n",
      "6 -21.370627  0.000000e+00            ***  \n",
      "7  10.886677  0.000000e+00            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87      6792\n",
      "           1       0.72      0.41      0.52      2522\n",
      "\n",
      "    accuracy                           0.80      9314\n",
      "   macro avg       0.76      0.67      0.69      9314\n",
      "weighted avg       0.79      0.80      0.78      9314\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6392  400]\n",
      " [1498 1024]]\n",
      "0.2784225231033742\n",
      "#########################################\n",
      "2000 to 2009 inclusive\n",
      "#########################################\n",
      "[ 0  1  5  2  4  3  6  7  8 15 16  9 14 12 13 22 26]\n",
      "\n",
      "(13594, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -1.274982    0.025290 -50.414924  0.000000e+00          ***   \n",
      "1      pij_t     0.201544    0.039508   5.101392  3.371636e-07          ***   \n",
      "2   log(cij)    -0.035963    0.044383  -0.810294  4.177712e-01                \n",
      "3      abs_p     0.839812    0.054194  15.496347  0.000000e+00          ***   \n",
      "4      avg_p    -1.253904    0.069754 -17.976155  0.000000e+00          ***   \n",
      "5      abs_c     0.173318    0.025234   6.868387  6.493250e-12          ***   \n",
      "6      avg_c    -0.888491    0.031781 -27.956678  0.000000e+00          ***   \n",
      "7     aff_js     0.128742    0.020135   6.393970  1.616334e-10          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -50.414924  0.000000e+00            ***  \n",
      "1   5.101392  3.417081e-07            ***  \n",
      "2  -0.810294  4.177854e-01                 \n",
      "3  15.496347  0.000000e+00            ***  \n",
      "4 -17.976155  0.000000e+00            ***  \n",
      "5   6.868387  6.775691e-12            ***  \n",
      "6 -27.956678  0.000000e+00            ***  \n",
      "7   6.393970  1.669191e-10            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      9836\n",
      "           1       0.70      0.38      0.49      3758\n",
      "\n",
      "    accuracy                           0.78     13594\n",
      "   macro avg       0.75      0.66      0.68     13594\n",
      "weighted avg       0.77      0.78      0.76     13594\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9216  620]\n",
      " [2321 1437]]\n",
      "0.3353452083026645\n",
      "#########################################\n",
      "2010 to 2019 inclusive\n",
      "#########################################\n",
      "[ 0  1  2  4  3  5  6  8  9  7 10 12 14 16 11 17 15 13 18 20 19 37]\n",
      "\n",
      "(15021, 7)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -0.290750    0.019107 -15.216780  0.000000e+00          ***   \n",
      "1      pij_t     0.233378    0.034330   6.798104  1.060041e-11          ***   \n",
      "2   log(cij)    -0.143503    0.036986  -3.879908  1.044960e-04          ***   \n",
      "3      abs_p     0.678996    0.043883  15.472751  0.000000e+00          ***   \n",
      "4      avg_p    -0.964130    0.052687 -18.299207  0.000000e+00          ***   \n",
      "5      abs_c     0.326912    0.021493  15.210202  0.000000e+00          ***   \n",
      "6      avg_c    -0.914660    0.027119 -33.728263  0.000000e+00          ***   \n",
      "7     aff_js     0.125392    0.019251   6.513513  7.341328e-11          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -15.216780  0.000000e+00            ***  \n",
      "1   6.798104  1.100009e-11            ***  \n",
      "2  -3.879908  1.049423e-04            ***  \n",
      "3  15.472751  0.000000e+00            ***  \n",
      "4 -18.299207  0.000000e+00            ***  \n",
      "5  15.210202  0.000000e+00            ***  \n",
      "6 -33.728263  0.000000e+00            ***  \n",
      "7   6.513513  7.574830e-11            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      8211\n",
      "           1       0.70      0.76      0.73      6810\n",
      "\n",
      "    accuracy                           0.75     15021\n",
      "   macro avg       0.75      0.75      0.75     15021\n",
      "weighted avg       0.75      0.75      0.75     15021\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6036 2175]\n",
      " [1620 5190]]\n",
      "0.29034836475054954\n"
     ]
    }
   ],
   "source": [
    "for i in range(1970,2021,10):\n",
    "    print(\"#########################################\")\n",
    "    print(str(i-10)+' to '+str(i-1) + \" inclusive\")\n",
    "    print(\"#########################################\")\n",
    "    # test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)].reset_index(drop=True)\n",
    "    test_df=df_f_20[(df_f_20[\"tij\"]<i)&(df_f_20[\"tij\"]>=i-10)][[\"pij_t\",'cij_t',\"ytij\",\"tij\",\"tij_0\",\"tij_1\",\"Author\", \"Coauthor\",\"E\",\"avg_p\",\"abs_p\",'avg_c',\"abs_c\",\"aff_js\"]].drop_duplicates().reset_index(drop=True)\n",
    "    # plothist(test_df, \"pij_t\")\n",
    "    # plothist(test_df, \"E\")\n",
    "    test_df[\"log(cij)\"]=np.log(test_df['cij_t'].clip(lower=0.0001))\n",
    "    print(test_df[\"cij_t\"].unique())\n",
    "    X=test_df[[\"pij_t\",'log(cij)',\"E\",\"abs_p\", \"avg_p\",'abs_c',\"avg_c\",\"aff_js\"]].fillna(0)\n",
    "    y=test_df[\"ytij\"]\n",
    "    print()\n",
    "    mods_e.append(logi_mod(X,y, False, 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\makecell[l]{Intercept}&\\makecell[c]{-0.763396***\\\\(0.080386)\\\\0.0} & \\makecell[c]{-0.973154***\\\\(0.047148)\\\\0.0}& \\makecell[c]{-1.234341***\\\\(0.0342)\\\\0.0}& \\makecell[c]{-1.33889***\\\\(0.031641)\\\\0.0}& \\makecell[c]{-1.274982***\\\\(0.02529)\\\\0.0}& \\makecell[c]{-0.29075***\\\\(0.019107)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{pij t}&\\makecell[c]{0.241372\\\\(0.54099)\\\\0.655476} & \\makecell[c]{-0.359071**\\\\(0.119796)\\\\0.002723}& \\makecell[c]{0.084285\\\\(0.063475)\\\\0.184228}& \\makecell[c]{0.161192**\\\\(0.050721)\\\\0.001483}& \\makecell[c]{0.201544***\\\\(0.039508)\\\\0.0}& \\makecell[c]{0.233378***\\\\(0.03433)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{log(cij)}&\\makecell[c]{-0.197819\\\\(0.569755)\\\\0.728442} & \\makecell[c]{0.546784***\\\\(0.122971)\\\\9e-06}& \\makecell[c]{0.086051\\\\(0.071115)\\\\0.226268}& \\makecell[c]{0.083978\\\\(0.054758)\\\\0.125124}& \\makecell[c]{-0.035963\\\\(0.044383)\\\\0.417771}& \\makecell[c]{-0.143503***\\\\(0.036986)\\\\0.000104}\\\\\\\\\n",
      "\\makecell[l]{abs p}&\\makecell[c]{1.463265***\\\\(0.222692)\\\\0.0} & \\makecell[c]{1.556855***\\\\(0.144394)\\\\0.0}& \\makecell[c]{1.13743***\\\\(0.077869)\\\\0.0}& \\makecell[c]{0.851436***\\\\(0.057726)\\\\0.0}& \\makecell[c]{0.839812***\\\\(0.054194)\\\\0.0}& \\makecell[c]{0.678996***\\\\(0.043883)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{avg p}&\\makecell[c]{-2.524037***\\\\(0.280779)\\\\0.0} & \\makecell[c]{-2.518388***\\\\(0.181209)\\\\0.0}& \\makecell[c]{-1.631405***\\\\(0.096228)\\\\0.0}& \\makecell[c]{-1.440894***\\\\(0.076126)\\\\0.0}& \\makecell[c]{-1.253904***\\\\(0.069754)\\\\0.0}& \\makecell[c]{-0.96413***\\\\(0.052687)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{abs c}&\\makecell[c]{0.273811\\\\(0.177277)\\\\0.122458} & \\makecell[c]{-0.01641\\\\(0.065)\\\\0.800678}& \\makecell[c]{0.075351.\\\\(0.039167)\\\\0.054372}& \\makecell[c]{0.182007***\\\\(0.033113)\\\\0.0}& \\makecell[c]{0.173318***\\\\(0.025234)\\\\0.0}& \\makecell[c]{0.326912***\\\\(0.021493)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{avg c}&\\makecell[c]{-0.421607*\\\\(0.183271)\\\\0.021423} & \\makecell[c]{-0.285519***\\\\(0.068043)\\\\2.7e-05}& \\makecell[c]{-0.619248***\\\\(0.044951)\\\\0.0}& \\makecell[c]{-0.861426***\\\\(0.040309)\\\\0.0}& \\makecell[c]{-0.888491***\\\\(0.031781)\\\\0.0}& \\makecell[c]{-0.91466***\\\\(0.027119)\\\\0.0}\\\\\\\\\n",
      "\\makecell[l]{aff js}&\\makecell[c]{0.643839***\\\\(0.06792)\\\\0.0} & \\makecell[c]{0.534825***\\\\(0.037571)\\\\0.0}& \\makecell[c]{0.410252***\\\\(0.027117)\\\\0.0}& \\makecell[c]{0.265769***\\\\(0.024412)\\\\0.0}& \\makecell[c]{0.128742***\\\\(0.020135)\\\\0.0}& \\makecell[c]{0.125392***\\\\(0.019251)\\\\0.0}\\\\\\\\\n"
     ]
    }
   ],
   "source": [
    "print_latex_format(mods_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1970,2021,10):\n",
    "    print(\"#########################################\")\n",
    "    print(str(i-10)+' to '+str(i-1) + \" inclusive\")\n",
    "    print(\"#########################################\")\n",
    "    # test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)].reset_index(drop=True)\n",
    "    test_df=df_f_20[(df_f_20[\"tij\"]<i)&(df_f_20[\"tij\"]>=i-10)][[\"pij_t\",'cij_t',\"ytij\",\"tij\",\"tij_0\",\"tij_1\",\"Author\", \"Coauthor\",\"E\",\"avg_p\",\"abs_p\",'avg_c',\"abs_c\",\"aff_js\"]].drop_duplicates().reset_index(drop=True)\n",
    "    # plothist(test_df, \"pij_t\")\n",
    "    # plothist(test_df, \"E\")\n",
    "    test_df[\"log(cij)\"]=np.log(test_df['cij_t'].clip(lower=0.0001))\n",
    "    print(test_df[\"cij_t\"].unique())\n",
    "    X=test_df[[\"pij_t\",'log(cij)',\"E\",\"abs_p\", \"avg_p\",'abs_c',\"avg_c\",\"aff_js\"]].fillna(0)\n",
    "    y=test_df[\"ytij\"]\n",
    "    print()\n",
    "    mods_e.append(logi_mod(X,y, False, 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  4,  3,  5,  6,  8,  9,  7, 10, 12, 14, 16, 11, 17, 15,\n",
       "       13, 18, 20, 19, 37])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"cij_t\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pij_t</th>\n",
       "      <th>cij_t</th>\n",
       "      <th>ytij</th>\n",
       "      <th>tij</th>\n",
       "      <th>tij_0</th>\n",
       "      <th>tij_1</th>\n",
       "      <th>Author</th>\n",
       "      <th>Coauthor</th>\n",
       "      <th>E</th>\n",
       "      <th>avg_p</th>\n",
       "      <th>abs_p</th>\n",
       "      <th>avg_c</th>\n",
       "      <th>abs_c</th>\n",
       "      <th>log(cij)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2002</td>\n",
       "      <td>2017</td>\n",
       "      <td>10031</td>\n",
       "      <td>14703</td>\n",
       "      <td>0</td>\n",
       "      <td>37.833333</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2006</td>\n",
       "      <td>2016</td>\n",
       "      <td>10121</td>\n",
       "      <td>10392</td>\n",
       "      <td>0</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.362500</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2006</td>\n",
       "      <td>2012</td>\n",
       "      <td>10121</td>\n",
       "      <td>11069</td>\n",
       "      <td>0</td>\n",
       "      <td>20.416667</td>\n",
       "      <td>32.833333</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2007</td>\n",
       "      <td>2014</td>\n",
       "      <td>10121</td>\n",
       "      <td>16229</td>\n",
       "      <td>0</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2008</td>\n",
       "      <td>2014</td>\n",
       "      <td>10121</td>\n",
       "      <td>16456</td>\n",
       "      <td>0</td>\n",
       "      <td>21.416667</td>\n",
       "      <td>30.833333</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pij_t  cij_t  ytij   tij  tij_0  tij_1 Author Coauthor  E      avg_p  \\\n",
       "1   0.090909      1     0  2010   2002   2017  10031    14703  0  37.833333   \n",
       "8   0.166667      2     0  2010   2006   2016  10121    10392  0  50.333333   \n",
       "9   0.125000      2     0  2010   2006   2012  10121    11069  0  20.416667   \n",
       "10  0.333333      1     0  2010   2007   2014  10121    16229  0  36.333333   \n",
       "11  0.142857      2     0  2010   2008   2014  10121    16456  0  21.416667   \n",
       "\n",
       "        abs_p     avg_c     abs_c  log(cij)  \n",
       "1   41.666667  0.928571  0.142857  0.000000  \n",
       "8   27.000000  1.362500  0.475000  0.693147  \n",
       "9   32.833333  1.800000  0.400000  0.693147  \n",
       "10   1.000000  1.550000  0.100000  0.000000  \n",
       "11  30.833333  1.800000  0.400000  0.693147  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df[\"pij_t\"]>0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "1950 to 1959 inclusive\n",
      "#########################################\n",
      "[0 1]\n",
      "\n",
      "(767, 6)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error   z-value       p-value Significance  \\\n",
      "0  Intercept    -0.561579    0.081601 -6.881988  5.902390e-12          ***   \n",
      "1      pij_t     0.621874    0.472540  1.316022  1.881666e-01                \n",
      "2   log(cij)    -0.539902    0.533521 -1.011961  3.115569e-01                \n",
      "3      abs_p     0.788227    0.181493  4.343011  1.405431e-05          ***   \n",
      "4      avg_p    -1.238795    0.199553 -6.207837  5.371898e-10          ***   \n",
      "5      abs_c     1.239883    0.587517  2.110377  3.482591e-02            *   \n",
      "6      avg_c    -1.301547    0.591738 -2.199532  2.784009e-02            *   \n",
      "\n",
      "    t-value    p_values_t Significance_t  \n",
      "0 -6.881988  1.234124e-11            ***  \n",
      "1  1.316022  1.885628e-01                 \n",
      "2 -1.011961  3.118786e-01                 \n",
      "3  4.343011  1.595736e-05            ***  \n",
      "4 -6.207837  8.825309e-10            ***  \n",
      "5  2.110377  3.515166e-02              *  \n",
      "6 -2.199532  2.814010e-02              *  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       472\n",
      "           1       0.68      0.54      0.60       295\n",
      "\n",
      "    accuracy                           0.72       767\n",
      "   macro avg       0.71      0.69      0.70       767\n",
      "weighted avg       0.72      0.72      0.72       767\n",
      "\n",
      "Confusion Matrix:\n",
      "[[396  76]\n",
      " [135 160]]\n",
      "0.39342105263157895\n",
      "#########################################\n",
      "1960 to 1969 inclusive\n",
      "#########################################\n",
      "[0 1]\n",
      "\n",
      "(1439, 6)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -0.798819    0.078130 -10.224196  0.000000e+00          ***   \n",
      "1      pij_t     0.229516    0.501092   0.458033  6.469288e-01                \n",
      "2   log(cij)    -0.177551    0.526034  -0.337528  7.357191e-01                \n",
      "3      abs_p     1.167599    0.172128   6.783312  1.174527e-11          ***   \n",
      "4      avg_p    -2.408323    0.234215 -10.282515  0.000000e+00          ***   \n",
      "5      abs_c     0.100730    0.172793   0.582951  5.599260e-01                \n",
      "6      avg_c    -0.316786    0.173467  -1.826205  6.781939e-02            .   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -10.224196  0.000000e+00            ***  \n",
      "1   0.458033  6.469982e-01                 \n",
      "2  -0.337528  7.357686e-01                 \n",
      "3   6.783312  1.712852e-11            ***  \n",
      "4 -10.282515  0.000000e+00            ***  \n",
      "5   0.582951  5.600178e-01                 \n",
      "6  -1.826205  6.802738e-02              .  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       872\n",
      "           1       0.68      0.69      0.69       567\n",
      "\n",
      "    accuracy                           0.75      1439\n",
      "   macro avg       0.74      0.74      0.74      1439\n",
      "weighted avg       0.75      0.75      0.75      1439\n",
      "\n",
      "Confusion Matrix:\n",
      "[[687 185]\n",
      " [173 394]]\n",
      "0.21717877094972068\n",
      "#########################################\n",
      "1970 to 1979 inclusive\n",
      "#########################################\n",
      "[0 1 2 4 3]\n",
      "\n",
      "(4019, 6)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -0.928685    0.043918 -21.145760  0.000000          ***   \n",
      "1      pij_t    -0.232692    0.111023  -2.095889  0.036092            *   \n",
      "2   log(cij)     0.388399    0.108802   3.569796  0.000357          ***   \n",
      "3      abs_p     0.975083    0.115720   8.426227  0.000000          ***   \n",
      "4      avg_p    -1.983817    0.138651 -14.308026  0.000000          ***   \n",
      "5      abs_c    -0.003872    0.063124  -0.061341  0.951088                \n",
      "6      avg_c    -0.266795    0.066528  -4.010248  0.000061          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -21.145760    0.000000            ***  \n",
      "1  -2.095889    0.036154              *  \n",
      "2   3.569796    0.000361            ***  \n",
      "3   8.426227    0.000000            ***  \n",
      "4 -14.308026    0.000000            ***  \n",
      "5  -0.061341    0.951091                 \n",
      "6  -4.010248    0.000062            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      2643\n",
      "           1       0.68      0.49      0.57      1376\n",
      "\n",
      "    accuracy                           0.75      4019\n",
      "   macro avg       0.72      0.69      0.70      4019\n",
      "weighted avg       0.74      0.75      0.74      4019\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2319  324]\n",
      " [ 695  681]]\n",
      "0.34297108673978066\n",
      "#########################################\n",
      "1980 to 1989 inclusive\n",
      "#########################################\n",
      "[0 1 2 3 4 6 5]\n",
      "\n",
      "(7307, 6)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -1.172969    0.032218 -36.406765  0.000000          ***   \n",
      "1      pij_t     0.143382    0.063756   2.248909  0.024518            *   \n",
      "2   log(cij)     0.043514    0.071446   0.609045  0.542495                \n",
      "3      abs_p     0.736033    0.063225  11.641578  0.000000          ***   \n",
      "4      avg_p    -1.249139    0.077732 -16.069833  0.000000          ***   \n",
      "5      abs_c     0.068685    0.039819   1.724942  0.084538            .   \n",
      "6      avg_c    -0.641817    0.046248 -13.877826  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -36.406765    0.000000            ***  \n",
      "1   2.248909    0.024548              *  \n",
      "2   0.609045    0.542514                 \n",
      "3  11.641578    0.000000            ***  \n",
      "4 -16.069833    0.000000            ***  \n",
      "5   1.724942    0.084580              .  \n",
      "6 -13.877826    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86      5261\n",
      "           1       0.67      0.37      0.48      2046\n",
      "\n",
      "    accuracy                           0.77      7307\n",
      "   macro avg       0.73      0.65      0.67      7307\n",
      "weighted avg       0.76      0.77      0.75      7307\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4889  372]\n",
      " [1283  763]]\n",
      "0.29945205479452053\n",
      "#########################################\n",
      "1990 to 1999 inclusive\n",
      "#########################################\n",
      "[ 0  1  2  4  6  3  5 20 18 16  8 10  7]\n",
      "\n",
      "(9314, 6)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value   p-value Significance  \\\n",
      "0  Intercept    -1.297461    0.030660 -42.317359  0.000000          ***   \n",
      "1      pij_t     0.192434    0.051228   3.756441  0.000172          ***   \n",
      "2   log(cij)     0.099686    0.055763   1.787676  0.073828            .   \n",
      "3      abs_p     0.667689    0.054020  12.359940  0.000000          ***   \n",
      "4      avg_p    -1.312369    0.071642 -18.318315  0.000000          ***   \n",
      "5      abs_c     0.137517    0.034484   3.987804  0.000067          ***   \n",
      "6      avg_c    -0.794085    0.042240 -18.799510  0.000000          ***   \n",
      "\n",
      "     t-value  p_values_t Significance_t  \n",
      "0 -42.317359    0.000000            ***  \n",
      "1   3.756441    0.000173            ***  \n",
      "2   1.787676    0.073861              .  \n",
      "3  12.359940    0.000000            ***  \n",
      "4 -18.318315    0.000000            ***  \n",
      "5   3.987804    0.000067            ***  \n",
      "6 -18.799510    0.000000            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      6792\n",
      "           1       0.68      0.36      0.47      2522\n",
      "\n",
      "    accuracy                           0.78      9314\n",
      "   macro avg       0.74      0.65      0.67      9314\n",
      "weighted avg       0.77      0.78      0.76      9314\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6363  429]\n",
      " [1608  914]]\n",
      "0.27097883313634896\n",
      "#########################################\n",
      "2000 to 2009 inclusive\n",
      "#########################################\n",
      "[ 0  1  5  2  4  3  6  7  8 15 16  9 14 12 13 22 26]\n",
      "\n",
      "(13594, 6)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -1.226220    0.024396 -50.263549  0.000000e+00          ***   \n",
      "1      pij_t     0.192342    0.039456   4.874872  1.088791e-06          ***   \n",
      "2   log(cij)    -0.023256    0.045183  -0.514704  6.067598e-01                \n",
      "3      abs_p     0.714842    0.051700  13.826674  0.000000e+00          ***   \n",
      "4      avg_p    -1.112185    0.066005 -16.849995  0.000000e+00          ***   \n",
      "5      abs_c     0.130087    0.026002   5.002920  5.646825e-07          ***   \n",
      "6      avg_c    -0.789103    0.033715 -23.404934  0.000000e+00          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -50.263549  0.000000e+00            ***  \n",
      "1   4.874872  1.101097e-06            ***  \n",
      "2  -0.514704  6.067681e-01                 \n",
      "3  13.826674  0.000000e+00            ***  \n",
      "4 -16.849995  0.000000e+00            ***  \n",
      "5   5.002920  5.717385e-07            ***  \n",
      "6 -23.404934  0.000000e+00            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      9836\n",
      "           1       0.67      0.33      0.44      3758\n",
      "\n",
      "    accuracy                           0.77     13594\n",
      "   macro avg       0.73      0.63      0.65     13594\n",
      "weighted avg       0.75      0.77      0.74     13594\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9221  615]\n",
      " [2511 1247]]\n",
      "0.3381909177890631\n",
      "#########################################\n",
      "2010 to 2019 inclusive\n",
      "#########################################\n",
      "[ 0  1  2  4  3  5  6  8  9  7 10 12 14 16 11 17 15 13 18 20 19 37]\n",
      "\n",
      "(15021, 6)\n",
      "\n",
      "Logistic Regression Results:\n",
      "    Variable  Coefficient  Std. Error    z-value       p-value Significance  \\\n",
      "0  Intercept    -0.289635    0.018908 -15.318257  0.000000e+00          ***   \n",
      "1      pij_t     0.260956    0.034531   7.557222  4.107825e-14          ***   \n",
      "2   log(cij)    -0.163508    0.037453  -4.365714  1.267080e-05          ***   \n",
      "3      abs_p     0.589023    0.039202  15.025265  0.000000e+00          ***   \n",
      "4      avg_p    -0.952105    0.049013 -19.425648  0.000000e+00          ***   \n",
      "5      abs_c     0.259144    0.021919  11.822906  0.000000e+00          ***   \n",
      "6      avg_c    -0.795345    0.027942 -28.463890  0.000000e+00          ***   \n",
      "\n",
      "     t-value    p_values_t Significance_t  \n",
      "0 -15.318257  0.000000e+00            ***  \n",
      "1   7.557222  4.352074e-14            ***  \n",
      "2  -4.365714  1.275555e-05            ***  \n",
      "3  15.025265  0.000000e+00            ***  \n",
      "4 -19.425648  0.000000e+00            ***  \n",
      "5  11.822906  0.000000e+00            ***  \n",
      "6 -28.463890  0.000000e+00            ***  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75      8211\n",
      "           1       0.69      0.77      0.72      6810\n",
      "\n",
      "    accuracy                           0.74     15021\n",
      "   macro avg       0.74      0.74      0.73     15021\n",
      "weighted avg       0.74      0.74      0.74     15021\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5823 2388]\n",
      " [1590 5220]]\n",
      "0.2733448781137605\n"
     ]
    }
   ],
   "source": [
    "mods_e=[]\n",
    "for i in range(1960,2021,10):\n",
    "    print(\"#########################################\")\n",
    "    print(str(i-10)+' to '+str(i-1) + \" inclusive\")\n",
    "    print(\"#########################################\")\n",
    "    # test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)].reset_index(drop=True)\n",
    "    test_df=df_f[(df_f[\"tij\"]<i)&(df_f[\"tij\"]>=i-10)][[\"pij_t\",'cij_t',\"ytij\",\"tij\",\"tij_0\",\"tij_1\",\"Author\", \"Coauthor\",\"E\",\"avg_p\",\"abs_p\",'avg_c',\"abs_c\"]].drop_duplicates().reset_index(drop=True)\n",
    "    # plothist(test_df, \"pij_t\")\n",
    "    # plothist(test_df, \"E\")\n",
    "    print(test_df[\"cij_t\"].unique())\n",
    "    test_df[\"log(cij)\"]=np.log(test_df['cij_t'].clip(lower=0.00001))\n",
    "    test_df=test_df.fillna(0)\n",
    "    # test_df[\"pij:log(cij)\"]=test_df[\"pij_t\"]*test_df[\"log(cij)\"]\n",
    "    # test_df.loc[test_df[\"pij:log(cij)\"]==-0,\"pij:log(cij)\n",
    "    # \"]=0\n",
    "    X=test_df[[\"pij_t\",'log(cij)',\"E\",\"abs_p\", \"avg_p\",'abs_c',\"avg_c\"]]\n",
    "    y=test_df[\"ytij\"]\n",
    "    print()\n",
    "    mods_e.append(logi_mod(X,y, False, 0.9 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5733, 26)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_w_lags_10[(upd_w_lags_10[\"pij_t\"]==0)&(upd_w_lags_10[\"cij_t\"]==0)&(upd_w_lags_10[\"avg_p\"]==0)&(upd_w_lags_10[\"avg_c\"]==0)&(upd_w_lags_10[\"tij\"]<=upd_w_lags_10[\"tij_1\"])].shape\n",
    "#[[\"shortest_path_count\",\"pij_t\",\"tij\",\"tij_1\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
