{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting .pkl to panel data\n",
    "\n",
    "Expect inputs in .pkl:\n",
    "- combined jstor + scopus metadata\n",
    "- author names and affiliations data\n",
    "- references data\n",
    "- tables, figures and equations data\n",
    "\n",
    "\n",
    "Output:\n",
    "- flattened versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from unidecode import unidecode\n",
    "import re\n",
    "from datetime import date\n",
    "import json\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "from itertools import combinations\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/sijiawu/Work/Thesis/Data/Affiliations/\"\n",
    "data_base_path=\"/Users/sijiawu/Work/Thesis/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_auths_all = pd.read_pickle(base_path+\"proc_auth_aff_flat.pkl\")\n",
    "aff_sub=pd.read_pickle(base_path+\"affiliations_combined_sub.pkl\")\n",
    "j_data=pd.read_pickle(data_base_path+\"Combined/011_merged_proc_scopus_inception_2020.pkl\")\n",
    "all_refs=pd.read_excel('../031_proc_refs_full_set/refs_1940_2020.xlsx')\n",
    "relevant=pd.read_excel('../031_proc_refs_full_set/refs_1940_2020_top5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_data[\"id\"]=j_data[\"URL\"].str.split(\"/\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant[\"id_o\"]=relevant[\"id_o\"].astype(str)\n",
    "relevant[\"year_o\"]=relevant[\"year_o\"].astype(int)\n",
    "proc_auths_all[\"id_o\"]=proc_auths_all[\"url\"].str.split(\"/\").str[-1]\n",
    "relevant_sub=relevant[[\"ref_ord\", \"id_o\", \"year_o\",\"match_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in proc_auths_all['id_o'].unique():\n",
    "    if \".\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auth_ord</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>last</th>\n",
       "      <th>affs</th>\n",
       "      <th>year</th>\n",
       "      <th>content_type</th>\n",
       "      <th>jid</th>\n",
       "      <th>url</th>\n",
       "      <th>a1_order</th>\n",
       "      <th>a2_order</th>\n",
       "      <th>a3_order</th>\n",
       "      <th>fl</th>\n",
       "      <th>a1_tk_count</th>\n",
       "      <th>id_o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>benjamin enke</td>\n",
       "      <td>b. enke</td>\n",
       "      <td>b. enke</td>\n",
       "      <td>enke</td>\n",
       "      <td>{national bureau of economic research - nber, harvard university}</td>\n",
       "      <td>2020</td>\n",
       "      <td>Article</td>\n",
       "      <td>qje</td>\n",
       "      <td>https://doi.org/10.1093/qje/qjaa012</td>\n",
       "      <td>12220</td>\n",
       "      <td>4712</td>\n",
       "      <td>4304</td>\n",
       "      <td>benjamin enke</td>\n",
       "      <td>2</td>\n",
       "      <td>qjaa012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>lauren f. bergquist</td>\n",
       "      <td>l. f. bergquist</td>\n",
       "      <td>l. bergquist</td>\n",
       "      <td>bergquist</td>\n",
       "      <td>{university of michigan}</td>\n",
       "      <td>2020</td>\n",
       "      <td>Article</td>\n",
       "      <td>aer</td>\n",
       "      <td>https://www.jstor.org/stable/26966478</td>\n",
       "      <td>4049</td>\n",
       "      <td>5985</td>\n",
       "      <td>13392</td>\n",
       "      <td>lauren bergquist</td>\n",
       "      <td>3</td>\n",
       "      <td>26966478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>michael dinerstein</td>\n",
       "      <td>m. dinerstein</td>\n",
       "      <td>m. dinerstein</td>\n",
       "      <td>dinerstein</td>\n",
       "      <td>{university of chicago}</td>\n",
       "      <td>2020</td>\n",
       "      <td>Article</td>\n",
       "      <td>aer</td>\n",
       "      <td>https://www.jstor.org/stable/26966478</td>\n",
       "      <td>1884</td>\n",
       "      <td>15221</td>\n",
       "      <td>13547</td>\n",
       "      <td>michael dinerstein</td>\n",
       "      <td>2</td>\n",
       "      <td>26966478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>dominic coey</td>\n",
       "      <td>d. coey</td>\n",
       "      <td>d. coey</td>\n",
       "      <td>coey</td>\n",
       "      <td>{facebook}</td>\n",
       "      <td>2020</td>\n",
       "      <td>Article</td>\n",
       "      <td>aer</td>\n",
       "      <td>https://www.jstor.org/stable/26966479</td>\n",
       "      <td>3032</td>\n",
       "      <td>7322</td>\n",
       "      <td>6575</td>\n",
       "      <td>dominic coey</td>\n",
       "      <td>2</td>\n",
       "      <td>26966479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bradley j. larsen</td>\n",
       "      <td>b. j. larsen</td>\n",
       "      <td>b. larsen</td>\n",
       "      <td>larsen</td>\n",
       "      <td>{stanford university, national bureau of economic research - nber}</td>\n",
       "      <td>2020</td>\n",
       "      <td>Article</td>\n",
       "      <td>aer</td>\n",
       "      <td>https://www.jstor.org/stable/26966479</td>\n",
       "      <td>1624</td>\n",
       "      <td>1330</td>\n",
       "      <td>4346</td>\n",
       "      <td>bradley larsen</td>\n",
       "      <td>3</td>\n",
       "      <td>26966479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  auth_ord                   a1               a2             a3        last  \\\n",
       "0        0        benjamin enke          b. enke        b. enke        enke   \n",
       "1        0  lauren f. bergquist  l. f. bergquist   l. bergquist   bergquist   \n",
       "2        1   michael dinerstein    m. dinerstein  m. dinerstein  dinerstein   \n",
       "3        0         dominic coey          d. coey        d. coey        coey   \n",
       "4        1    bradley j. larsen     b. j. larsen      b. larsen      larsen   \n",
       "\n",
       "                                                                 affs  year  \\\n",
       "0   {national bureau of economic research - nber, harvard university}  2020   \n",
       "1                                            {university of michigan}  2020   \n",
       "2                                             {university of chicago}  2020   \n",
       "3                                                          {facebook}  2020   \n",
       "4  {stanford university, national bureau of economic research - nber}  2020   \n",
       "\n",
       "  content_type  jid                                    url a1_order a2_order  \\\n",
       "0      Article  qje    https://doi.org/10.1093/qje/qjaa012    12220     4712   \n",
       "1      Article  aer  https://www.jstor.org/stable/26966478     4049     5985   \n",
       "2      Article  aer  https://www.jstor.org/stable/26966478     1884    15221   \n",
       "3      Article  aer  https://www.jstor.org/stable/26966479     3032     7322   \n",
       "4      Article  aer  https://www.jstor.org/stable/26966479     1624     1330   \n",
       "\n",
       "  a3_order                  fl  a1_tk_count      id_o  \n",
       "0     4304       benjamin enke            2   qjaa012  \n",
       "1    13392    lauren bergquist            3  26966478  \n",
       "2    13547  michael dinerstein            2  26966478  \n",
       "3     6575        dominic coey            2  26966479  \n",
       "4     4346      bradley larsen            3  26966479  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_auths_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_coauthorship_network(collabs):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(list(collabs.index))\n",
    "    unique_pairs = list(combinations(collabs.index, 2))\n",
    "\n",
    "    for i in unique_pairs:\n",
    "        if collabs.loc[i[0],i[1]]!=0:\n",
    "            G.add_edge(i[0], i[1], weight=collabs.loc[i[0],i[1]])\n",
    "    return G\n",
    "\n",
    "def get_network_features(G, author1, author2):\n",
    "    try:\n",
    "        distance = nx.shortest_path_length(G, source=author1, target=author2)\n",
    "    except nx.NetworkXNoPath:\n",
    "        distance = np.inf  # No path exists\n",
    "\n",
    "    num_paths = len(list(nx.all_shortest_paths(G, source=author1, target=author2))) if distance != np.inf else 0\n",
    "    return distance, num_paths\n",
    "\n",
    "def compute_cosine_similarity(matrix):\n",
    "    m_array = matrix.values\n",
    "    cosine_sim = cosine_similarity(m_array)\n",
    "    authors = matrix.index\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim, index=authors, columns=authors)\n",
    "    return cosine_sim_df\n",
    "\n",
    "def cit_matrix(aff_auths, order, cit_data):\n",
    "    # Merge to get citations at author level\n",
    "    print(cit_data.shape)\n",
    "    df_citations = cit_data.merge(aff_auths[[order, \"id_o\"]], on=\"id_o\")\n",
    "    print(df_citations.shape)\n",
    "    matrix = df_citations.pivot_table(\n",
    "        index=order, columns=\"match_id\", aggfunc=\"size\", fill_value=0\n",
    "    )\n",
    "    co_simm=compute_cosine_similarity(matrix)\n",
    "    return {\"matrix\":matrix,\"sim_matrix\":co_simm}\n",
    "\n",
    "def collab_matrix(aff_auths, order):\n",
    "    authors = aff_auths[order].unique()\n",
    "    author_index = {author: idx for idx, author in enumerate(authors)}\n",
    "    matrix_size = len(authors)\n",
    "    collab_matrix = np.zeros((matrix_size, matrix_size), dtype=int)\n",
    "    grouped_papers = aff_auths.groupby(\"url\")[order].apply(list)\n",
    "\n",
    "    for authors_list in grouped_papers:\n",
    "        for author1, author2 in combinations(authors_list, 2):\n",
    "            idx1, idx2 = author_index[author1], author_index[author2]\n",
    "            collab_matrix[idx1, idx2] += 1\n",
    "            collab_matrix[idx2, idx1] += 1  \n",
    "\n",
    "    collaboration_matrix = pd.DataFrame(collab_matrix, index=authors, columns=authors)\n",
    "    \n",
    "    return collaboration_matrix\n",
    "    \n",
    "def reduce_affs_jacc_sim(aff_auths, order, cits):\n",
    "    collabs=collab_matrix(aff_auths, order)\n",
    "    o={}\n",
    "    for i in aff_auths.index:\n",
    "        if aff_auths.loc[i,order] in o.keys():\n",
    "            o[aff_auths.loc[i,order]].update(aff_auths.loc[i,\"affs\"])  # Merge sets\n",
    "        else:\n",
    "            o[aff_auths.loc[i,order]] = aff_auths.loc[i,\"affs\"]\n",
    "    cit_mat=cit_matrix(aff_auths, order, cits)\n",
    "    \n",
    "    o_proc=[]\n",
    "    pairs = list(combinations(list(o.keys()), 2))\n",
    "    # print(cit_mat['sim_matrix'].head())\n",
    "    \n",
    "    G_t = build_coauthorship_network(collabs)\n",
    "    \n",
    "    for i in pairs:\n",
    "        distance, num_paths = get_network_features(G_t, i[0], i[1])\n",
    "        network_proximity = 1 / distance if distance != np.inf else 0\n",
    "        log_num_paths = np.log(num_paths + 1)  # Avoid log(0)\n",
    "        temp={ \n",
    "                       \"pair_1\":i[0], \n",
    "                       \"pair_2\":i[1],\n",
    "                       \"aff_jacc_sim\":compute_jaccard_similarity(o[i[0]],o[i[1]]),\n",
    "                       \"collabs\": collabs.loc[i[0],i[1]],\n",
    "                       \"distance\": distance,\n",
    "                       \"network_proximity\": network_proximity,\n",
    "                       \"log_num_paths\":log_num_paths\n",
    "        }\n",
    "        \n",
    "        \n",
    "        if (i[0] in cit_mat[\"sim_matrix\"].index) & (i[1] in cit_mat[\"sim_matrix\"].index):\n",
    "            temp[\"cit_cos_sim\"]=cit_mat[\"sim_matrix\"].loc[i[0],i[1]]\n",
    "        else:\n",
    "            temp[\"cit_cos_sim\"]=0\n",
    "        o_proc.append(temp)\n",
    "\n",
    "    \n",
    "    o_flat=[]\n",
    "    for i in o.keys():\n",
    "        o_flat.append({\"order\": i,\"affs\": o[i]})\n",
    "\n",
    "    \n",
    "    return {\"sims_pairs\":pd.DataFrame(o_proc), \"aff_sets\":o, \"aff_flat_sets\": pd.DataFrame(o_flat),  \"collabs\": collabs, \"cit\":cit_mat, \"auth_net\": G_t}\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def reduce_affs_jacc_sim_optim(aff_auths, order, cits):\n",
    "    collabs = collab_matrix(aff_auths, order)\n",
    "    \n",
    "    # Efficiently create dictionary mapping orders to sets of affiliations\n",
    "    o = {}\n",
    "    auths_order_col = aff_auths[order]\n",
    "    auths_affs_col = aff_auths[\"affs\"]\n",
    "\n",
    "    for i, key in auths_order_col.items():\n",
    "        if key in o:\n",
    "            o[key].update(auths_affs_col[i])  # Merge sets directly\n",
    "        else:\n",
    "            o[key] = set(auths_affs_col[i])  # Ensure it's a set\n",
    "\n",
    "    cit_mat = cit_matrix(aff_auths, order, cits)\n",
    "\n",
    "    # Precompute pairs for similarity computations\n",
    "    keys_list = list(o.keys())\n",
    "    pairs = list(combinations(keys_list, 2))\n",
    "\n",
    "    # Build coauthorship network once\n",
    "    G_t = build_coauthorship_network(collabs)\n",
    "\n",
    "    # Compute similarities and other metrics efficiently\n",
    "    o_proc = [\n",
    "        {\n",
    "            \"pair_1\": a, \n",
    "            \"pair_2\": b,\n",
    "            \"aff_jacc_sim\": compute_jaccard_similarity(o[a], o[b]),\n",
    "            \"collabs\": collabs.loc[a, b] if a in collabs.index and b in collabs.columns else 0,\n",
    "            \"distance\": (dist := get_network_features(G_t, a, b)[0]),\n",
    "            \"network_proximity\": (1 / dist) if dist != np.inf else 0,\n",
    "            \"log_num_paths\": np.log(get_network_features(G_t, a, b)[1] + 1),  # Avoid log(0)\n",
    "            \"cit_cos_sim\": cit_mat[\"sim_matrix\"].loc[a, b] if a in cit_mat[\"sim_matrix\"].index and b in cit_mat[\"sim_matrix\"].columns else 0\n",
    "        }\n",
    "        for a, b in pairs\n",
    "    ]\n",
    "\n",
    "    # Flatten the affiliation dictionary to DataFrame\n",
    "    o_flat = [{\"order\": k, \"affs\": v} for k, v in o.items()]\n",
    "\n",
    "    return {\n",
    "        \"sims_pairs\": pd.DataFrame(o_proc),\n",
    "        \"aff_sets\": o,\n",
    "        \"aff_flat_sets\": pd.DataFrame(o_flat),\n",
    "        \"collabs\": collabs,\n",
    "        \"cit\": cit_mat,\n",
    "        \"auth_net\": G_t\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def data_prep(t, duration, order):\n",
    "    print(t)\n",
    "    aff_t=proc_auths_all[(proc_auths_all['year']<t+duration)&(proc_auths_all['year']>=t)].reset_index(drop=True)\n",
    "    cit_t=relevant_sub[(relevant_sub[\"year_o\"]>=t)&(relevant_sub[\"year_o\"]<t+duration)].reset_index(drop=True)\n",
    "    j_t=j_data[(j_data[\"year\"]>=t)&(j_data[\"year\"]<t+duration)][['id', \"title\", \"jid\", \"year\", \"content_type\"]].reset_index(drop=True)\n",
    "    a=time.time()\n",
    "    jaccs=reduce_affs_jacc_sim(aff_t, order, cit_t)\n",
    "    jaccs[\"j_data_t\"]=j_t\n",
    "    b=time.time()\n",
    "    print(b-a)\n",
    "    # print()\n",
    "    return jaccs\n",
    "\n",
    "def data_prep_optim(t, duration, order):\n",
    "    print(t)\n",
    "    aff_t=proc_auths_all[(proc_auths_all['year']<t+duration)&(proc_auths_all['year']>=t)].reset_index(drop=True)\n",
    "    cit_t=relevant_sub[(relevant_sub[\"year_o\"]>=t)&(relevant_sub[\"year_o\"]<t+duration)].reset_index(drop=True)\n",
    "    j_t=j_data[(j_data[\"year\"]>=t)&(j_data[\"year\"]<t+duration)][['id', \"title\", \"jid\", \"year\", \"content_type\"]].reset_index(drop=True)\n",
    "    a=time.time()\n",
    "    jaccs=reduce_affs_jacc_sim_optim(aff_t, order, cit_t)\n",
    "    jaccs[\"j_data_t\"]=j_t\n",
    "    b=time.time()\n",
    "    print(b-a)\n",
    "    # print()\n",
    "    return jaccs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jacc_sims_10={}\n",
    "\n",
    "# for i in range(1940,2020,10):\n",
    "#     jacc_sims_10[i]=data_prep(i,10, 'a1_order')\n",
    "\n",
    "# jacc_sims_20={}\n",
    "\n",
    "# for i in range(1940,2020,20):\n",
    "#     jacc_sims_20[i]=data_prep(i,20, 'a1_order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940\n",
      "(2447, 4)\n",
      "(2597, 5)\n",
      "Index(['pair_1', 'pair_2', 'distance'], dtype='object')\n",
      "9.258679866790771\n",
      "1950\n",
      "(3171, 4)\n",
      "(3420, 5)\n",
      "Index(['pair_1', 'pair_2', 'distance'], dtype='object')\n",
      "12.634435892105103\n",
      "1960\n",
      "(3677, 4)\n",
      "(4442, 5)\n",
      "Index(['pair_1', 'pair_2', 'distance'], dtype='object')\n",
      "24.34161686897278\n",
      "1970\n",
      "(10147, 4)\n",
      "(13368, 5)\n",
      "Index(['pair_1', 'pair_2', 'distance'], dtype='object')\n",
      "75.93183279037476\n",
      "1980\n",
      "(15578, 4)\n",
      "(23216, 5)\n",
      "Index(['pair_1', 'pair_2', 'distance'], dtype='object')\n",
      "157.0410521030426\n"
     ]
    }
   ],
   "source": [
    "jacc_sims_10={}\n",
    "\n",
    "for i in range(1940,1990,10):\n",
    "    jacc_sims_10[i]=data_prep(i,10, 'a1_order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"flattened_data_10_dec_red\"+str(time.time())+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(jacc_sims_10, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
